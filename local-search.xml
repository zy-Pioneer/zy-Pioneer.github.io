<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>Linux安全模块LSM及访问控制</title>
    <link href="/2024/12/15/Linux%E5%AE%89%E5%85%A8%E6%A8%A1%E5%9D%97LSM%E5%8F%8A%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/"/>
    <url>/2024/12/15/Linux%E5%AE%89%E5%85%A8%E6%A8%A1%E5%9D%97LSM%E5%8F%8A%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/</url>
    
    <content type="html"><![CDATA[<p>操作系统安全以<strong>访问控制</strong>为核心，与<strong>硬件结构安全</strong>一同构成信息系统安全的基础，在计算机信息系统的整体安全性中具有至关重要的作用。</p><p>访问控制机制的理论基础是引用监视器（也叫做参照监控器，reference monitor），引用监视器位于内核空间中，所有用户空间中的应用进程在进行系统调用时都必须经过引用监视器的安全检查，再去调用内核空间中的资源。引用监视器必须具有自我保护能力、总是处于活跃状态、设计得足够小，以利于分析和测试。</p><p>安全内核是指系统中与安全性实现有关的部分，包括引用验证机制、访问控制机制、授权机制和授权管理机制等，三条基本原则为：</p><ol><li>完整性原则：主体引用客体时必须通过安全内核</li><li>隔离性原则：安全内核具有防篡改能力</li><li>可验证性原则：接口简单、内核小等</li></ol><p>MAC（Mandatory Access Control，强制访问控制）是一种由系统强制执行的安全策略，通过预定义的规则对资源访问进行限制。MAC基于主体（用户或进程）和客体（文件或资源）的安全标签，以及系统管理员设定的策略来决定是否允许访问。用户无法更改权限设置，确保了高度安全性，因此常用于军事、政府和金融等高安全性需求的场景。</p><p>DAC（Discretionary Access Control，自主访问控制）是一种由资源所有者控制访问权限的安全模型。资源的所有者可以根据需要自由设置访问权限，例如读、写、执行权限。DAC机制灵活且易于使用，但由于其依赖于用户设置，存在一定的安全漏洞，适用于普通用户环境和企业级应用场景。</p><h2 id="Linux安全模块LSM简介"><a href="#Linux安全模块LSM简介" class="headerlink" title="Linux安全模块LSM简介"></a>Linux安全模块LSM简介</h2><p> Linux安全模块（LSM，Linux Security Modules）是Linux内核中的一个安全框架，旨在为不同的安全模型（如SELinux、AppArmor）提供统一的接口和基础设施。通过在内核关键代码路径中插入安全钩子（hooks），LSM允许安全模块实现访问控制、权限管理和资源保护等功能，从而增强系统的安全性和灵活性。  </p><p>Linux 安全模块（LSM）为增强 Linux 系统的安全性提供了统一的轻量级的访问控制框架，通过安全钩子和模块化设计，使得各种访问控制模型能够在内核中实现。用户在执行系统调用时，先通过内核接口找到对应的系统调用，接着定位目标节点，然后执行错误检查判断是否存在或损坏，然后执行自主访问控制 DAC 检查，判断访问权限是否满足，再通过 LSM 钩子执行对应的内核安全模块的检查逻辑，再上述检查无误的情况下执行对应的功能。</p><h2 id="基于LSM的访问控制机制"><a href="#基于LSM的访问控制机制" class="headerlink" title="基于LSM的访问控制机制"></a>基于LSM的访问控制机制</h2><p>LSM框架下的访问策略包括selinux，smack，tomoyo，yama 用户还可以注册自己的钩子函数，注册到LSM框架的模块被加载成功后，就可以进行访问控制。LSM通过在内核源代码中放置钩子函数的方法，来仲裁对内核内部对象进行的访问，实现了相关钩子函数就可以实现访问控制。LSM 钩子函数通常放在内核自主访问控制后，在内核进行真正内部资源访问前。也就是说，经过了自主访问控制的检查，还需要经过LSM 钩子函数的判定，才能访问到资源。</p><h2 id="LSM在信息系统安全中的作用"><a href="#LSM在信息系统安全中的作用" class="headerlink" title="LSM在信息系统安全中的作用"></a>LSM在信息系统安全中的作用</h2><p>Linux安全模块（LSM，Linux Security Modules）在信息系统安全中的作用主要体现在以下几个方面：</p><ol><li><strong>统一安全框架</strong>：LSM为内核中的各种安全机制提供了一个统一的接口和框架。它允许不同的安全模块（如SELinux、AppArmor、Smack）通过挂载安全钩子（hooks）实现特定的安全策略，而无需修改内核的核心代码，提升了系统的扩展性和灵活性。</li><li>LSM 支持强制访问控制模型（MAC，如 SELinux、Smack 等），通过安全策略严格限制资源的访问权限。LSM 支持灵活的自主访问控制（DAC），可以结合传统的自主访问控制与更高级别的控制模型，如基于角色（RBAC）的访问控制。</li><li>LSM 模块通过标签化的机制对敏感文件、进程、网络连接等对象进行标记，并定义严格的访问策略。LSM 可以根据安全策略限制进程的操作，如启动子进程、加载模块、访问内存等。通过网络相关的 LSM 钩子，可以控制网络套接字的创建、绑定、发送和接收操作。LSM 模块提供丰富的日志记录功能，记录系统中所有被限制或允许的安全事件。</li><li><strong>强化访问控制：</strong>LSM 提供了一种框架，通过它可以在操作系统级别实现增强的机制。这使得管理员可以定义和实施复杂的访问控制策略，超越了传统的基于用户理。例如，SELinux和AppArmor 等模块允许对进程、文件和其他系统资源进行乡问控制，从而减少未授权访问的风险。</li><li><strong>实现强制性安全策略：</strong>通过使用如SELinux或Smack 这样的LSM，组织可性的安全策略，确保即使应用程序存在漏洞或者被攻破，攻击者也无法轻易地超全边界。这些策略是强制执行的，不依赖于用户的行为或配置，提供了更强的安提供隔离环境:LSM 可以帮助创建隔离的运行环境，比如通过Landlock头提供沙箱功能。这种隔离有助于限制应用程序和服务之间的相互影响，降低单个后对整个系统的潜在威胁。</li><li><strong>防止恶意软件和内核级攻击：</strong>某些LSM如Yama 和 LoadPin 专门设计用于内核型的攻击，如防止进程间的非法交互或阻止加载未经验证的内核模块。这有效抵御恶意软件和内核级攻击的能力。</li><li><strong>简化安全管理：</strong>虽然一些LSM 如SELinux 可能需要较为复杂的配置，AppArmor 和 Tomoyo 则以简化配置为目标，使得中小型企业或不具备专业知识也能够轻松部署和维护有效的安全策略。</li><li><strong>支持多种安全模型共存：</strong>LSM 架构允许多个不同的安全模块同时存在，这意味着可以根据实际需求组合使用不同类型的 LSM 来满足多样化和复杂的控制，这对于构建高度定制化的安全解决方案非常有用。</li><li><strong>增强审计能力：</strong>许多LSM不仅能够控制访问，还能记录尝试访问的系统活动、检测异常行为以及事后分析都是非常有价值的。例如，通过日志可以追踪到哪些主体尝试过访问敏感资源，以及这些尝试是否成功。</li></ol>]]></content>
    
    
    <categories>
      
      <category>信息系统安全课程复习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>安全</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Rootkit与恶意代码防范</title>
    <link href="/2024/12/15/Rootkit%E4%B8%8E%E6%81%B6%E6%84%8F%E4%BB%A3%E7%A0%81%E9%98%B2%E8%8C%83/"/>
    <url>/2024/12/15/Rootkit%E4%B8%8E%E6%81%B6%E6%84%8F%E4%BB%A3%E7%A0%81%E9%98%B2%E8%8C%83/</url>
    
    <content type="html"><![CDATA[<h2 id="Rootkit概述"><a href="#Rootkit概述" class="headerlink" title="Rootkit概述"></a>Rootkit概述</h2><p><strong>Rootkit</strong>是一种恶意软件或工具集合，专门用于隐藏攻击者或恶意程序在目标系统中的存在。它通过深入操作系统核心（如内核层）或控制系统关键组件，绕过传统的安全检测机制，使攻击者可以长期、隐蔽地控制受害系统。  </p><h3 id="Rootkit的定义"><a href="#Rootkit的定义" class="headerlink" title="Rootkit的定义"></a><strong>Rootkit的定义</strong></h3><p>Rootkit一词来源于”root”（超级用户权限）和”kit”（工具集）。其目标是获得并隐藏对系统的超级用户权限，防止被检测和移除。</p><h4 id="核心功能"><a href="#核心功能" class="headerlink" title="核心功能"></a><strong>核心功能</strong></h4><ul><li><strong>隐藏</strong>：隐藏自身或其他恶意软件的进程、文件、网络连接等痕迹。</li><li><strong>控制</strong>：提供攻击者对目标系统的远程访问和控制。</li><li><strong>持久性</strong>：Rootkit可以在系统启动后自动加载，确保长期驻留。</li></ul><h3 id="Rootkit的主要类型"><a href="#Rootkit的主要类型" class="headerlink" title="Rootkit的主要类型"></a><strong>Rootkit的主要类型</strong></h3><p>Rootkit根据其运行的层级和隐藏的深度可分为以下几种类型：（用户级、内核级、引导级 Bootkit、硬件级、虚拟化级）</p><h4 id="用户级Rootkit（User-level-Rootkit）"><a href="#用户级Rootkit（User-level-Rootkit）" class="headerlink" title="用户级Rootkit（User-level Rootkit）"></a><strong>用户级Rootkit（User-level Rootkit）</strong></h4><ul><li><strong>描述</strong>： 用户级Rootkit主要通过修改用户态的操作环境来隐藏恶意活动，如修改或替换系统命令，劫持动态链接库、伪装成合法程序，利用钩子技术拦截或操纵系统调用</li><li><strong>特点</strong>：<ul><li>开发和部署成本低，不需要考虑内核差异（系统版本相同即可）</li><li>权限受限，无法绕过内核安全机制和操作系统核心资源</li><li>易被检测</li></ul></li><li><strong>危害</strong>：<ul><li>隐藏文件、进程和日志。</li><li>窃取、伪造用户命令的输出。</li><li>打开端口作为后门供远程控制，为后续攻击提供通道</li></ul></li><li>检测方法<ul><li>文件完整性检查（检查系统命令和库文件 hash 值和原始值是否有差异）</li><li>检测是否存在隐藏进程或文件</li><li>分析系统调用行为</li></ul></li><li>清除方法<ul><li>替换被修改的系统命令和库文件</li><li>重装系统</li></ul></li></ul><h4 id="内核级Rootkit（Kernel-level-Rootkit）"><a href="#内核级Rootkit（Kernel-level-Rootkit）" class="headerlink" title="内核级Rootkit（Kernel-level Rootkit）"></a><strong>内核级Rootkit（Kernel-level Rootkit）</strong></h4><ul><li><strong>描述</strong>： 内核级Rootkit直接运行在操作系统内核空间，拥有最高权限，可以绕过用户空间程序和安全软件的限制。  </li><li><strong>特点</strong>：高权限、高隐蔽性、难以移除、高复杂性</li><li><strong>危害</strong>：<ul><li>系统安全完全失控，禁用安全机制和操作敏感数据</li><li>长期隐蔽控制：难以被清除，可以长期存在</li><li>系统稳定性降低：系统崩溃、性能下降甚至硬件损坏</li></ul></li><li>检测方法：内核完整性检验、检测异常系统行为、使用外部可信设别扫描</li><li>清除方法：卸载可疑内核模块、格式化硬盘并重装操作系统、使用可信启动防止恶意模块加载</li></ul><h4 id="引导级Rootkit（Bootkit）"><a href="#引导级Rootkit（Bootkit）" class="headerlink" title="引导级Rootkit（Bootkit）"></a><strong>引导级Rootkit（Bootkit）</strong></h4><ul><li><strong>描述</strong>：<strong>引导型Rootkit</strong>是一种恶意软件，它通过感染系统的引导过程（如主引导记录 MBR 或 UEFI 固件）实现对操作系统的完全控制。引导型Rootkit在操作系统加载之前执行，其隐蔽性和破坏性极高，因为它能够在系统启动的最早阶段接管控制权，并隐藏其存在。  </li><li><strong>特点</strong>：<ul><li>在操作系统启动之前运行，规避大多数安全软件的检测。</li><li>具有高隐蔽性和持久性（即使重装操作系统恶意代码依然存在）。</li></ul></li><li>清除方法：<ul><li>修复引导区域</li><li>刷新固件</li><li>全盘重装</li></ul></li><li>防御方法：<ul><li>启用安全启动，防止未经授权的引导加载程序执行</li><li>定期更新固件和系统</li><li>完整性检查</li></ul></li></ul><p></p><h4 id="硬件-固件级Rootkit（Firmware-Rootkit）"><a href="#硬件-固件级Rootkit（Firmware-Rootkit）" class="headerlink" title="硬件&#x2F;固件级Rootkit（Firmware Rootkit）"></a><strong>硬件&#x2F;固件级Rootkit（Firmware Rootkit）</strong></h4><ul><li><strong>描述</strong>：攻击固件（如BIOS、网络适配器固件）或嵌入式设备。</li><li><strong>特点</strong>：<ul><li>存在于硬件固件中，几乎不可检测。</li><li>可通过重新刷写固件进行清除。</li></ul></li><li><strong>危害</strong>：<ul><li>在系统重装操作系统后依然存在。</li><li>可操控硬件设备（如键盘记录）。</li></ul></li><li>防御<ul><li>物理安全防护</li><li>供应链安全：确保硬件供应商可信</li></ul></li></ul><h4 id="虚拟化Rootkit（Hypervisor-level-Rootkit）"><a href="#虚拟化Rootkit（Hypervisor-level-Rootkit）" class="headerlink" title="虚拟化Rootkit（Hypervisor-level Rootkit）"></a><strong>虚拟化Rootkit（Hypervisor-level Rootkit）</strong></h4><ul><li><strong>描述</strong>：在系统底层创建一个虚拟化层，将目标操作系统置于虚拟环境中运行。</li><li><strong>特点</strong>：<ul><li>高度隐蔽，难以察觉。</li><li>能监控和操控操作系统的所有行为。</li></ul></li><li><strong>危害</strong>：<ul><li>实时拦截系统的输入&#x2F;输出。</li><li>截获敏感信息（如用户密码）。</li></ul></li></ul><h2 id="恶意代码类型及特点"><a href="#恶意代码类型及特点" class="headerlink" title="恶意代码类型及特点"></a>恶意代码类型及特点</h2><p>恶意代码（Malware）是一类旨在破坏计算机系统、窃取数据或干扰正常操作的恶意程序。根据其行为特点和传播方式，恶意代码可以分为以下几种主要类型：</p><ul><li><strong>计算机病毒（Computer Virus）</strong></li><li><strong>蠕虫（Worm）</strong></li><li><strong>特洛伊木马（Trojan Horse）</strong></li><li><strong>勒索软件（Ransomware）</strong></li><li><strong>僵尸程序（Botnet）</strong></li><li><strong>后门程序（Backdoor）</strong></li></ul><p>总结：计算机病毒需要用户、需要程序作为载体、会复制、不会隐藏；蠕虫不需要用户、不需要载体、会复制、不会隐藏；木马不会复制、需要用户、不需要载体、会隐藏。rootkit 主要用于持久化、隐藏并为其他病毒打基础。勒索软件是一种木马，但它的目的是勒索钱财。</p><hr><p>病毒的生命周期：</p><ol><li>创造期：⿊客研制出病毒的恶意代码</li><li>孕育期：⿊客将带有病毒的⽂件放在⼀些容易散播的地⽅，例如⽹站等</li><li>潜伏感染期：病毒不断地繁殖和传染。病毒拥有很⻓的潜伏期有利于其⼴泛传播</li><li>发病期：当触发病毒的条件满⾜时，病毒就执⾏其破坏性活动。有些病毒在某些特定的⽇期发作，还有些病毒通过倒计时或跟踪某些操作来触发⾃身</li><li>根除期：如果防毒软件能够检测和控制这些病毒，病毒就有可能被发现、隔离或清除</li></ol><h3 id="计算机病毒（Computer-Virus）"><a href="#计算机病毒（Computer-Virus）" class="headerlink" title="计算机病毒（Computer Virus）"></a>计算机病毒（Computer Virus）</h3><p>攻击者在计算机程序中插⼊的、破坏计算机功能或者数据、影响计算机使⽤并能⾃我复制的⼀组计算机指令或者程序代码</p><ul><li><strong>特点</strong>：<ul><li>需要宿主程序运行才能激活。</li><li>能自我复制并感染其他文件或程序。</li></ul></li><li><strong>传播方式</strong>：通过文件共享、邮件附件或外部存储设备传播。</li><li><strong>危害</strong>：可能删除数据、破坏文件或减慢系统性能。</li></ul><hr><h3 id="蠕虫（Worm）"><a href="#蠕虫（Worm）" class="headerlink" title="蠕虫（Worm）"></a>蠕虫（Worm）</h3><p>⽆须计算机使⽤者⼲预即可运⾏的独⽴程序或代码，通过不断扫描⽹络上存在系统漏洞的节点主机并获取其控制权来进⾏传播。</p><ul><li><strong>特点</strong>：<ul><li>不依赖宿主程序，自主运行并通过网络传播（攻击主动性）。</li><li>消耗系统资源和网络带宽。</li></ul></li><li><strong>传播方式</strong>：通过网络漏洞、邮件链接等方式快速扩散。</li><li><strong>危害</strong>：对网络和系统性能造成严重影响。</li><li>分类：电子邮件蠕虫、互联网蠕虫、网络蠕虫、多介质蠕虫</li></ul><hr><h3 id="木马病毒（Trojan-Horse）"><a href="#木马病毒（Trojan-Horse）" class="headerlink" title="木马病毒（Trojan Horse）"></a>木马病毒（Trojan Horse）</h3><p>⽊⻢程序可以将⾃⼰伪装成某种有⽤的应⽤程序来吸引⽤户下载或执⾏，危害⽤户计算机的安全，这是⼀种附着于正常程序或者单独存在的⼀类恶意程序。</p><ul><li><strong>特点</strong>：<ul><li>伪装成合法程序，诱骗用户运行。</li><li>不会自我复制，但常用来创建后门。</li></ul></li><li><strong>传播方式</strong>：通过软件安装包、钓鱼邮件等途径。</li><li><strong>危害</strong>：窃取敏感数据、远程控制受害者设备。</li><li>分类：远控型木马、Dropper 木马（加载或安装其他恶意软件的恶意程序）、Infostealer 木马（数据窃取型木马）、破坏型木马</li></ul><hr><h3 id="勒索软件（Ransomware）"><a href="#勒索软件（Ransomware）" class="headerlink" title="勒索软件（Ransomware）"></a>勒索软件（Ransomware）</h3><p>勒索软件（Ransomware）是⼀种⽊⻢软件，通过锁定桌⾯、加密⽤户⽂件、限制访问管理⼯具或者禁⽤输⼊设备等⽅式阻⽌⽤户对计算机或其数据的正常使⽤，并向⽤户勒索钱财，声称在⽤户缴纳赎⾦之后才可恢复正常使⽤。</p><ul><li><strong>特点</strong>：<ul><li>加密受害者数据，要求支付赎金以解锁。</li><li>一旦感染，用户无法访问自己的文件。</li></ul></li><li><strong>传播方式</strong>：通过钓鱼邮件或恶意下载。</li><li><strong>危害</strong>：数据丢失、经济损失。</li><li>分类：锁定型勒索软件（禁用基本功能如键鼠等）、加密型勒索软件（加密数据）、恐吓型勒索软件（通过谎称令用户恐慌，从而进行支付）</li></ul><hr><h3 id="僵尸程序（Botnet）"><a href="#僵尸程序（Botnet）" class="headerlink" title="僵尸程序（Botnet）"></a>僵尸程序（Botnet）</h3><ul><li><strong>特点</strong>：<ul><li>将受害设备变成“僵尸节点”，由攻击者远程控制。</li><li>常被用于发动DDoS攻击、发送垃圾邮件。</li></ul></li><li><strong>传播方式</strong>：通过蠕虫或木马感染。</li><li><strong>危害</strong>：网络瘫痪、资源消耗。</li></ul><hr><h3 id="后门程序（Backdoor）"><a href="#后门程序（Backdoor）" class="headerlink" title="后门程序（Backdoor）"></a>后门程序（Backdoor）</h3><ul><li><strong>特点</strong>：<ul><li>绕过正常身份验证，在系统中创建隐秘的入口。</li><li>常与其他恶意软件捆绑使用。</li></ul></li><li><strong>传播方式</strong>：通过漏洞利用、特洛伊木马等植入。</li><li><strong>危害</strong>：允许攻击者长期控制系统。</li></ul><hr><h2 id="恶意代码防范技术"><a href="#恶意代码防范技术" class="headerlink" title="恶意代码防范技术"></a>恶意代码防范技术</h2><h3 id="软件漏洞防治"><a href="#软件漏洞防治" class="headerlink" title="软件漏洞防治"></a>软件漏洞防治</h3><p>软件漏洞防治主要⽅法主要为漏洞挖掘，主要包含以下三个⽅⾯：</p><h4 id="基于源码的静态漏洞分析"><a href="#基于源码的静态漏洞分析" class="headerlink" title="基于源码的静态漏洞分析"></a>基于源码的静态漏洞分析</h4><ol><li>基于中间表示的静态分析技术<ol><li>原理：基于中间表示（IR）的静态分析技术通过将源代码转换为统一的抽象表示（如抽象语法树AST、控制流图CFG等），从而进行程序结构和语义的分析。IR消除了语言特性带来的复杂性，提供了更通用的分析平台，便于多语言支持和高效的漏洞检测。</li><li>优缺点：语言无关性，支持多种语言统一分析；抽象性强，简化语法细节，关注核心语义；高效性，提供统一的数据结构，易于实现复杂分析。但检测能力受制于分析规则，且会产生误报，需要人力分析。</li><li>数据流分析：沿着各种可能的控制流路径（程序执⾏路径）跟踪数据的各个定义点和使⽤点，并收集有关特定数据项属性信息。</li><li>符号执行：符号执⾏是指在不执⾏程序的前提下，⽤符号值表示程序变量的值，模拟程序执⾏来进⾏相关分析的技术；⽤于探索给定程序空间中尽可能多的不同的程序路径。</li><li>污点分析：将感兴趣的程序数据（外部输⼊数据或内部数据）标记为污点数据，通过跟踪污点数据在程序中的流向，检测这些数据是否会影响某些关键的操作。</li></ol></li><li>基于逻辑推理的静态分析技术<ol><li>原理：将源代码进⾏形式化的描述，利⽤推理、证明等数学⽅法验证或者发现形式化描述的⼀些性质，以此推断程序是否存在某种类型的漏洞。</li><li>优缺点：分析有一定的严格性，相对更可靠；但难以将较大规模的程序进行完全的形式化，也存在误报和漏报，也需要人工分析</li><li>模型检验：通常基于程序的有限状态模型，通过搜索模型的状态空间，检验该模型是否满⾜期望性质。可以只验证系统的部分形式化规格，⼀旦所检验的性质未被满⾜，则终⽌搜索并给出反例。（完全自动化，速度快，但存在状态空间爆炸的问题，且开销很大）</li><li>定理证明：通过将验证问题转化为数学上的定理证明问题，判断待分析程序是否满⾜指定属性，是较为复杂但准确的⽅法。（验证准确但对人力要求严格）</li></ol></li></ol><h4 id="基于二进制码的静态漏洞分析"><a href="#基于二进制码的静态漏洞分析" class="headerlink" title="基于二进制码的静态漏洞分析"></a>基于二进制码的静态漏洞分析</h4><h5 id="基于模式的静态分析技术"><a href="#基于模式的静态分析技术" class="headerlink" title="基于模式的静态分析技术"></a>基于模式的静态分析技术</h5><ol><li>原理：通过深⼊分析⼤量已知漏洞的⼆进制代码（或其反汇编代码）的特征，归纳其共性和规律，抽象出代码的漏洞模式。基于这些漏洞模式，可检测存在于其它代码中的同类漏洞。</li><li>步骤：①⽣成并分析反汇编代码；②⽣成并分析中间表示（IR）代码；③ 建⽴漏洞模式；④ 基于漏洞模式检测漏洞。</li></ol><h5 id="基于⼆进制代码⽐对的静态分析技术"><a href="#基于⼆进制代码⽐对的静态分析技术" class="headerlink" title="基于⼆进制代码⽐对的静态分析技术"></a>基于⼆进制代码⽐对的静态分析技术</h5><ol><li>基于⽂本⽐对：⼆进制代码、反汇编代码。</li><li>基于图同构⽐对：CFG、DDG。</li><li>基于结构化信息⽐对：关注逻辑结构的变化。</li><li>基于综合⽐对：综合使⽤以上1~3种⽐对技术。</li></ol><h4 id="基于二进制码的动态漏洞分析"><a href="#基于二进制码的动态漏洞分析" class="headerlink" title="基于二进制码的动态漏洞分析"></a>基于二进制码的动态漏洞分析</h4><ol><li>原理：通过跟踪⼆进制程序的执⾏，分析程序在运⾏时的内存读写操作、函数调⽤关系、内存分配&#x2F;释放等信息的⼀种漏洞检测⽅法，其主要技术为模糊测试。</li></ol><h3 id="恶意软件防治"><a href="#恶意软件防治" class="headerlink" title="恶意软件防治"></a>恶意软件防治</h3><h4 id="恶意代码逆向分析技术"><a href="#恶意代码逆向分析技术" class="headerlink" title="恶意代码逆向分析技术"></a>恶意代码逆向分析技术</h4><ol><li>原理：软件的逆向分析是对软件开发过程的逆向，通过对低级形式的代码进⾏反汇编、反编译和动态调试等分析，得到其对应的⾼级形式。</li><li>静态逆向分析技术：静态逆向分析将低级形式的⽬标代码变换为其⾼级易读形式（例如⾼级语⾔代码、结构图等），流程如下：<ol><li>对⼆进制代码程序进⾏反汇编，得到其汇编代码；</li><li>对汇编代码进⾏分析，或者进⼀步对汇编代码进⾏反编译，得到其对应的源代码并进⾏分析。</li><li>在对灰白你代码或源代码进行静态分析时，通常需要提取代码的结构信息、语义信息和统计信息，例如函数调⽤图、程序切⽚、指令序列、API调⽤频次等。</li></ol></li><li>动态逆向分析技术：通过控制和跟踪⽬标代码的执⾏，调试分析程序的⾏为和状态，以理解程序的逻辑和结构等。</li><li>动态分析和静态分析的对比：</li></ol><p>优点：能准确地观测程序行为；获取真实的程序执行逻辑；获得程序执行过程中函数和指令参数的具体值。</p><p>缺点：动态分析效果严重依赖于具体的程序输⼊，代码覆盖率低。</p><h4 id="基本的恶意代码检测技术"><a href="#基本的恶意代码检测技术" class="headerlink" title="基本的恶意代码检测技术"></a>基本的恶意代码检测技术</h4><ol><li>特征值检测：恶意代码的特征值是软件安全分析⼈员从恶意代码⽂件中提取的⼀段或多段特定的（独有的）⼆进制串数值串或字符串，⽤于唯⼀地标识它是哪个恶意代码。（只能检测已知攻击）</li><li>校验和检测：对校验内容进行哈希，校验对象⼀般为：⽂件内容、⽂件属性、⽂件头部和系统数据。（可以识别已知和未知攻击，但无法确定具体的攻击类型）</li><li>基于虚拟机的检测：对于一些采用多态和变形技术的恶意代码，在虚拟机中执行可以使其原本的恶意代码主体在虚拟机中暴露出来，对此恶意代码本体进行特征值检测。（检测环境与主机隔离；但资源开销较大，实现复杂）</li></ol><h4 id="基于AI的恶意代码检测"><a href="#基于AI的恶意代码检测" class="headerlink" title="基于AI的恶意代码检测"></a>基于AI的恶意代码检测</h4><p>基于AI的恶意代码的检测问题通常被转换为恶意代码和良性代码的⼆分类问题；恶意代码的类型识别（例如家族识别）问题通常被转换为恶意代码的多分类问题。通过建⽴对应模型，能有效解决恶意代码的检测和类型识别问题。</p><h2 id="防范策略在信息系统安全中的应用"><a href="#防范策略在信息系统安全中的应用" class="headerlink" title="防范策略在信息系统安全中的应用"></a>防范策略在信息系统安全中的应用</h2><p>因为恶意软件由多种威胁组成，所以需要采取多处方法和技术来保卫系统。如采用防火墙来过滤潜在的破坏性代码，采用垃圾邮件过滤器、入侵检测系统、入侵防御系统等来加固网络，加强对破坏性代码的防御能力。</p><ol><li>正确使用电子邮件和Web</li><li>确保在所有的桌面系统和服务器上安装最新的浏览器、操作系统、应用程序补丁，并确保垃圾邮件和浏览器的安全设置达到适当水平。</li><li>确保安装所有的安全软件，并及时更新并且使用最新的威胁数据库。</li><li>不要授权普通用户使用管理员权限，特别要注意不要让其下载和安装设备驱动程序，因为这正是许多恶意软件乘虚而入的方式。</li><li>AI赋能的威胁检测产品</li></ol><p><strong>恶意代码检测：</strong>AI技术能够分析⽂件的静态特征（如⼆进制代码结构）和动态⾏为（运⾏时的操作序列），<strong>学习历史上已知恶意软件的模式，并基于此识别新的、未⻅过的恶意⽂件</strong>。AI 能够快速适应恶意软件的变种，对于零⽇攻击的检测尤其有效。通过持续训练，模型能够不断提升对恶意⽂件的识别准确率，减少误报和漏报。随着⼤模型的兴起，业界也在尝试采⽤⼤模型来进⾏恶意⽂件的检测，⽐如华清未央公司所发明的 MLM ⼤模型（机器语⾔⼤模型），就可以⽤来进⾏恶意代码的检测。</p><p><strong>攻击流量检测：</strong>在攻击流量检测中，<strong>AI****技术通过对⽹络流量的实时分析，能够识别出异常的数据包和通信模式，</strong>这些往往与⽹络攻击相关。AI模型能够处理⼤量数据流，<strong>学习正常⽹络⾏为的复杂模式，并在此基础上识别出偏离常态的流量</strong>，⽐如DDoS攻击、恶意扫描、数据泄露尝试等。通过实时分析和模式匹配，AI能够即时触发警报并采取防御措施，保护⽹络免受攻击。业界现在有公司在开发AI智能体（AI Agent），⽤于做攻击流量的检测与⾃动处置。</p><p><strong>加密流量分析：</strong>随着加密技术的普及，加密流量成为⽹络攻击隐藏的⼀种⼿段。AI通过<strong>分析加密流量的元数据（如流量⼤⼩、时间模式、连接频率等），在不解密内容的情况下识别异常流量。结合AI模型，系统可以学习加密流量的特征，识别出与恶意活动相关的模式</strong>，如恶意软件命令与控制通信、数据泄露等。这种⽅法在保护⽤户隐私的同时，提⾼了对加密流量中隐藏威胁的检测能⼒。</p>]]></content>
    
    
    <categories>
      
      <category>信息系统安全课程复习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>安全</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Satcoms Threat Detection Summary</title>
    <link href="/2024/12/15/Satcoms%20Threat%20Detection%20Summary/"/>
    <url>/2024/12/15/Satcoms%20Threat%20Detection%20Summary/</url>
    
    <content type="html"><![CDATA[<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><h2 id="解决的主要问题"><a href="#解决的主要问题" class="headerlink" title="解决的主要问题"></a>解决的主要问题</h2><ol><li><strong>研究任务：</strong></li></ol><p>本文的研究任务主要围绕<strong>卫星通信（Satcoms）系统中的入侵检测问题</strong>展开，特别是设计一种能够有效检测各类网络威胁的<strong>深度联邦学习（DFL）</strong>模型。卫星通信系统作为现代全球信息传输的重要基础设施，面临越来越多的网络安全威胁。因此，本文的核心任务是通过采用深度学习与联邦学习相结合的方法，提出一种既能有效应对各种网络攻击，又能保证数据隐私的卫星通信安全防护机制。</p><p>该研究的核心目标是：</p><ul><li><strong>设计一种高效的威胁检测模型</strong>，能够在卫星通信环境下识别常见和复杂的攻击类型，如拒绝服务（DoS）、分布式拒绝服务（DDoS）、零日攻击等。</li><li><strong>保证数据隐私的同时进行模型训练</strong>，即在多个分布式设备（如卫星、地面站等）之间共享模型更新而不暴露敏感数据，从而利用<strong>深度联邦学习</strong>解决传统集中式方法中存在的数据隐私问题。</li></ul><blockquote><h3 id="研究任务总结"><a href="#研究任务总结" class="headerlink" title="研究任务总结"></a>研究任务总结</h3><p>本文的研究任务聚焦于<strong>卫星通信（Satcoms）系统中的入侵检测问题</strong>，目标是设计一种基于<strong>深度联邦学习（DFL）<strong><strong>的威胁检测模型。卫星通信系统作为全球信息传输的关键基础设施，面临着日益严重的网络安全威胁。本文旨在通过结合</strong></strong>深度学习</strong>和<strong>联邦学习</strong>方法，提出一种既能有效应对各种网络攻击，又能保证数据隐私的安全防护机制。</p><p>核心目标包括：</p><ul><li><strong>设计高效的威胁检测模型</strong>，能够识别卫星通信环境中的常见和复杂攻击（如拒绝服务、DDoS、零日攻击等）。</li><li><strong>保证数据隐私</strong>的同时进行模型训练，采用<strong>深度联邦学习</strong>在多个分布式设备间共享模型更新，而不暴露敏感数据，从而解决传统集中式方法中的数据隐私问题。</li></ul></blockquote><ol start="2"><li>面临的挑战：</li></ol><ul><li><strong>数据收集和隐私问题</strong><br>在传统的入侵检测系统中，所有数据需要集中到一个权威机构进行训练，但在卫星通信环境下，这种方式存在显著的问题。卫星通信系统传输的数据具有不同的隐私优先级，其中大多数数据都属于高度私密的内容。因此，数据共享以训练强大的IDS系统是不可行的，这不仅违反了数据隐私程序，还可能导致未授权的泄露。这使得在卫星通信系统中收集和汇总全面的数据集变得具有挑战性。</li><li><strong>集中式控制和安全风险</strong><br>即使数据收集成为可能，集中式IDS系统的控制机制也存在问题。这些系统容易遭受网络攻击，且在获取远程数据源的训练数据时可能面临较长的访问时间。此外，数据从数据所有者传输到数据收集方的过程可能暴露数据，从而引发更多的数据隐私问题。</li><li><strong>资源利用和计算效率</strong><br>由于每个卫星节点的计算能力有限，且传输过程中有高安全性和隐私保护的要求，因此，在为卫星通信系统开发IDS模型和架构时，如何有效利用资源变得至关重要。卫星通信系统的IDS应该在计算复杂性较低的前提下，仍然能够准确地识别攻击，比其他系统更具效率。</li><li><strong>对特定攻击的适应性</strong><br>卫星通信系统对于不同类型攻击的容忍度存在差异。诸如后门攻击、拒绝服务攻击（DoS）、分布式拒绝服务攻击（DDoS）以及零日攻击等，都可能对系统造成严重破坏。考虑到卫星通信系统的高计算性能需求和交易性质，IDS架构在应对这些攻击时需要仔细设计，确保能够有效适应这些特定的威胁。</li></ul><ol start="3"><li>现有工作的不足： 目前的卫星通信安全防护系统大多依赖于中心化学习，且通常未能有效保护本地数据的隐私。此外，许多现有的模型在检测精度和隐私保护之间未能达到理想的平衡，且存在较高的误报率，导致检测效率降低。</li></ol><blockquote><ol><li>数据收集与隐私：传统IDS需要集中收集数据，可能导致敏感信息泄露，尤其在卫星通信中，数据的隐私性要求高，难以共享用于训练的敏感数据。</li></ol><p>集中式控制与安全风险：集中式IDS面临系统故障、网络攻击以及数据传输过程中可能泄露隐私的风险，增加了数据暴露的机会。</p><p>资源利用与计算效率：卫星通信节点计算能力有限，现有IDS的高计算需求与卫星系统对低延迟、高效性的要求之间存在矛盾。</p><p>适应特定攻击的能力：卫星通信系统面临多种攻击（如DDoS、零日攻击等），现有IDS缺乏灵活性，难以应对新兴攻击或不同类型的威胁。</p></blockquote><h2 id="论文的主要内容、创新点"><a href="#论文的主要内容、创新点" class="headerlink" title="论文的主要内容、创新点"></a>论文的主要内容、创新点</h2><ol><li><strong>提出了基于深度联邦学习（DFL）的威胁检测模型</strong>： 本文首次将<strong>深度联邦学习</strong>与卫星通信网络的<strong>网络安全</strong>问题结合，提出了一种创新的基于DFL的威胁检测模型。这一模型能够在确保数据隐私的前提下，有效地检测卫星通信网络中的各种安全威胁，包括<strong>零日攻击</strong>、<strong>拒绝服务攻击（DoS）</strong>和<strong>高级持续威胁（APT）</strong>等。</li><li><strong>数据隐私保护与高效威胁检测的平衡</strong>： 本文提出了一种创新的<strong>去中心化数据预处理机制（DLP）</strong>，通过在数据预处理阶段对原始数据进行加密或匿名化处理，确保了数据隐私的保护。与传统的集中式模型相比，该方法能够在多个分布式设备上进行局部训练，只共享模型更新（而非原始数据），有效避免了隐私泄露的风险。</li><li><strong>采用深度自编码器（DAE）架构提升威胁检测能力</strong>： 在本地设备上训练的模型采用了<strong>深度自编码器（DAE）</strong>架构，这一架构特别适用于异常检测，能够有效识别通信数据中的潜在威胁。通过这种架构，本模型能够较好地检测到卫星通信网络中的异常行为，从而提高了对复杂攻击的识别能力。</li><li><strong>全局模型优化与集成机制</strong>： 本文引入了<strong>集成机制</strong>来聚合来自不同设备的模型更新，优化全局学习模型的准确性。通过合并来自多个源的更新，该方法能够提高模型的鲁棒性，减少偏差，从而确保了威胁检测的高效性和准确性。</li><li><strong>实验验证与性能提升</strong>： 本文通过实验验证了所提方法的有效性，结果表明该方法相比传统的集中式学习模型（非联邦学习版本），在<strong>保护数据隐私</strong>和<strong>提高威胁检测精度</strong>方面均表现出色。尤其在检测<strong>高级持续性威胁</strong>和<strong>零日攻击</strong>时，该方法具有明显优势。</li></ol><blockquote><ul><li><strong>基于深度联邦学习（DFL）的威胁检测模型</strong><br>本文首次将<strong>深度联邦学习（DFL）</strong>应用于卫星通信网络的安全防护，提出了一种创新的威胁检测模型，能够在确保数据隐私的同时，有效检测各种网络威胁，如零日攻击、拒绝服务攻击（DoS）和高级持续威胁（APT）。</li><li><strong>数据隐私保护与高效威胁检测的平衡</strong><br>提出了<strong>去中心化数据预处理机制（DLP）</strong>，通过加密或匿名化处理原始数据，保证数据隐私，同时在多个分布式设备上进行局部训练，仅共享模型更新，避免了数据泄露的风险。</li><li><strong>深度自编码器（DAE）架构提升威胁检测能力</strong><br>采用<strong>深度自编码器（DAE）</strong>架构进行本地模型训练，特别适用于异常检测，能够有效识别卫星通信网络中的潜在威胁，提升了对复杂攻击的检测能力。</li><li><strong>全局模型优化与集成机制</strong><br>引入<strong>集成机制</strong>对来自不同设备的模型更新进行聚合，优化全局模型的准确性，提高模型的鲁棒性，减少偏差，从而确保高效、准确的威胁检测。</li></ul></blockquote><h1 id="数据来源及预处理"><a href="#数据来源及预处理" class="headerlink" title="数据来源及预处理"></a>数据来源及预处理</h1><p>在本文的方法框架中，<strong>数据采集与预处理模块</strong>是基础且关键的部分，它确保了数据在后续处理和学习过程中能够以隐私保护且高效的方式进行处理。以下是对该模块的详细总结：</p><h4 id="数据采集："><a href="#数据采集：" class="headerlink" title="数据采集："></a><strong>数据采集：</strong></h4><p>数据采集阶段是整个方法的起点，卫星通信系统中的本地设备（如终端设备、卫星、地面站等）负责从不同源（如通信流量、系统日志等）收集原始数据。数据通常包括：</p><ul><li><strong>流量信息：</strong> 包括网络流量的各种特征，例如传输速率、连接时长、数据包大小等。</li><li><strong>系统日志：</strong> 系统运行的记录，可能包含关于网络健康状态、连接事件、异常行为的详细信息。</li></ul><p>这些数据可以反映出网络中是否存在潜在的攻击活动或者异常行为，因此数据的采集是后续威胁检测的基础。</p><h4 id="数据预处理："><a href="#数据预处理：" class="headerlink" title="数据预处理："></a><strong>数据预处理：</strong></h4><p>在数据采集之后，数据需要经过预处理模块进行清洗和转换，以确保数据适合用于模型训练，同时避免敏感信息的泄露。本文提出的预处理机制具有以下几个关键特点：</p><ul><li><strong>去中心化数据级预处理（DLP）：</strong> 本文采用了<strong>去中心化数据级预处理机制</strong>（DLP），这个步骤的核心目的是在不泄露原始数据的前提下，转化数据为适合进行机器学习模型训练的形式。DLP机制确保了数据隐私的保护，尤其是在分布式环境中，每个本地设备都只能访问和处理本地的数据，而不会共享原始数据。具体来说，DLP包括以下步骤：<ul><li><strong>数据加密与匿名化：</strong> 数据在本地进行加密或匿名化处理，防止数据在传输和存储过程中泄露敏感信息。</li><li><strong>特征提取与转换：</strong> 对原始数据进行特征提取和转换，筛选出对威胁检测有价值的信息，去除冗余和无关的数据。这个过程有助于提高模型的训练效率和准确性。</li><li><strong>数据标准化：</strong> 对数据进行标准化处理，确保不同设备和数据来源的一致性，避免因数据格式差异导致模型性能的波动。</li></ul></li><li><strong>本地化处理：</strong> 由于联邦学习的去中心化特性，数据处理和模型训练都在<strong>本地设备</strong>进行，而不需要将数据上传到中央服务器。这种本地处理的方式可以有效减少数据泄露的风险，并保证数据隐私保护。预处理模块在本地完成所有必要的操作，将处理后的数据（如特征化数据）传输到下一阶段的模型训练中。</li><li><strong>减少数据泄露的风险：</strong> 在传统的集中式学习方法中，所有数据都被上传到服务器，可能存在泄露隐私的风险。而在本文的框架中，通过去中心化的数据预处理机制，数据在本地设备上被处理和转换，且不会以原始形式传输到中心服务器，这有效避免了数据泄露的风险。</li></ul><blockquote><h4 id="数据来源"><a href="#数据来源" class="headerlink" title="数据来源"></a><strong>数据来源</strong></h4><ol><li><strong>流量信息</strong>：包括网络传输速率、连接时长、数据包大小等特征，用于识别潜在的攻击和异常行为。</li><li><strong>系统日志</strong>：记录网络健康状态、连接事件和异常行为，提供关键背景信息帮助检测不正常活动。</li></ol><h4 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a><strong>数据预处理</strong></h4><ol><li><strong>去中心化数据级预处理（DLP）</strong>：<ul><li><strong>数据加密与匿名化</strong>：在本地加密或匿名化处理数据，保护隐私。</li><li><strong>特征提取与转换</strong>：提取对威胁检测有价值的信息，去除冗余数据。</li><li><strong>数据标准化</strong>：标准化数据格式，确保一致性。</li></ul></li><li><strong>本地化处理</strong>：数据在本地处理和转换，避免上传原始数据，减少隐私泄露风险。</li></ol></blockquote><h1 id="论文包含的主要攻击类型"><a href="#论文包含的主要攻击类型" class="headerlink" title="论文包含的主要攻击类型"></a>论文包含的主要攻击类型</h1><ol><li><strong>侦察和恶意命令发送</strong>：<ul><li>攻击者通过侦察（如使用恶意软件扫描）识别<strong>卫星地面站（GSs）<strong><strong>中的</strong></strong>易受攻击的物联网设备</strong>，然后将这些设备招募到一个大型的<strong>僵尸网络</strong>（Botnet）中。</li><li>攻击者利用这些受感染的设备，向卫星（Sat1和Sat2）及多个地面站（GS4和GS5）发送伪造的指令或上传恶意文件，造成网络严重故障。</li></ul></li><li><strong>拒绝服务攻击（DoS）</strong>：<ul><li>攻击者接管了主要的地面站（GS2），向其发送大量请求，造成网络瓶颈，降低了连接到Sat1的合法地面站的服务质量。</li><li>攻击者通过向网络中注入大量的数据包，特别是针对Sat1、Sat2、GS1、GS4和GS5，实施<strong>分布式拒绝服务攻击（DDoS）</strong>，使通信网络无法正常运行。</li></ul></li><li><strong>命令篡改和响应监听</strong>：<ul><li>攻击者还通过卫星Sat3进行<strong>监听和篡改</strong>，试图窃取或篡改<strong>地面站的数据集</strong>（如参与者数据），甚至重构这些数据。</li><li>在联邦学习（FL）框架中，尽管每个地面站的本地数据集（Di）是保存在本地的，但它们需要将本地模型的更新（Mi）与服务器交换，这可能泄露地面站的私密信息。攻击者通过监听这些更新数据并进行推断，增加了篡改更新的风险。</li></ul></li><li><strong>防范措施</strong>：<ul><li>本文提出的<strong>深度联邦学习（DFL-IDS）<strong><strong>系统在Sat1和Sat2的边缘应用，能够识别并阻止恶意命令的接收，从而避免系统执行伪造的命令。该系统能够有效区分</strong></strong>合法和恶意的命令</strong>，只对合法命令做出反应。</li></ul></li></ol><p>通过以上步骤，攻击者能够利用僵尸网络进行网络瘫痪，窃取敏感数据并执行恶意命令，而本文提出的DFL-IDS系统能够有效检测并防御这些攻击。</p><table><thead><tr><th>数据集</th><th>攻击类型</th><th>描述</th></tr></thead><tbody><tr><td><strong>UNSW-NB15</strong></td><td>Fuzzers</td><td>模糊测试攻击，通过随机数据输入检测系统漏洞</td></tr><tr><td></td><td>DoS (Denial of Service)</td><td>拒绝服务攻击，消耗资源使系统无法提供服务</td></tr><tr><td><strong>Bot-IoT</strong></td><td>DDoS (Distributed Denial of Service)</td><td>分布式拒绝服务攻击，通过多个源向目标发送大量请求</td></tr><tr><td></td><td>Keylogging</td><td>键盘记录攻击，记录用户按键窃取敏感信息</td></tr><tr><td><strong>STIN</strong></td><td>DDoS (Distributed Denial of Service)</td><td>包含六种子类别的DDoS攻击，通过大量请求压垮目标系统</td></tr><tr><td></td><td>Botnet</td><td>僵尸网络攻击，多个受感染设备共同发起攻击</td></tr><tr><td></td><td>Web Attacks</td><td>Web攻击，如SQL注入、XSS等，利用Web应用漏洞进行攻击</td></tr></tbody></table><h1 id="提出的主要模型"><a href="#提出的主要模型" class="headerlink" title="提出的主要模型"></a>提出的主要模型</h1><ol><li>本地模型训练：</li></ol><p>在每个参与者节点，使用本地数据训练深度自编码器（DAE）模型。这些训练过程中的权重更新（如梯度和模型参数）会在本地计算，但差分隐私在此时应用于模型更新过程。</p><p>添加噪声： 在计算完本地模型更新后，差分隐私会向这些更新添加噪声。噪声的大小和类型通常由差分隐私的参数控制，这些噪声保证了模型更新的隐私性。</p><ol start="2"><li>上传模型更新：</li></ol><p>当本地训练完成后，参与者将模型更新（包含噪声的权重更新）发送到中央服务器。这些更新已经经过差分隐私处理，防止了其中泄露的数据。</p><p>噪声掩盖： 由于噪声的引入，攻击者无法推断出某个具体更新背后的数据模式，从而保护了数据隐私。</p><ol start="3"><li>模型聚合与全局更新：</li></ol><p>中央服务器收到所有参与者的模型更新后，会对这些更新进行加权聚合，生成全局模型。尽管这些更新被添加了噪声，但整个聚合过程仍然能够保留模型训练的效果，同时确保个体隐私得到保护。</p><p>全局更新的隐私保护： 即使聚合了多个参与者的模型更新，差分隐私保证了通过查看全局模型更新也无法泄露参与者的私人数据。</p><blockquote><ul><li><strong>联邦学习 (Federated Learning)</strong><br>数据保留在本地设备进行训练，仅共享模型更新，避免数据隐私泄露。通过分布式训练实现高效学习。</li><li><strong>差分隐私 (Differential Privacy)</strong><br>在模型更新中加入噪声，保护数据隐私，防止敏感信息泄露或推断攻击。</li><li><strong>深度自编码器 (DAE)</strong><br>通过编码器和解码器结构学习正常数据模式，利用重构误差进行异常检测，有效识别网络攻击。</li></ul></blockquote>]]></content>
    
    
    <categories>
      
      <category>入侵检测</category>
      
    </categories>
    
    
    <tags>
      
      <tag>安全</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>物联网安全</title>
    <link href="/2024/12/15/%E7%89%A9%E8%81%94%E7%BD%91%E5%AE%89%E5%85%A8/"/>
    <url>/2024/12/15/%E7%89%A9%E8%81%94%E7%BD%91%E5%AE%89%E5%85%A8/</url>
    
    <content type="html"><![CDATA[<h2 id="物联网体系架构"><a href="#物联网体系架构" class="headerlink" title="物联网体系架构"></a>物联网体系架构</h2><p>人和人、人和物体、物体和物体之间通过一个巨大的网络相连接，因而他们能够相互协作和通信。这个使得事物相互连接的网络就是物联网 (Internet of Things)。</p><p>核心组成：</p><ol><li>物理层：承载着感知层设备的物理载体</li><li>感知层：对物理世界中的各类物理量、音频、视频等数据进行采集、感知和处理</li><li>网络层：又称传输层，包括接入网和传输网两种。主要解决在感知层获得的数据传输问题，负责信息的传递、路由和控制。</li><li>应用层：利用感知层的信息，并经过处理和分析后，为用户提供特定的服务。主要解决的是信息处理与用户交互的问题。</li></ol><h2 id="物联网安全需求"><a href="#物联网安全需求" class="headerlink" title="物联网安全需求"></a>物联网安全需求</h2><p><strong>物联网是异构网络的融合，</strong>涉及传感器网络、移动通信网络和互联网相同的安全问题，涉及到<strong>隐私保护、异构网络认证、访问控制、信息存储和管理等更为特殊的问题。</strong></p><ol><li><strong>物理层：</strong>要求在执行过程中<strong>有一个安全的计算环境，</strong>这种计算环境可以保证<strong>数据的完整性，</strong>以便于本地或者远程的服务可以顺利执行。</li><li><strong>感知层：</strong>对感知节点进行<strong>身份验证，</strong>防止非法节点访问<strong>。</strong>节点间传输的信息需要轻量级的加密算法和协议，保证<strong>信息的机密性。</strong>保证<strong>数据的完整性和真实性。</strong></li><li><strong>网络层：</strong>防范<strong>分布式拒绝服务攻击。</strong>保证<strong>数据的机密性和完整性。信息隐私保护。</strong></li><li><strong>应用层：</strong>网格计算、普适计算、云计算等技术，随着物联网的发展和普及应运而生，这些<strong>新型计算模式需要保证安全性。 应用数据的隐私安全和应用部署安全。</strong></li></ol><h2 id="物联网安全机制"><a href="#物联网安全机制" class="headerlink" title="物联网安全机制"></a>物联网安全机制</h2><p>安全特征：机密性、完整性、可用性身份验证、轻量级的解决方案、异构性。</p><ol><li>机密性：数据拥有机密性可以确保数据是安全的，不会被其他非授权用户所见。</li><li>完整性：保障数据来自正确的发送方，而不会被其他人在传输过程中被篡改或者伪造。</li><li>可用性：物联网用户应该在需要的时候及时拥有所有可用的数据，服务和设备。</li><li>身份验证：物联网中的每个对象必须能够识别和验证其他对象。</li><li>轻量级解决方案：由于物联网中涉及的设备在计算能力和电源能力方面的限制，这是在设计算法时需要考虑的限制。</li><li>异构性：物联网将不同的实体、不同的功能和复杂性、不同的供应商连接起来。因此必须将协议设计为适用于所有不同的设备。</li></ol><p>物理层保证在硬件执行的过程中的数据安全，提供不同等级的安全保护机制。感知层加密感知设备传输的信息，以及在接收或发送信息时验证感知节点的身份。传输层确保点与点之间传输信息的机密性，利用密钥有关的安全协议支持数据的安全传输。应用层使用数据库安全访问控制技术、信息保护技术、数据机密检索技术等。</p><p><img src="https://raw.githubusercontent.com/zy-Pioneer/BlogImage/main/img/2025/01/3098cd7e.png"></p><h2 id="物联网安全在信息系统安全中的应用"><a href="#物联网安全在信息系统安全中的应用" class="headerlink" title="物联网安全在信息系统安全中的应用"></a>物联网安全在信息系统安全中的应用</h2><p>$ F_n(x) &#x3D; \frac{1}{n} \sum_{i&#x3D;1}^{n} I(X_i \le x) $</p>]]></content>
    
    
    <categories>
      
      <category>信息系统安全课程复习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>安全</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>网络空间安全概述</title>
    <link href="/2024/12/15/%E7%BD%91%E7%BB%9C%E7%A9%BA%E9%97%B4%E5%AE%89%E5%85%A8%E6%A6%82%E8%BF%B0/"/>
    <url>/2024/12/15/%E7%BD%91%E7%BB%9C%E7%A9%BA%E9%97%B4%E5%AE%89%E5%85%A8%E6%A6%82%E8%BF%B0/</url>
    
    <content type="html"><![CDATA[<h2 id="网络空间概念"><a href="#网络空间概念" class="headerlink" title="网络空间概念"></a>网络空间概念</h2><p>网络空间是除空天地海之外的第五空间，包含了三个基本要素：</p><ol><li>载体，也就是通讯信息系统</li><li>主体，也就是网民、用户</li><li>构造一个集合，用规则管理起来，我们称之为“网络空间”</li></ol><p>网络空间是信息时代人类赖以生存的信息环境，是所有信息系统的集合。</p><h2 id="网络空间安全涉及层面"><a href="#网络空间安全涉及层面" class="headerlink" title="网络空间安全涉及层面"></a>网络空间安全涉及层面</h2><p>网络空间安全涉及到在网络空间中的电子设备、电子信息系统、运行数据、系统应用中存在的安全问题，分别对应四个层面：设备、系统、数据、应用。</p><ul><li>物理层面</li><li>网络层面</li><li>数据层面</li><li>应用层面</li><li>管理层面</li></ul><h2 id="基本安全需求"><a href="#基本安全需求" class="headerlink" title="基本安全需求"></a>基本安全需求</h2><h3 id="可靠性"><a href="#可靠性" class="headerlink" title="可靠性"></a>可靠性</h3><p>指信息系统能够在规定条件下和规定的时间内完成规定的功能的特性。</p><p>衡量指标：</p><ol><li>抗毁性（在人力破坏下的可靠性）</li><li>生存性（在随机破坏下的可靠性）</li><li>有效性（基于业务性能的可靠性）</li></ol><h3 id="可用性"><a href="#可用性" class="headerlink" title="可用性"></a>可用性</h3><p>指信息可被授权实体访问并按需求使用的特性，是系统面向用户的安全性能。</p><p>衡量指标：</p><p>一般用系统正常使用时间和整个工作时间之比来度量。</p><h3 id="机密性"><a href="#机密性" class="headerlink" title="机密性"></a>机密性</h3><p>指信息不被泄露给非授权的用户、实体或过程，或供其利用的特性。机密性是在可靠性和可用性基础上，保障信息安全的重要手段。</p><h3 id="完整性"><a href="#完整性" class="headerlink" title="完整性"></a>完整性</h3><p>指网络信息未经授权不能进行改变的特性，既信息在存储或传输过程中保持不被偶然或蓄意地删除、修改、伪造、乱序、重放、插入等破坏和丢失的特性。</p><h3 id="不可抵赖性"><a href="#不可抵赖性" class="headerlink" title="不可抵赖性"></a>不可抵赖性</h3><p>指在信息交互过程中，确信参与者的真实同一性，既所有参与者都不可能否认或抵赖曾经完成的操作和承诺。</p><h2 id="信息系统安全管理与技术"><a href="#信息系统安全管理与技术" class="headerlink" title="信息系统安全管理与技术"></a>信息系统安全管理与技术</h2><p>安全&#x3D;风险分析+执行策略+系统实施+漏洞检测+实时响应</p><ol><li>P2DR安全模型（Policy安全策略、Protection防护、Detection检测、Response响应）</li><li>PDRR安全模型（防护、检测、响应、恢复）：尽可能增大保护时间，减少检测和响应的时间，并且在系统遭受到破坏之后快速恢复，减少系统暴露的时间。</li><li>MP2DRR安全模型（管理、安全策略、访问控制、入侵检测、安全响应、恢复）</li></ol>]]></content>
    
    
    <categories>
      
      <category>信息系统安全课程复习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>安全</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>基于生成式人工智能增强手写数字识别的实验研究</title>
    <link href="/2024/12/15/%E9%AB%98%E7%BA%A7%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%AE%9E%E9%AA%8C%E6%8A%A5%E5%91%8A/"/>
    <url>/2024/12/15/%E9%AB%98%E7%BA%A7%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%AE%9E%E9%AA%8C%E6%8A%A5%E5%91%8A/</url>
    
    <content type="html"><![CDATA[<h1 id="基于生成式人工智能增强手写数字识别的实验研究"><a href="#基于生成式人工智能增强手写数字识别的实验研究" class="headerlink" title="基于生成式人工智能增强手写数字识别的实验研究"></a>基于生成式人工智能增强手写数字识别的实验研究</h1><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>本研究探索了三种不同的生成式神经网络方法（DDPM、VAE 和 GAN）在增强手写数字识别任务中的应用。通过对比实验表明，生成式模型能够有效提升分类器的性能。实验结果显示，DDPM方法在样本质量和分类增强效果上表现最优，而 VAE 方法在训练效率上具有优势。</p><h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><h3 id="研究背景"><a href="#研究背景" class="headerlink" title="研究背景"></a>研究背景</h3><p>手写数字识别是计算机视觉领域的基础任务，但传统方法在数据量有限的情况下往往表现不佳。生成式模型的出现为解决此类问题提供了新的思路。</p><h3 id="研究目的"><a href="#研究目的" class="headerlink" title="研究目的"></a>研究目的</h3><ul><li>探索不同生成式模型在数据增强中的效果</li><li>比较各种方法的优劣势</li><li>提出最优的模型组合方案</li></ul><h2 id="系统设计"><a href="#系统设计" class="headerlink" title="系统设计"></a>系统设计</h2><p>系统采用模块化设计，主要包含四个核心组件：</p><ol><li><strong>生成模型模块</strong></li><li><strong>分类器模块</strong></li><li><strong>评估与分析模块</strong></li></ol><h3 id="DDPM模型"><a href="#DDPM模型" class="headerlink" title="DDPM模型"></a>DDPM模型</h3><p>DDPM（Denoising Diffusion Probabilistic Models）模型采用了基于马尔可夫链的扩散过程，主要包含两个核心过程：</p><ol><li><strong>前向扩散过程</strong>：逐步向图像添加高斯噪声</li><li><strong>反向扩散过程</strong>：学习去噪过程，逐步从噪声恢复图像</li></ol><h4 id="前向过程"><a href="#前向过程" class="headerlink" title="前向过程"></a>前向过程</h4><p>前向过程的公式如下所示：</p><p>$<br>x_t &#x3D; \sqrt{\bar{\alpha}_t} x_0 + \sqrt{1 - \bar{\alpha}_t} \epsilon<br> $</p><ul><li>$ x_t $：在时间步 $ t $ 的数据。</li><li>$ \bar{\alpha}<em>t &#x3D; \prod</em>{i&#x3D;1}^t \alpha_i $：累积噪声控制参数。</li><li>$ \epsilon $：从标准正态分布中采样的噪声。</li></ul><h4 id="反向过程"><a href="#反向过程" class="headerlink" title="反向过程"></a>反向过程</h4><p>$<br>x_{t-1} &#x3D; \frac{1}{\sqrt{\alpha_t}} \left( x_t - \frac{\beta_t}{\sqrt{1 - \bar{\alpha}_t}} \epsilon_\theta \right) + \sqrt{\beta_t} z<br> $</p><ul><li>$ x_{t-1} $：还原到前一步的数据。</li><li>$ \epsilon_\theta $：由神经网络预测的噪声。</li><li>$ z $：附加的随机噪声，仅在 $ t &gt; 0 $ 时加入。</li></ul><h4 id="核心代码"><a href="#核心代码" class="headerlink" title="核心代码"></a>核心代码</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">DDPM</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, device, n_steps=<span class="hljs-number">1000</span>, min_beta=<span class="hljs-number">0.0001</span>, max_beta=<span class="hljs-number">0.02</span></span>):<br>        <span class="hljs-comment"># 初始化扩散过程参数</span><br>        <span class="hljs-variable language_">self</span>.n_steps = n_steps<br>        <span class="hljs-variable language_">self</span>.device = device<br>        <span class="hljs-variable language_">self</span>.beta = torch.linspace(min_beta, max_beta, n_steps).to(device)<br>        <span class="hljs-variable language_">self</span>.alpha = <span class="hljs-number">1</span> - <span class="hljs-variable language_">self</span>.beta<br>        <span class="hljs-variable language_">self</span>.alpha_bar = torch.cumprod(<span class="hljs-variable language_">self</span>.alpha, dim=<span class="hljs-number">0</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">sample_forward</span>(<span class="hljs-params">self, x0, t</span>):<br>        <span class="hljs-comment"># 前向过程：添加噪声</span><br>        alpha_bar = <span class="hljs-variable language_">self</span>.alpha_bar[t].reshape(-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>)<br>        eps = torch.randn_like(x0)<br>        <span class="hljs-keyword">return</span> torch.sqrt(alpha_bar) * x0 + torch.sqrt(<span class="hljs-number">1</span> - alpha_bar) * eps, eps<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">sample_backward</span>(<span class="hljs-params">self, shape, net, device, return_sequence=<span class="hljs-literal">False</span></span>):<br>        <span class="hljs-comment"># 反向过程：从噪声生成数据</span><br>        <span class="hljs-keyword">with</span> torch.no_grad():<br>            x = torch.randn(shape).to(device)<br>            sequence = []<br>            <span class="hljs-keyword">for</span> t <span class="hljs-keyword">in</span> tqdm(<span class="hljs-built_in">reversed</span>(<span class="hljs-built_in">range</span>(<span class="hljs-variable language_">self</span>.n_steps)), desc=<span class="hljs-string">&quot;Sampling&quot;</span>):<br>                <span class="hljs-keyword">if</span> t % <span class="hljs-number">100</span> == <span class="hljs-number">0</span>:<br>                    torch.cuda.empty_cache()<br>                t_batch = torch.ones(shape[<span class="hljs-number">0</span>], dtype=torch.long, device=device) * t<br>                eps_theta = net(x, t_batch)<br>                alpha = <span class="hljs-variable language_">self</span>.alpha[t].to(device)<br>                alpha_bar = <span class="hljs-variable language_">self</span>.alpha_bar[t].to(device)<br>                beta = <span class="hljs-variable language_">self</span>.beta[t].to(device)<br>                factor1 = (<span class="hljs-number">1</span> / torch.sqrt(alpha))<br>                factor2 = (beta / torch.sqrt(<span class="hljs-number">1</span> - alpha_bar))<br>                z = torch.randn_like(x) <span class="hljs-keyword">if</span> t &gt; <span class="hljs-number">0</span> <span class="hljs-keyword">else</span> <span class="hljs-number">0</span><br>                x = factor1 * (x - factor2 * eps_theta) + torch.sqrt(beta) * z<br>                <span class="hljs-keyword">if</span> return_sequence <span class="hljs-keyword">and</span> t % <span class="hljs-number">100</span> == <span class="hljs-number">0</span>:<br>                    sequence.append(x.detach().cpu())<br>                <span class="hljs-keyword">del</span> eps_theta<br>                torch.cuda.empty_cache()<br>            <span class="hljs-keyword">return</span> sequence <span class="hljs-keyword">if</span> return_sequence <span class="hljs-keyword">else</span> x<br></code></pre></td></tr></table></figure><h3 id="VAE-模型"><a href="#VAE-模型" class="headerlink" title="VAE 模型"></a>VAE 模型</h3><p>VAE（Variational AutoEncoder，变分自编码器）是一种生成模型，通过编码器将输入数据映射到潜空间，并通过重参数化技巧采样潜变量，再使用解码器将潜变量重构为原始数据。</p><p>VAE 的主要过程包括：</p><ol><li><strong>编码过程</strong>：输入数据通过卷积层降维，提取特征，并生成潜空间的均值和对数方差。</li><li><strong>重参数化技巧</strong>：对潜空间进行采样，以确保模型的可导性。</li><li><strong>解码过程</strong>：从潜空间的样本生成数据，通过反卷积逐步还原为输入尺寸。</li></ol><hr><h4 id="编码过程"><a href="#编码过程" class="headerlink" title="编码过程"></a>编码过程</h4><p>编码过程通过卷积层逐步提取输入数据的特征，并最终生成潜空间的均值 $ \mu $ 和对数方差 $ \log \sigma^2 $。</p><ul><li><strong>均值</strong>：</li></ul><p>$ \mu &#x3D; \text{fc}_\mu(\text{flatten}(\text{encoder}(x))) $</p><ul><li><strong>对数方差</strong>：</li></ul><p>$ \log \sigma^2 &#x3D; \text{fc}_\text{var}(\text{flatten}(\text{encoder}(x))) $</p><ul><li>$ x $：输入数据。</li><li>$ \mu $：潜空间的均值。</li><li>$ \log \sigma^2 $：潜空间的对数方差。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">encode</span>(<span class="hljs-params">self, x</span>):<br>    x = <span class="hljs-variable language_">self</span>.encoder(x)  <span class="hljs-comment"># 提取特征</span><br>    x = torch.flatten(x, start_dim=<span class="hljs-number">1</span>)  <span class="hljs-comment"># 平铺为向量</span><br>    mu = <span class="hljs-variable language_">self</span>.fc_mu(x)  <span class="hljs-comment"># 计算均值</span><br>    log_var = <span class="hljs-variable language_">self</span>.fc_var(x)  <span class="hljs-comment"># 计算对数方差</span><br>    <span class="hljs-keyword">return</span> mu, log_var<br></code></pre></td></tr></table></figure><h4 id="重参数化技巧"><a href="#重参数化技巧" class="headerlink" title="重参数化技巧"></a>重参数化技巧</h4><p>重参数化技巧用于从潜空间中采样，以确保模型的可导性。公式如下：</p><p>$ z &#x3D; \mu + \epsilon \cdot \sigma, \quad \epsilon \sim \mathcal{N}(0, I), \quad \sigma &#x3D; \exp(0.5 \cdot \log \sigma^2) $</p><ul><li>$ z $：从潜空间采样的潜变量。</li><li>$ \mu $：潜空间的均值，由编码器输出。</li><li>$ \sigma $：潜空间的标准差，通过对数方差 $ \log \sigma^2 $ 计算。</li><li>$ \epsilon $：标准正态分布噪声，用于引入随机性。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">reparameterize</span>(<span class="hljs-params">self, mu, log_var</span>):<br>    std = torch.exp(<span class="hljs-number">0.5</span> * log_var)  <span class="hljs-comment"># 计算标准差</span><br>    eps = torch.randn_like(std)    <span class="hljs-comment"># 从标准正态分布采样噪声</span><br>    <span class="hljs-keyword">return</span> mu + eps * std          <span class="hljs-comment"># 重参数化</span><br></code></pre></td></tr></table></figure><h4 id="解码过程"><a href="#解码过程" class="headerlink" title="解码过程"></a>解码过程</h4><p>解码过程将潜空间的潜变量 $ z $ 转换回原始数据尺寸，主要包括以下步骤：</p><ol><li>特征向量映射</li></ol><p>将潜变量 $ z $ 映射到特征空间的向量形式，便于后续的卷积操作：</p><p>$ h &#x3D; \text{decoder_input}(z) $</p><ul><li>$ z $：从潜空间采样的潜变量。</li><li>$ h $：解码器输入的特征向量。</li></ul><ol start="2"><li>特征向量重塑</li></ol><p>将映射后的特征向量调整为适配卷积输入的形状：</p><p>$ h &#x3D; \text{reshape}(h, [\text{batch_size}, \text{channels}, \text{height}, \text{width}]) $</p><ol start="3"><li>卷积操作</li></ol><p>通过反卷积逐步放大特征图，最终恢复到输入数据的尺寸：</p><p>$ \hat{x} &#x3D; \text{decoder}(h) $</p><ol start="4"><li>自适应池化与映射</li></ol><p>在最终输出阶段，利用自适应池化和卷积层精确调整数据尺寸为目标尺寸：</p><p>$ \hat{x} &#x3D; \text{AdaptiveAvgPool2d}(h) \rightarrow \text{Conv2d}(\text{to desired output channels}) $</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">decode</span>(<span class="hljs-params">self, z</span>):<br>    <span class="hljs-comment"># 将潜变量映射为特征向量</span><br>    x = <span class="hljs-variable language_">self</span>.decoder_input(z)<br>    <br>    <span class="hljs-comment"># 重塑为卷积输入形状</span><br>    x = x.view(-<span class="hljs-number">1</span>, <span class="hljs-variable language_">self</span>.hidden_dims[-<span class="hljs-number">1</span>], <span class="hljs-variable language_">self</span>.feature_size, <span class="hljs-variable language_">self</span>.feature_size)<br>    <br>    <span class="hljs-comment"># 通过解码器逐步还原</span><br>    x = <span class="hljs-variable language_">self</span>.decoder(x)<br>    <span class="hljs-keyword">return</span> x<br></code></pre></td></tr></table></figure><h2 id="3-实验设置"><a href="#3-实验设置" class="headerlink" title="3. 实验设置"></a>3. 实验设置</h2><h3 id="3-1-数据集"><a href="#3-1-数据集" class="headerlink" title="3.1 数据集"></a>3.1 数据集</h3><ul><li><strong>训练集</strong>：<ul><li>MNIST训练集（60,000张）</li><li>生成样本（每种方法20,000张）</li></ul></li><li><strong>测试集</strong>：<ul><li>MNIST测试集（10,000张）</li></ul></li></ul><h3 id="3-2-实验环境"><a href="#3-2-实验环境" class="headerlink" title="3.2 实验环境"></a>3.2 实验环境</h3><ul><li>GPU：NVIDIA RTX 4090</li><li>框架：PyTorch 2.4.0</li><li>CUDA：12.4</li></ul><h2 id="4-实验结果与分析"><a href="#4-实验结果与分析" class="headerlink" title="4. 实验结果与分析"></a>4. 实验结果与分析</h2><p>本实验还实现了 GAN 版本的数据增强方法，实验对比分析如下。</p><h3 id="4-2-分类性能提升"><a href="#4-2-分类性能提升" class="headerlink" title="4.2 分类性能提升"></a>4.2 分类性能提升</h3><table><thead><tr><th>增强方法</th><th>基准准确率</th><th>增强后准确率</th><th>提升幅度</th></tr></thead><tbody><tr><td>无增强</td><td>97.25%</td><td>-</td><td>-</td></tr><tr><td>DDPM增强</td><td>97.25%</td><td>98.45%</td><td>1.20%</td></tr><tr><td>GAN增强</td><td>97.25%</td><td>98.12%</td><td>0.87%</td></tr><tr><td>VAE增强</td><td>97.25%</td><td>97.89%</td><td>0.64%</td></tr></tbody></table><h3 id="4-3-结果分析"><a href="#4-3-结果分析" class="headerlink" title="4.3 结果分析"></a>4.3 结果分析</h3><ol><li><strong>生成质量</strong>：<ul><li>DDPM生成的样本质量最高，但计算开销大</li><li>VAE生成样本相对模糊</li></ul></li><li><strong>分类增强效果</strong>：<ul><li>所有方法都能提升分类性能</li><li>DDPM增强效果最显著</li><li>增强效果与生成样本质量正相关</li></ul></li><li><strong>实际应用考虑</strong>：<ul><li>资源充足时推荐DDPM</li><li>稳定性和实时性要求高时推荐VAE</li></ul></li></ol><h2 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h2><h3 id="代码使用说明"><a href="#代码使用说明" class="headerlink" title="代码使用说明"></a>代码使用说明</h3><h4 id="目录结构"><a href="#目录结构" class="headerlink" title="目录结构"></a>目录结构</h4><p>├── config&#x2F;</p><p>│ ├── ddpm_config.py # DDPM配置</p><p>│ ├── gan_config.py # GAN配置</p><p>│ └── vae_config.py # VAE配置</p><p>├── models&#x2F;</p><p>│ ├── ddpm.py # DDPM模型实现</p><p>│ ├── gan.py # GAN模型实现</p><p>│ └── vae.py # VAE模型实现</p><p>├── utils&#x2F;</p><p>│ ├── data_loader.py # 数据加载工具</p><p>│ └── visualization.py # 可视化工具</p><p>├── train_ddpm.py # DDPM训练脚本</p><p>├── train_gan.py # GAN训练脚本</p><p>└── train_vae.py # VAE训练脚本</p><p>└── main.py # 启动脚本</p><h4 id="环境配置"><a href="#环境配置" class="headerlink" title="环境配置"></a>环境配置</h4><p>通过以下指令配置虚拟环境</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">pip install requirements.txt<br></code></pre></td></tr></table></figure><h4 id="使用说明"><a href="#使用说明" class="headerlink" title="使用说明"></a>使用说明</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">main</span>():<br>    <span class="hljs-comment"># 解析参数</span><br>    args = parse_args()<br>    <br>    <span class="hljs-comment"># 设置设备</span><br>    torch.cuda.set_device(args.device)<br>    <br>    <span class="hljs-comment"># 根据method参数选择运行的实验</span><br>    results = &#123;&#125;<br>    <br>    <span class="hljs-keyword">if</span> args.method <span class="hljs-keyword">in</span> [<span class="hljs-string">&#x27;ddpm&#x27;</span>, <span class="hljs-string">&#x27;all&#x27;</span>]:<br>        results[<span class="hljs-string">&#x27;ddpm&#x27;</span>] = run_ddpm_experiment(args.train)<br>        <br>    <span class="hljs-keyword">if</span> args.method <span class="hljs-keyword">in</span> [<span class="hljs-string">&#x27;vae&#x27;</span>, <span class="hljs-string">&#x27;all&#x27;</span>]:<br>        results[<span class="hljs-string">&#x27;vae&#x27;</span>] = run_vae_experiment(args.train)<br>        <br>    <span class="hljs-keyword">if</span> args.method <span class="hljs-keyword">in</span> [<span class="hljs-string">&#x27;gan&#x27;</span>, <span class="hljs-string">&#x27;all&#x27;</span>]:<br>        results[<span class="hljs-string">&#x27;gan&#x27;</span>] = run_gan_experiment(args.train)<br></code></pre></td></tr></table></figure><p>使用以下指令来运行实验 </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">python ./main.py --method gan<br></code></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/zy-Pioneer/BlogImage/main/img/2025/01/7edf253a.png"></p>]]></content>
    
    
    <categories>
      
      <category>实验报告</category>
      
    </categories>
    
    
    <tags>
      
      <tag>深度学习</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>人工智能模型安全</title>
    <link href="/2024/12/14/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%A8%A1%E5%9E%8B%E5%AE%89%E5%85%A8/"/>
    <url>/2024/12/14/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%A8%A1%E5%9E%8B%E5%AE%89%E5%85%A8/</url>
    
    <content type="html"><![CDATA[<h3 id="攻击类型："><a href="#攻击类型：" class="headerlink" title="攻击类型："></a>攻击类型：</h3><ol><li><p>对抗攻击：旨在通过⼲扰模型预测结果以获取⾮法利益。</p></li><li><p>后⻔攻击：通过在模型中植⼊后⻔来破坏模型的可靠性。</p></li><li><p>隐私攻击：旨在窃取模型或数据中的隐私信息。</p></li></ol><h2 id="对抗样本攻击概述"><a href="#对抗样本攻击概述" class="headerlink" title="对抗样本攻击概述"></a>对抗样本攻击概述</h2><h3 id="对抗样本的概念："><a href="#对抗样本的概念：" class="headerlink" title="对抗样本的概念："></a>对抗样本的概念：</h3><p>使⽤特定技术对输⼊样本进⾏微⼩的修改就可骗过模型⽽得到错误的结果，这种经过修改，使得模型判断错误的样本被称为对抗样本。</p><h3 id="威胁模型"><a href="#威胁模型" class="headerlink" title="威胁模型"></a>威胁模型</h3><ol><li>黑盒攻击<br>攻击者只能给定输⼊去获得模型输出，但并不知道被攻击模型所使⽤的算法和参数，⿊盒攻击可以针对任何⼀个⼈⼯智能模型（可以攻击任何一个人工智能模型）。</li><li>白盒攻击<br>攻击者熟知⼈⼯智能模型的算法和模型参数，⽣成对抗样本的过程可以与模型的每⼀部分进⾏交互。</li></ol><h3 id="白盒模型下对抗样本的生成与防御"><a href="#白盒模型下对抗样本的生成与防御" class="headerlink" title="白盒模型下对抗样本的生成与防御"></a>白盒模型下对抗样本的生成与防御</h3><ol><li>（攻击角度，白盒攻击）对抗样本的生成：对⼈⼯智能模型的⽩盒攻击通常会对模型的每⼀部分进⾏逐层分解，然后对每⼀部分添加⼀定的扰动，使得模型的结果逐步向误判⽬标类别偏移</li><li>（防御角度）生成对抗网络 GAN：<br>由于白盒攻击时对模型内部增添扰动实现的，所以在训练的时候使用同样的方法增强模型训练的鲁棒性，例如对抗生成网络（GAN）</li></ol><h4 id="GAN的组成："><a href="#GAN的组成：" class="headerlink" title="GAN的组成："></a>GAN的组成：</h4><ol><li>生成网络：通过神经⽹络将输⼊的⼀个服从简单分布的随机变量（随机噪声）转化为能够欺骗判别⽹络的对抗样本</li><li>对抗网络：通过神经⽹络判断输⼊样本的真实类别</li></ol><p>在模型训练时，⽣成⽹络负责⽣成对抗样本，判别⽹络（即我们真正需要的⽹络）对样本类别进⾏判断。在这⼀过程中，⽣成⽹络所⽣成的试图欺骗判别⽹络的对抗样本会被判别⽹络识破，从⽽达到防御⽩盒攻击的⽬的。</p><h4 id="GAN-的训练过程"><a href="#GAN-的训练过程" class="headerlink" title="GAN 的训练过程"></a>GAN 的训练过程</h4><h3 id="黑盒模型下的攻击与防御"><a href="#黑盒模型下的攻击与防御" class="headerlink" title="黑盒模型下的攻击与防御"></a>黑盒模型下的攻击与防御</h3><ol><li>（攻击角度，黑盒攻击）在⿊盒威胁模型下，攻击者的⽬标是设计有效的攻击⽅法，使模型在未知攻击下表现出性能下降或错误输出，例如通过设计针对特定模型的对抗样本进⾏攻击</li><li>（防御角度）针对⿊盒威胁模型的防御策略通常需要设计更加健壮的防御⽅法，例如通过增加数据的多样性和噪声来提⾼模型的鲁棒性，或者通过模型结构的改进和安全性增强来提⾼模型抵抗对抗样本攻击的能⼒。</li></ol><h4 id="攻击技术"><a href="#攻击技术" class="headerlink" title="攻击技术"></a>攻击技术</h4><p>⼈⼯智能安全威胁的⿊盒攻击技术主要包括对抗性输⼊、数据中毒攻击、反馈武器化和模型窃取技术。</p><ol><li>对抗性输⼊：是⼀种专⻔设计的输⼊，旨在确保被误分类，以躲避检测。这种攻击涉及到创建恶意⽂档和试图逃避垃圾邮件过滤器的电⼦邮件等，⽬的是通过欺骗⼈⼯智能系统，使其做出错误的分类或决策。</li><li>数据中毒攻击： 数据中毒攻击通过对训练数据进行污染（例如通过添加恶意数据）来影响模型的训练过程，使得模型在推理阶段产生错误的预测。这种攻击方法通常依赖于攻击者能够影响训练数据的获取，但又不能直接访问模型的训练过程，包括</li></ol><ul><li><strong>标签污染</strong>：攻击者可以通过向训练数据中添加带有错误标签的数据来误导训练过程，使得模型在训练时产生偏差。</li><li><strong>特征污染</strong>：攻击者可以改变输入特征，制造模型在推理时的误判。</li></ul><ol start="3"><li>模型窃取攻击： 模型提取攻击是攻击者通过查询目标模型并记录其输出，从而反向构建目标模型的近似副本。在黑盒环境下，攻击者并不知道目标模型的结构和参数，但可以通过查询和反馈来模拟出一个接近的模型。构建出的副本模型可以被用来进一步发起对抗攻击或直接被用作攻击其他系统。  </li><li>反馈武器化攻击：本质上来说它是一种策略，通过不断观察目标系统的反馈结果如模型输出等，来不断调整输入，来达到攻击目的。</li><li>边界攻击：边界攻击通过微小的扰动对输入样本进行调整，迫使目标模型输出错误的结果。攻击者在黑盒环境下通过推测模型的决策边界（decision boundary），逐渐将样本推向这个决策边界，从而逼迫模型做出错误分类。</li><li>模型压缩与反向工程： 攻击者可能试图通过<strong>模型压缩</strong>技术将目标模型转换为一个简单的模型，从而揭示其潜在结构和行为。压缩通常是指将一个大规模的神经网络转换成一个更小的网络，通过在保持较高准确度的同时，减少模型的复杂性。 如网络剪枝（减少一些权重）或知识蒸馏（训练替代的小模型）</li></ol><h4 id="对抗样本的生成"><a href="#对抗样本的生成" class="headerlink" title="对抗样本的生成"></a>对抗样本的生成</h4><ol><li>无针对攻击：任意生成的输入数据，使得模型输出为指定结果（噪声–&gt;模型输出 3）</li></ol><p><img src="https://raw.githubusercontent.com/zy-Pioneer/BlogImage/main/img/2025/01/b0a7c540.png"></p><ol start="2"><li>有针对攻击：生成人类与模型判断迥异的对抗样本（人类认为 9–&gt;模型输出 3），两阶段损失函数，分别保证被人误判和被模型误判</li></ol><p><img src="https://raw.githubusercontent.com/zy-Pioneer/BlogImage/main/img/2025/01/48926d0d.png"></p><h4 id="防御技术"><a href="#防御技术" class="headerlink" title="防御技术"></a>防御技术</h4><p>数据压缩：通过对输⼊数据进⾏压缩或者降维，在保证识别准确率的情况下 提升模型对⼲扰攻击的鲁棒性</p><p>数据随机化：对训练数据进⾏随机缩放、增强等操作，提升模型的鲁棒性</p><p>训练额外的⽹络来判断训练数据是否为攻击样本</p><h2 id="人工智能模型安全防护措施"><a href="#人工智能模型安全防护措施" class="headerlink" title="人工智能模型安全防护措施"></a>人工智能模型安全防护措施</h2><h3 id="攻击类型"><a href="#攻击类型" class="headerlink" title="攻击类型"></a>攻击类型</h3><ol><li>对抗攻击：对抗攻击的⽬的在于通过制造并注⼊对抗样本，降低模型的预测准确性。这类攻击通常针对模型的输⼊数据，通过添加⼈类难以察觉的⼲扰，使得模型产⽣错误的输出。</li><li>后门攻击：后⻔攻击的⽬的在于在模型训练过程中植⼊后⻔，使得模型在特定情况下产⽣错误的输出。这类攻击通常通过修改模型参数或使⽤特定的训练数据来实现。</li><li>隐私攻击：隐私攻击的⽬的在于通过获取模型的隐私信息，如训练数据、模型结构等，来提⾼攻击者的能⼒。这类攻击通常针对模型的所有者，通过窃取或购买的⽅式获取敏感信息。</li></ol><h3 id="防御类型"><a href="#防御类型" class="headerlink" title="防御类型"></a>防御类型</h3><ol><li>检测数据攻击：通过检测数据是否被篡改或伪造来防⽌数据攻击。这可以通过检查数据的完整性、⼀致性或可信度来实现。</li><li>检测模型攻击：通过检测模型是否被篡改或⼲扰来防⽌模型攻击。这可以通过检查模型的预测结果、性能或结构来实现。</li><li>检测后⻔攻击：通过检测模型是否包含后⻔来防⽌后⻔攻击。这可以通过检查模型的参数、训练数据或输⼊数据来实现。</li></ol><h4 id="数据保护"><a href="#数据保护" class="headerlink" title="数据保护"></a>数据保护</h4><ol><li>保护数据隐私：通过保护数据隐私来防⽌数据被泄露或滥⽤。这可以通过加密数据、保护数据隐私空间、限制数据访问等⽅式实现。</li><li>保护数据安全：通过保护数据安全来防⽌数据被篡改或损坏。这可以通过确保数据的完整性、⼀致性或可信度来实现。</li><li>保护数据可⽤：通过保护数据可⽤性来防⽌数据被删除或不可⽤。这可以通过备份数据、保证数据完整性、⼀致性等⽅式实现。</li></ol><h4 id="模型增强"><a href="#模型增强" class="headerlink" title="模型增强"></a>模型增强</h4><ol><li>增强模型安全性：通过增强模型安全性来防⽌模型被攻击或篡改。这可以通过增加模型参数、使⽤更安全的学习算法、增加模型复杂性等⽅式实现。</li><li>增强模型鲁棒性：通过增强模型鲁棒性来提⾼模型对噪声、⼲扰等攻击的抵抗⼒。这可以通过训练模型对噪声和⼲扰的鲁棒性、使⽤更稳定的计算器等实现。</li><li>增强模型可解释性：通过增强模型可解释性来提⾼模型决策过程的可理解和可信任度。这可以通过使⽤可解释性强的学习算法、对模型进⾏可视化等实现。</li></ol><h2 id="人工智能模型安全在信息系统安全中的应用"><a href="#人工智能模型安全在信息系统安全中的应用" class="headerlink" title="人工智能模型安全在信息系统安全中的应用"></a>人工智能模型安全在信息系统安全中的应用</h2>]]></content>
    
    
    <categories>
      
      <category>信息系统安全课程复习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>安全</tag>
      
      <tag>人工智能</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>冗余容错技术</title>
    <link href="/2024/12/14/%E5%86%97%E4%BD%99%E5%AE%B9%E9%94%99%E6%8A%80%E6%9C%AF/"/>
    <url>/2024/12/14/%E5%86%97%E4%BD%99%E5%AE%B9%E9%94%99%E6%8A%80%E6%9C%AF/</url>
    
    <content type="html"><![CDATA[<p>物理安全（实体安全）：是保护计算机设备、设施（网络及通信线路）免遭地震、水灾、火灾、有害气体和其他环境事故（如电磁污染等）破坏的措施和过程。</p><p>物理安全包括：环境安全、电源系统安全、设备安全和通信线路安全。</p><h2 id="冗余技术概述"><a href="#冗余技术概述" class="headerlink" title="冗余技术概述"></a>冗余技术概述</h2><p>冗余技术指的是通过添加备用组件或资源，使得即使出错或发生故障，系统的功能仍不受影响的技术。冗余可以用于硬件、软件和数据等多个层面，目的是为了增强系统的<strong>可靠性</strong>和<strong>可用性</strong>。  </p><ol><li>硬件冗余：在常规设计的硬件之外附加备份硬件，包括静态冗余、动态冗余</li><li>时间冗余：重复地执行指令或一段程序而附加额外的时间</li><li>信息冗余：增加信息的多余度，使其具有检错和纠错能力</li><li>软件冗余：用于测试、检错的外加程序</li></ol><h2 id="容错技术概述"><a href="#容错技术概述" class="headerlink" title="容错技术概述"></a>容错技术概述</h2><p>容错是指当系统发生故障时，系统能够自动检测并自动恢复以继续正常运行。容错技术不仅包括冗余，还包括故障检测、故障恢复和故障屏蔽等机制，确保系统在出现硬件故障、软件错误、网络问题或外部攻击时，仍能维持正常运行。  </p><p>容错技术：在发生故障或存在软件错误的情况下仍能继续正确完成指定任务的计算机系统是容错计算机系统。设计与分析容错计算机系统的各种技术称为容错技术。</p><p>实现容错技术的四个方面：</p><ol><li>不希望事件的检测（异常检测）</li><li>损坏估价（故障影响的范围）</li><li>不希望事件的恢复（从错误状态转为正确的系统状态）</li><li>不希望事件的处理和继续服务（在解决之后不会再次出现故障）</li></ol><p>容错技术的主要内容：故障检测、故障定位、故障诊断，故障屏蔽，冗余容错，信息保护技术</p><h2 id="冗余容错技术在信息系统安全中的应用"><a href="#冗余容错技术在信息系统安全中的应用" class="headerlink" title="冗余容错技术在信息系统安全中的应用"></a>冗余容错技术在信息系统安全中的应用</h2><p>容错主要依靠冗余设计来实现，它以增加资源的办法换取可靠性。由于资源的不同，冗余技术分为硬件冗余、软件冗余、时间冗余和信息冗余。</p><ol><li>硬件冗余：增加线路、设备、部件，形成备份（双机容错、双机热备份、RAID系统）；数据备份</li><li>软件冗余：增加程序，一个程序分别用几种途径编写，按一定方式执行，分段或多种表决（前向恢复的杀毒、后向恢复的系统还原、恢复块方法）</li><li>信息冗余：增加信息数据位数，检错纠错（奇偶校验、海明码、CRC循环冗余校验）</li><li>时间冗余：重复地执行指令或一段程序而附加额外的时间，程序回卷技术</li></ol><p>双机热备份：采用辅助系统作为主系统的热备份，正常状态下主系统工作，并对主系统进行故障检测和定位，一旦诊断出故障发生的位置，由闲置状态的备份系统接替。系统能进行自动修复，但正在处理的交易有可能丢失，从而导致数据的不一致。</p><p>程序回卷：在执行的程序中设置若干测试点，在每个测试点上检查输出结果。当测试程序检测出错误时，就认为正在执行的程序是一个错误的系统中运行的，这段程序要被重新执行，即程序的卷回。</p><p>奇偶校验：在数字通信系统中，奇偶校验通过设置规则来检查一组给定的位中1的数量。如果采用奇校验，那么每个数据单元（如字节）中1的总数必须是奇数；如果采用偶校验，则这些1的总数必须是偶数。在奇校验中如果数据单元中1的数量已经是奇数，则校验位设置为0；否则，校验位设置为1。在偶校验中如果数据单元中1的数量已经是偶数，则校验位设置为0；否则，校验位设置为1。发送方在数据末尾添加校验位，形成校验单元后发送。接收方收到数据后，重新计算校验位，并与接收到的校验位进行比对。如果两者相同，则认为数据传输正确；如果不同，则意味着在传输过程中出现了错误。</p>]]></content>
    
    
    <categories>
      
      <category>信息系统安全课程复习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>安全</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>PROVNINJA论文阅读</title>
    <link href="/2024/11/20/PROVNINJA%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"/>
    <url>/2024/11/20/PROVNINJA%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/</url>
    
    <content type="html"><![CDATA[<p>该论文提出了一个名为 <strong>PROVNINJA</strong> 的框架，用来设计和生成对抗性攻击，目的是规避基于系统溯源<strong>数据的机器学习检测器。系统溯源用于追踪系统中进程、文件、网络套接字等资源之间的操作和依赖关系，这些信息通过</strong>溯源图来表示。PROVNINJA的主要目标是伪装恶意行为，使它们看起来像正常系统操作，从而规避检测。</p><p><img src="https://cdn.nlark.com/yuque/0/2024/png/46744832/1728363715637-8e45fd21-7754-4328-ba74-b799609e6ec1.png"></p><h2 id="XliVX"> Introduction</h2>基于溯源的ML检测器分析系统中详细的运行时数据，通过检测异常行为来防御潜在的 APT 和无文件恶意软件等复杂攻击。然而，现有的基于溯源的ML检测器并未完全抵御攻击者可能使用的对抗性技术，攻击者可以设计看似正常的系统操作来绕过检测。这种情况下需要一个系统化的方法来生成对抗性攻击，使其既能够完成恶意目标，又能尽量不被检测器发现。<h2 id="I4E44">PROVNINJA的核心框架</h2>PROVNINJA通过三个关键阶段实现对抗性攻击的生成与实施：<h3 id="Gkur5"> 识别显眼事件</h3>显眼事件是指那些容易引起ML检测器注意的系统事件。这些事件可能具有以下特点：<ul><li>在系统中出现频率较低（稀有性高）。</li><li>对ML检测器的预测结果影响大。</li></ul><h4 id="ASPp1"> 频率分析</h4>PROVNINJA通过计算系统事件的**规则性评分（Regularity Score）**来判断事件的稀有程度。规则性评分的公式如下：<p><img src="https://cdn.nlark.com/yuque/0/2024/png/46744832/1728356583881-5460842d-8454-4719-9fcf-005055bd14aa.png"></p><p>通过计算每个事件的规则性评分，PROVNINJA可以识别出那些在系统活动中不常见的显眼事件，这些事件很容易引发检测器的警报。</p><h4 id="cvvfp">图结构分析</h4>1. 事件的传递性影响<p>在系统中，某些事件可能会通过一条长路径传播影响。一个显眼事件往往是那些能引发后续多个操作的事件。例如：</p><ul><li>如果进程A创建了进程B，而进程B执行了网络连接或修改了系统文件，那么进程A的行为会在之后通过进程B的操作对系统产生重大影响。</li><li>如果某个事件（如进程创建、文件读写）位于路径的关键位置，它不仅影响直接相连的节点，还可能通过多个中介节点传递影响到系统的其他部分。</li></ul><p>因此，具有<strong>广泛传递性</strong>的事件通常是显眼事件。攻击者可能希望通过替换这些事件来隐蔽攻击路径。</p><hr><ol start="2"><li>事件在路径中的位置</li></ol><p>在因果路径中，事件的相对位置非常重要。通常，<strong>位于因果路径关键位置</strong>的事件（例如路径的起点或中间位置）具有更高的显眼性，因为这些位置的事件可能直接影响后续事件的执行：</p><ul><li>如果某个事件发生在路径的起点，它通常是整个攻击链的触发点，且对于后续的攻击操作至关重要。</li><li>中间节点的事件（例如创建关键进程或修改重要文件）也可能是显眼的，因为它们连接了路径的不同阶段，起到了承前启后的作用。</li></ul><p>这些位置上的事件如果表现异常，就更容易被ML检测器捕捉到。</p><ol start="3"><li>路径的长度和复杂度</li></ol><p><strong>路径的长度和复杂度</strong>也是判断事件显眼性的一个重要指标。通常，越长的路径包含的操作和依赖关系越多，检测器可能会更加关注这类复杂路径中的关键节点和事件：</p><ul><li>如果某个事件位于一条长路径的中间，它的异常行为可能会被放大，因为它可能影响到路径的多个下游节点。</li><li>同样，如果一个路径包含多个高度依赖的节点或资源，这些资源之间的依赖关系越紧密，路径中的异常事件就越容易引起检测器的警觉。</li></ul><ol start="4"><li>节点和边的重要性（图结构分析）</li></ol><p>在因果路径分析中，除了事件本身的位置和传递性，还可以通过图的结构特性来分析事件的重要性。通过分析图中的<strong>节点和边的中心性</strong>，可以判断某个节点（事件）是否在整个系统图中起到关键作用。例如：</p><ul><li><strong>介数中心性（Betweenness Centrality）</strong>：介数中心性衡量一个节点在多条最短路径中的重要性。如果一个节点具有较高的介数中心性，说明该节点位于系统中多条重要路径的中间，连接着大量其他节点。这样的节点通常是显眼事件，因为它们控制着多个系统资源之间的交互。</li><li><strong>度数中心性（Degree Centrality）</strong>：一个节点的度数表示它与其他节点相连的边数。如果一个节点的度数很高（即它连接了许多其他节点），那么该节点可能是一个系统中高度活跃的资源。如果该节点的行为在系统中不常见，它可能成为显眼事件，因为它与系统中的多个资源有关联，且容易影响其他节点的行为。</li></ul><p>这些图结构分析可以帮助确定哪些事件在系统行为中起到至关重要的作用，从而可能引起检测器的重点关注。</p><h3 id="gL0XC">特征空间规避</h3>在特征空间规避中，PROVNINJA利用所谓的“**Gadget链**”来替换显眼事件。Gadget链是由一系列规则性较高的系统事件构成的，它们在系统中更加常见，因此替换后不会显得异常。<p>Gadget链的生成过程包括以下步骤：</p><ol><li><strong>寻找显眼事件的替代事件</strong>：PROVNINJA从“替代库”中寻找能够替代显眼事件的其他系统操作。替代事件必须符合两个条件：<ul><li>保持攻击者的目标不变。例如，如果攻击者需要创建一个恶意进程，替代事件也应能实现相似的操作。</li><li>替代事件应尽可能模仿正常的系统行为，避免引起检测器的警觉。</li></ul></li><li><strong>生成Gadget链</strong>：有时，单个替代事件不足以完成复杂的攻击任务。PROVNINJA可以通过多个Gadget链的组合来替换显眼事件，这些链条连接了一系列常见的系统操作，从而有效地掩盖了恶意行为。</li><li><strong>优化攻击路径</strong>：通过将显眼事件替换为更常见的事件，攻击路径在ML检测器看来更加像正常的系统活动。这样可以显著降低检测器对攻击的检测概率。</li></ol><p>在进行替换时，攻击者通过将显眼事件替换、攻击路径分散和路径加长（广度和深度）这些手段来混淆检测模型。</p><h3 id="hCY3Z">问题空间实现</h3>这是将特征空间中的规避策略转换为实际系统行为的过程，即将Gadget链应用于真实系统。在这个阶段，PROVNINJA的主要挑战是如何将理论上的规避方法应用到现实的复杂系统环境中。<p><strong>问题空间的实现面临以下几大挑战</strong>：</p><ol><li><strong>保持攻击语义</strong>：在进行攻击时，替代事件必须能够实现与原始显眼事件相同的恶意目标。例如，如果原本的恶意事件需要创建某个进程或修改某个文件，替代事件也必须具备类似功能，否则攻击目标将无法达成。</li><li><strong>处理系统环境差异</strong>：不同系统之间的配置和依赖关系可能会影响攻击实施。例如，一个系统在某个时间点的状态可能与在其他时间点有所不同，或系统运行的环境与攻击者的测试环境不一致，这些都可能影响攻击的实施。</li><li><strong>事件的可实现性</strong>：某些替代事件或Gadget链在攻击者的测试环境中可能可行，但在目标系统中却可能因为权限不足、系统配置差异等问题而无法实际实现。因此，PROVNINJA需要通过实际的系统环境进行校验，确保攻击路径的可执行性。</li></ol><h2 id="vRqkN">威胁模型</h2>PROVNINJA框架被设计用于不同类型的威胁模型，其中主要包括三种类型：<ul><li><strong>黑箱模型</strong>：攻击者无法直接访问或查询ML检测器的内部结构，但可以通过一些外部查询（如查询公开的程序执行频率）来推断系统行为。PROVNINJA在黑箱模型下主要依赖于从公开数据集中收集的行为数据，生成规避攻击。</li><li><strong>白箱模型</strong>：攻击者对ML检测器的内部工作机制有完全了解，包括模型的架构和参数。在这种情况下，PROVNINJA可以通过工具（如GNNExplainer）来识别哪些事件对ML检测器的决策贡献最大，从而设计更有针对性的攻击路径。</li><li><strong>盲箱模型</strong>：攻击者无法查询检测器，也无法获得系统的行为数据，只能基于公共数据集或对系统行为的推断来设计攻击。这是最为困难的模型。</li></ul>]]></content>
    
    
    <categories>
      
      <category>论文笔记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>安全</tag>
      
      <tag>入侵检测</tag>
      
      <tag>PIDS</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>IOT固件仿真测试方法</title>
    <link href="/2024/11/20/%E5%9F%BA%E4%BA%8E%E4%BB%BF%E7%9C%9F%E7%9A%84%E6%B5%8B%E8%AF%95%E6%96%B9%E6%B3%95/"/>
    <url>/2024/11/20/%E5%9F%BA%E4%BA%8E%E4%BB%BF%E7%9C%9F%E7%9A%84%E6%B5%8B%E8%AF%95%E6%96%B9%E6%B3%95/</url>
    
    <content type="html"><![CDATA[<h2 id="基于仿真的测试方法及其挑战"><a href="#基于仿真的测试方法及其挑战" class="headerlink" title="基于仿真的测试方法及其挑战"></a>基于仿真的测试方法及其挑战</h2><p>固件仿真是近年来的一项新兴技术。模拟器允许安全研究人员在没有硬件的情况下运行嵌入式软件。大多数动态测试通常都伴随着破坏性。例如，模糊测试会导致设备反复进入崩溃状态。因此，对于脆弱且昂贵的物联网设备，仿真和动态测试是一个有吸引力的解决方案。然而，成功的仿真并不像将固件导入仿真器那么简单。它将面临许多现实世界环境限制带来的挑战。例如，不统一的固件开发原则导致需要手动定制仿真固件所需的仿真器。此外，在模拟器上部署各种测试工具并测试正在运行的固件也具有挑战性。</p><p>进行仿真测试需要解决一下四个问题：</p><ol><li>获取固件；</li><li>外部硬件及外围设备；</li><li>大规模测试；</li><li>检测漏洞。</li></ol><h2 id="固件获取"><a href="#固件获取" class="headerlink" title="固件获取"></a>固件获取</h2><p>固件是整个仿真过程的关键。许多现有方法讨论如何进行仿真，但忽略了固件获取过程。为了保护产品的安全，大多数厂家并没有发布相关的固件。而且，物联网设备的各种调试端口被制造商封锁，以防止固件泄露。因此，获取目标固件具有挑战性。为了克服这一挑战，研究人员提出了以下不同的解决方案：</p><ol><li>互联网上有很多固件的镜像可以下载，但通常都并不完善；</li><li>固件进行更新时会下载最新固件到设备上，可以通过网络流量拦截的方式获取，但通常都会被加密或只是下载补丁而不是完整的固件。</li></ol><h2 id="外部硬件及外围设备"><a href="#外部硬件及外围设备" class="headerlink" title="外部硬件及外围设备"></a>外部硬件及外围设备</h2><p> 由于固件需要与特定的硬件外围设备交互，而这些外围设备在虚拟化器（如QEMU）中可能无法得到充分仿真，因此有些固件无法在虚拟环境中正常仿真。此外，许多设备都定制了自己的固件，导致其体系结构和内核标准不一致，使得仿真变得更加复杂和多样化。  因此分为部分仿真和完全仿真：</p><blockquote><ol><li>部分仿真<br>例子：嵌入式设备的固件分析</li></ol><p>假设你正在分析一个智能家居设备的固件，比如智能灯泡的固件。这个固件依赖于嵌入式硬件（如LED控制芯片、无线通信模块等）来实现其功能。使用部分仿真的方法，你可能只仿真固件的部分功能，比如固件的启动过程、操作系统的初始化或一些核心逻辑（如处理指令或控制灯泡开关的代码）。</p><p>部分仿真的一个常见做法是跳过固件中对特定硬件的调用，这些硬件在虚拟环境中无法被精确仿真。例如，QEMU 可能无法仿真无线通信模块。因此，部分仿真可以忽略或模拟这些外设的存在，而只聚焦于固件的软件部分，从而分析出设备的部分行为。</p><p>优势：这种方法能够快速获得关于固件的一些信息，而不需要精确仿真所有硬件。但它的局限性在于，无法分析固件与硬件的深层次交互，比如无法仿真出固件如何控制LED灯或与Wi-Fi模块通信的行为。</p><ol start="2"><li>完全仿真<br>例子：路由器固件的全仿真</li></ol><p>假设你正在对路由器固件进行安全分析。路由器的固件往往与多个外围设备交互，例如网卡、交换芯片、USB接口等。在这种情况下，完全仿真方法试图精确仿真固件与这些外设的所有交互。</p><p>例如，QEMU 通过仿真ARM架构，可以完整地仿真路由器固件的启动过程、驱动程序加载、网络接口初始化、无线网卡和交换芯片的工作流程等。为实现这一点，仿真环境可能需要定制设备模型，甚至模拟特定硬件的寄存器行为，以便精确还原固件的工作方式。</p><p>优势：完全仿真可以提供更高的精确度，特别适合进行复杂的固件安全分析或逆向工程研究。分析人员可以模拟设备的真实行为，包括固件如何与硬件协作。这有助于发现隐藏在硬件交互中的漏洞或后门，例如网络接口的安全漏洞或USB接口的未授权访问问题。</p></blockquote><h3 id="部分仿真"><a href="#部分仿真" class="headerlink" title="部分仿真"></a>部分仿真</h3><p>在嵌入式设备的漏洞挖掘中，由于外设的复杂性和硬件与软件的紧密结合，完全仿真往往困难重重。因此，部分仿真成为了解决这一问题的重要方法。以下是对 PROSPECT、AVATAR、SURROGATES 和 ECMO 等几种部分仿真方法的详细描述：</p><ol><li>PROSPECT<br>概述：<br>PROSPECT 是一个能够克服仿真外设困难的系统。它的核心思想是将固件对外设的硬件访问透明地从主机系统转发到虚拟机。这种转发机制使得嵌入式软件能够在虚拟环境中运行，而无需了解具体外设的操作细节。</li></ol><p>技术原理：<br>PROSPECT 的部分仿真工作流程如下：</p><p>在仿真器中，固件继续运行，并发出与外设的交互请求。这些请求通常是通过I&#x2F;O指令或存储器映射的外设访问实现的。<br>PROSPECT 将这些外设访问请求捕获并透明地转发到真实的外设硬件。外设硬件响应后，其结果会被返回给虚拟机中的固件，仿真器接收并处理该结果，就好像外设实际上是通过仿真器直接控制的一样。<br>应用场景：<br>PROSPECT 适用于那些固件深度依赖专有外设的场景，特别是复杂的嵌入式设备，如物联网设备或工业控制系统。通过这种透明转发机制，固件能够在不完全仿真外设的情况下运行，并保持其预期的功能行为。</p><ol start="2"><li>AVATAR<br>概述：<br>AVATAR 是一个仿真框架，它允许仿真器和真实外设硬件协同工作，以实现固件的动态分析。AVATAR 的核心理念是在仿真器中执行固件的同时，将I&#x2F;O访问请求转发给真实的嵌入式设备，从而提高仿真精度和性能。</li></ol><p>技术原理：<br>AVATAR 的工作机制包括：</p><p>I&#x2F;O 转发：当仿真器中运行的固件发出I&#x2F;O访问指令时，AVATAR 会将这些访问请求转发给真实的外设设备。例如，访问网络接口、存储设备或传感器。<br>动态优化：AVATAR 动态优化代码和数据在仿真环境和真实硬件之间的分布。仿真器处理固件的主要逻辑部分，而外设交互则委托给真实的嵌入式设备。这种分布优化使得仿真性能显著提高。<br>优势：<br>AVATAR 不仅能够提高仿真的效率，还可以在仿真中实现动态分析。它能够捕获固件的执行路径、检测潜在漏洞，并通过外设的真实行为进行测试。由于部分功能是在真实硬件上执行的，AVATAR 能够提供与完全仿真器无法实现的高精度分析。</p><ol start="3"><li>SURROGATES<br>概述：<br>SURROGATES 是基于 AVATAR 的进一步优化版本，它通过加强外部设备与固件的连接来提升仿真的效率和稳定性。SURROGATES 专注于解决仿真中常见的中断处理、DMA（直接内存访问）以及时钟同步等问题。</li></ol><p>技术原理：<br>SURROGATES 的关键创新点是使用了自定义的低延迟 FPGA 桥接器。它将宿主机的外围组件互连（PCI）总线与待测试系统连接起来，使得仿真器能够更加有效地访问固件的外设。</p><p>低延迟通信：FPGA 桥接器大大减少了仿真环境与真实外设之间的通信延迟，从而增强了仿真的实时性和精确性。<br>问题解决：SURROGATES 通过优化整个仿真系统，解决了以前仿真器中的常见问题，例如中断处理不准确、DMA 操作缺失以及时钟同步不良等。这使得仿真器在更复杂的环境中也能稳定运行。<br>应用场景：<br>SURROGATES 在需要极高仿真精度的场景中表现尤为突出。例如，它能够有效仿真高速数据传输设备，复杂的多设备通信系统等。通过优化外设的仿真和硬件访问，SURROGATES 能够支持更多类型的嵌入式设备仿真，并提高分析效率。</p><ol start="4"><li>ECMO<br>概述：<br>ECMO 是另一种基于部分仿真的系统，它提出了一种外设移植技术，目的是减少在QEMU等仿真器中手动添加外设仿真模型的复杂性。</li></ol><p>技术原理：<br>ECMO 的核心思想是将特定外设的驱动程序移植到目标固件的内核二进制文件中。它不需要为每个外设编写专门的仿真代码，而是通过将真实外设的驱动直接嵌入固件，使得仿真器能够更好地处理外设交互。</p><p>外设移植：ECMO 将外设的仿真模型和驱动程序移植到固件内核中，从而简化了复杂外设的仿真过程。这种方法使仿真器能够无缝访问外设，而不需要在仿真器中逐一实现每个外设的行为。<br>双组件移植：ECMO 通过将外设的仿真模型移植到 QEMU，同时将设备驱动程序移植到固件内核中，成功减少了手动仿真代码编写的需求。<br>优势：<br>ECMO 的移植技术有效解决了仿真中外设复杂性的瓶颈。它减少了在仿真器中逐个实现外设功能的需求，能够加快仿真开发的速度，并且能够更灵活地处理复杂的固件与外设交互。</p><p>总结<br>以上几种部分仿真方法通过不同的技术手段，解决了嵌入式设备外设仿真难的问题。PROSPECT 提供了透明的外设访问转发机制，AVATAR 通过动态优化提高了仿真效率，SURROGATES 通过低延迟硬件桥接器和系统优化增强了稳定性，而 ECMO 则通过外设驱动移植简化了仿真配置。这些方法的结合为嵌入式设备的固件分析和漏洞挖掘提供了强大的工具支持，尤其在无法完全仿真外设时，部分仿真成为了非常有效的替代方案。</p><h3 id="完全仿真"><a href="#完全仿真" class="headerlink" title="完全仿真"></a>完全仿真</h3><p>为了完全模拟固件，Firmadyne [22] 从设备中提取文件系统，并将其放入与 QEMU 一起运行的预编译通用 Linux 内核中。由于全仿真的可扩展性，Firmadyne 可以对目标固件进行大规模测试。 Firmadyne 在 69 个固件映像上发现了 14 个未知漏洞。 ARM-X[95]在仿真方面采用了与Fimadyne类似的思路，但需要用户提供更多的信息和配置。而且ARM-X只能用于ARM架构的设备，并且需要固件中的rootfs和NVRAM作为支持。 Pretender [63] 是一个在虚拟环境中自动重新托管各种嵌入式系统固件的框架。它记录物理硬件和固件之间的交互，然后使用这些记录通过机器学习来构建模型来描述每个外围设备。因此，Pretender可以完全将固件放置在虚拟化环境中，不需要保持对硬件设备的长期访问。</p><h2 id="大规模测试"><a href="#大规模测试" class="headerlink" title="大规模测试"></a>大规模测试</h2><p>在模型外围设备时，有些物联网设备系统没有外围设备，但有些系统可能连接到可编程逻辑控制器（PLC）、FPGA、传感器、数据库和许多其他外围设备。许多部分仿真方法通常需要手动操作，其中包括将方法扩展到大规模测试的繁重工程工作，因此会存在挑战性。</p><p>目前有多种方法来帮助进行大规模测试，Laelaps 引入符号执行协助外设仿真，可以在无需先验知识的情况下运行各种固件，但只能在短期执行（并不贯穿固件的整个运行，而是只在关键点执行），路径过长会存在依赖爆炸的问题。P2IM是一个无需硬件即可独立测试固件的软件框架。它抽象外围设备并根据自动生成的模型，动态处理固件 I&#x2F;O。它将目标固件及其内存映射作为输入，并通过将现成的模糊器（即 AFL）的输入提供给外围设备来模糊代码。</p><h2 id="检测漏洞"><a href="#检测漏洞" class="headerlink" title="检测漏洞"></a>检测漏洞</h2><h3 id="漏洞检测的挑战"><a href="#漏洞检测的挑战" class="headerlink" title="漏洞检测的挑战"></a>漏洞检测的挑战</h3><p>在虚拟环境中进行漏洞检测时，研究人员面临多个挑战。虽然仿真技术可以帮助更好地执行固件的安全分析，但由于各种限制，这些漏洞检测的应用仍然存在一定的困难。这些挑战包括：</p><ul><li>驱动程序中的错误处理代码难以触发，通常在极端情况下才会暴露漏洞。</li><li>某些物联网设备中嵌入的Web应用服务可能存在大量隐藏的安全漏洞。</li><li>针对设备与硬件交互边界的漏洞检测通常不涉及系统调用，难以在现有检测方法中被发现。</li></ul><h3 id="漏洞检测的技术与方法"><a href="#漏洞检测的技术与方法" class="headerlink" title="漏洞检测的技术与方法"></a>漏洞检测的技术与方法</h3><p>为了克服这些挑战，研究人员提出了以下几种主要技术和方法：</p><h4 id="（1）驱动程序中的错误处理检测（Error-Handling-in-Driver）"><a href="#（1）驱动程序中的错误处理检测（Error-Handling-in-Driver）" class="headerlink" title="（1）驱动程序中的错误处理检测（Error Handling in Driver）"></a>（1）<strong>驱动程序中的错误处理检测（Error Handling in Driver）</strong></h4><ul><li><strong>SymDrive</strong>：这一框架通过符号执行来测试Linux设备驱动程序。它使用静态分析与源代码转换，显著减少了测试新驱动程序时所需的手动调整工作。SymDrive会自动化检测固件中设备驱动程序的错误处理部分。</li><li><strong>IFIZZ</strong>：通过模糊测试来专门针对错误处理代码进行检测。它采用状态感知和受限错误生成的方式，有效地覆盖了更深的错误路径。</li><li><strong>FIFUZZ</strong>：这是另一个模糊测试框架，它通过上下文敏感的故障注入方法，能够在复杂触发场景下找到隐藏的深层次错误。</li></ul><h4 id="（2）Web接口漏洞检测（Web-Interface-Vulnerability-Detection）"><a href="#（2）Web接口漏洞检测（Web-Interface-Vulnerability-Detection）" class="headerlink" title="（2）Web接口漏洞检测（Web Interface Vulnerability Detection）"></a>（2）<strong>Web接口漏洞检测（Web Interface Vulnerability Detection）</strong></h4><ul><li><strong>FIRMADYNE</strong>：该框架通过自动化动态分析方法检测嵌入式固件中的内置Web应用服务漏洞。它通过仿真运行固件，并自动检测固件中Web接口的安全漏洞，如缓冲区溢出、命令注入等问题。</li><li><strong>FirmFuzz</strong>：一个专门为Linux固件设计的独立仿真与自动化动态分析框架。它使用基于灰盒的生成式模糊测试方法，结合静态分析和系统监控来检测固件中Web应用程序的漏洞。</li></ul><h4 id="（3）其他检测技术（Other-Detection-Techniques）"><a href="#（3）其他检测技术（Other-Detection-Techniques）" class="headerlink" title="（3）其他检测技术（Other Detection Techniques）"></a>（3）<strong>其他检测技术（Other Detection Techniques）</strong></h4><ul><li><strong>FIRM-AFL</strong>：通过增强的进程仿真技术来解决系统仿真中的性能瓶颈，并启用POSIX兼容的固件模糊测试。相比全系统仿真，FIRM-AFL的检测吞吐量平均提升了8.2倍。</li><li><strong>PeriScope</strong>：这一方法用于检测设备与硬件交互边界的漏洞。PeriScope通过挂钩固件内核的页面错误处理机制，检测和记录设备驱动与硬件之间的通信流量。它还引入了PeriFuzz框架，用于模拟针对外围设备的攻击。</li></ul><p>现在主要讨论驱动程序中的错误处理检测方法，详细分析 FIFUZZ 的具体实现。</p><p><img src="https://raw.githubusercontent.com/zy-Pioneer/BlogImage/main/img/2025/01/c9ca1e83.png"></p><h3 id=""><a href="#" class="headerlink" title=""></a></h3>]]></content>
    
    
    <categories>
      
      <category>论文笔记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>漏洞挖掘</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>P2IM:Scalable and Hardware-independent Firmware Testing via Automatic Peripheral Interface Modeling</title>
    <link href="/2024/11/15/P2IM_%20Scalable%20and%20Hardware-independent%20Firmware%20Testing%20via%20Automatic%20Peripheral%20Interface%20Modeling/"/>
    <url>/2024/11/15/P2IM_%20Scalable%20and%20Hardware-independent%20Firmware%20Testing%20via%20Automatic%20Peripheral%20Interface%20Modeling/</url>
    
    <content type="html"><![CDATA[<p>本文章旨在解决嵌入式固件的动态测试或模糊测试由于硬件依赖性和扩展性差所带来的挑战，使得可以进行大规模模糊测试。</p><h3 id="主要内容摘要："><a href="#主要内容摘要：" class="headerlink" title="主要内容摘要："></a>主要内容摘要：</h3><p><strong>研究问题：</strong> 该论文聚焦于嵌入式固件模糊测试的限制，尤其是硬件依赖性问题。传统模糊测试工具虽然在通用计算机系统上表现良好，但由于嵌入式系统中硬件外设的多样化和限制，使得它们难以直接应用于 MCU 固件的测试。</p><p><strong>解决方案：</strong> 作者提出了一个名为 P2IM（处理器-外设接口建模）的框架，用于硬件无关且具有可扩展性的固件测试。P2IM 通过自动建模不同外设的 I&#x2F;O 行为来抽象外设操作，使固件能够在不依赖真实硬件的情况下运行，从而可以在标准模糊测试工具（如 AFL）和处理器仿真器（如 QEMU）中对固件进行测试。</p><h3 id="方法论："><a href="#方法论：" class="headerlink" title="方法论："></a>方法论：</h3><ul><li><strong>处理器-外设接口建模（P2IM）：</strong> 论文的核心创新是 P2IM，它通过抽象外设的行为，使模糊测试工具能够像与真实硬件交互一样与固件交互。框架通过生成外设接口的模型，允许固件通过通用处理程序与仿真外设交互。</li><li><strong>模型实例化：</strong> 框架在运行时自动为特定固件生成抽象模型，并通过“探索性执行”技术识别外设寄存器的访问方式，并根据固件的需要动态调整模型。</li><li><strong>中断管理：</strong> 论文还提出了一种无需真实硬件即可处理中断的新方法，将中断触发抽象为特殊输入，可以自定义定时和行为以模拟硬件的操作。</li></ul><h3 id="P2IM-具体实现："><a href="#P2IM-具体实现：" class="headerlink" title="P2IM 具体实现："></a>P2IM 具体实现：</h3><h4 id="寄存器类型判断"><a href="#寄存器类型判断" class="headerlink" title="寄存器类型判断"></a>寄存器类型判断</h4><p>仿真器将内存映射为寄存器，因此要判断每个内存区域（寄存器）的类型， 通过固件在运行时与寄存器的交互行为来推断：</p><ol><li>监控固件的寄存器访问<br>P2IM会在固件执行过程中，监控固件对特定地址范围（通常是内存映射的外设寄存器区域）的访问行为。这包括：<ul><li>读取操作：固件从某个寄存器中读取数据时，P2IM会记录读取的次数、读取的时机，以及固件是否依赖这些数据做出进一步决策。</li><li>写入操作：固件向某个寄存器写入数据时，P2IM会记录写入的数值、频率，以及这些写入操作是否影响固件的执行流或外设状态。</li></ul></li><li>分类和标记寄存器类型<br>基于监控到的访问行为，P2IM对寄存器进行分类和标记。不同类型的寄存器具有不同的访问模式：<ul><li>控制寄存器：如果固件对某个寄存器经常进行写操作，且写入的值通常是用于配置外设状态（例如启用某个功能或设置操作模式），P2IM会将其标记为控制寄存器。</li><li>状态寄存器：如果固件对某个寄存器频繁进行读取操作，并且这些读取操作用于检查外设的状态（例如是否完成某项操作），则P2IM会将该寄存器标记为状态寄存器。</li><li>数据寄存器：如果固件对某个寄存器进行读写操作且该寄存器用于传递实际的数据（例如传感器测量结果或通信数据），P2IM会将其标记为数据寄存器。</li></ul></li><li>探索性执行进行验证<br>在分类的初步推断过程中，P2IM使用探索性执行技术来验证这些推断是否准确。通过暂停固件的执行，P2IM可以尝试向某个寄存器写入或读取不同的值，然后观察固件的反应：<ul><li>如果固件继续执行并进入正确的操作路径（例如完成了一次外设操作或处理了一个中断），P2IM就可以确认这种访问模式是合理的，并且该寄存器的功能得到了正确推断。</li><li>如果固件进入错误路径或卡死，P2IM会调整其推断并尝试其他可能的访问模式，直到找到一个能让固件正常执行的正确模式。</li></ul></li><li>动态调整模型<br>随着固件的执行，P2IM会不断根据固件的行为动态调整寄存器模型。例如，如果固件在不同的上下文中以不同方式访问相同的寄存器（例如在初始化阶段作为控制寄存器，运行阶段作为状态寄存器），P2IM会根据固件的操作动态调整该寄存器的类型和行为。</li></ol><h4 id="探索性执行"><a href="#探索性执行" class="headerlink" title="探索性执行"></a>探索性执行</h4><p>在判断完成之后，就要确定每次交互时寄存器的值，具体如下：</p><ol><li><strong>暂停固件执行并快照保存状态</strong>：当固件在运行过程中访问状态寄存器（例如轮询等待某个外设状态变化）时，如果P2IM未事先为该寄存器建模，它会暂时暂停固件的执行，并对固件当前的状态进行快照保存。这包括保存当前的寄存器状态、堆栈信息和其他固件运行的上下文，以便在探索性执行完成后能够恢复到这一点继续执行。</li><li><strong>生成候选寄存器值</strong>：在暂停固件后，P2IM会生成一组可能的寄存器值（即<strong>候选值</strong>），每个值代表一种潜在的外设状态。例如，对于一个32位的状态寄存器，P2IM可能会生成32个不同的值，每个值只设置一个位为1，其他位为0，外加一个全为0的初始状态。这些候选值反映了寄存器中不同位的可能状态组合。</li><li><strong>并行执行探索分支</strong>：P2IM会为每一个候选寄存器值创建一个并行的执行分支（即<strong>工作线程</strong>）。在每个分支中，固件会使用这个候选值继续执行。P2IM会监控每个分支的执行进度，跟踪固件是否能够通过内部检查并继续正常运行。<ol><li><strong>并行性</strong>：这些探索分支是并行执行的，每个分支尝试不同的寄存器值，模拟固件在不同外设状态下的行为。</li><li><strong>监控执行结果</strong>：P2IM监控各个分支的执行情况，重点关注固件是否因不合理的状态值而崩溃、卡死，或者无法继续执行。</li></ol></li><li><strong>判断分支的有效性</strong> 在每个分支执行一段时间后，P2IM会评估其有效性。具体来说，P2IM会判断以下几点：<ol><li><strong>固件是否崩溃或卡死</strong>：如果某个候选寄存器值导致固件崩溃或无法继续执行，该分支将被视为无效。</li><li><strong>固件是否通过了内部检查</strong>：如果某个分支的寄存器值使固件成功通过了状态检查并继续运行，该分支将被视为有效。</li></ol></li><li><strong>选择最佳寄存器值</strong> P2IM会根据各个分支的执行结果选择<strong>最佳寄存器值</strong>。通常情况下，最佳值是能够使固件继续执行并触发预期的外设操作的值。P2IM可能会依据以下标准来选择最佳值：<ol><li><strong>固件成功执行的程度</strong>：固件继续执行的路径是否符合预期。</li><li><strong>触发的外设操作</strong>：固件是否成功与外设交互，例如从寄存器中读取数据或者处理中断。</li></ol></li><li><strong>恢复固件执行</strong> 一旦P2IM确定了最佳的寄存器值，它会将该值应用到状态寄存器中，并恢复固件的执行，继续从暂停点运行。固件此时将以被探索性执行选择的值作为外设状态，从而继续其预期的操作。</li><li><strong>动态调整模型</strong> 当探索性执行成功推断出某个寄存器的合理值后，P2IM会将此信息添加到模型中，用于后续的执行。如果固件再次访问该寄存器，P2IM可以直接返回已确定的正确值，而不必重新进行探索性执行。这使得模型随着固件的执行不断完善，越来越准确地模拟外设的行为。</li></ol><h3 id="关键成果："><a href="#关键成果：" class="headerlink" title="关键成果："></a>关键成果：</h3><ul><li><strong>可扩展性：</strong> P2IM 成功在没有人工干预的情况下运行了 70 个固件样本中的 79%，表明该框架具备良好的可扩展性，能够处理各种固件。</li><li><strong>漏洞发现：</strong> 在 10 个真实固件样本上进行的有限模糊测试中，框架发现了 7 个此前未知的漏洞，展示了其在提高固件安全性方面的潜力。</li></ul><h3 id="结论："><a href="#结论：" class="headerlink" title="结论："></a>结论：</h3><p>P2IM 是硬件无关固件测试的显著进步，提供了一个可扩展的解决方案，弥合了传统模糊测试工具与 MCU 固件之间的差距。该方法有望在提高 IoT 设备固件安全性方面发挥重要作用，帮助减少未经过充分测试的固件带来的安全风险。</p>]]></content>
    
    
    <categories>
      
      <category>论文笔记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>漏洞挖掘</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>神经网络调参技巧</title>
    <link href="/2024/11/14/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%B0%83%E5%8F%82%E6%96%B9%E6%B3%95/"/>
    <url>/2024/11/14/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%B0%83%E5%8F%82%E6%96%B9%E6%B3%95/</url>
    
    <content type="html"><![CDATA[<h2 id="调参顺序"><a href="#调参顺序" class="headerlink" title="调参顺序"></a>调参顺序</h2><p>第一个要进行调整的参数就是学习率，需要设置一个好的初始学习率，它可以决定损失函数的降低速度以及损失函数的最低位置。通常从 0.01 开始，**范围从 [1e-6,1e-1]**，通常只选择 1e<sup>n</sup> 。</p><p>学习率优化器是针对每个参数进行调整的，学习率调度器是对全局的学习率进行调整的。</p><table><thead><tr><th><strong>学习率调度器</strong></th><th><strong>学习率优化器</strong></th><th><strong>组合优势</strong></th><th><strong>适用场景</strong></th></tr></thead><tbody><tr><td><strong>StepLR</strong></td><td>SGD, Adam</td><td>定期减小学习率，简单高效，防止过拟合</td><td>大多数监督学习任务，如分类、回归任务</td></tr><tr><td><strong>ReduceLROnPlateau</strong></td><td>SGD, Adam</td><td>自适应调节学习率，基于验证损失自动减少，避免学习率过小</td><td>验证集性能停滞的任务，如回归、复杂的模型训练</td></tr><tr><td><strong>ExponentialLR</strong></td><td>SGD, Adam, RMSprop</td><td>指数衰减学习率，快速收敛，减少训练时间</td><td>快速收敛场景，适合较大规模数据集</td></tr><tr><td><strong>CosineAnnealingLR</strong></td><td>SGD, Adam</td><td>平滑衰减学习率，避免震荡，适合长时间训练</td><td>长期训练的大型深度神经网络，如卷积神经网络</td></tr><tr><td><strong>CyclicLR</strong></td><td>Adam, RMSprop</td><td>周期性调整学习率，跳出局部最优，稳定优化</td><td>复杂优化任务，如生成对抗网络（GAN）、深度强化学习</td></tr><tr><td><strong>OneCycleLR</strong></td><td>Adam, SGD</td><td>先增大学习率，后逐渐减小，快速找到最优解</td><td>快速训练大规模神经网络，如图像分类、NLP大模型</td></tr><tr><td><strong>LambdaLR</strong></td><td>任意优化器</td><td>完全自定义学习率变化策略，灵活可控</td><td>特定需求场景，无法用其他调度器满足的情况</td></tr><tr><td><strong>MultiStepLR</strong></td><td>SGD, Adam</td><td>在特定里程碑时减少学习率，适合多阶段训练</td><td>长期训练的任务，如卷积神经网络、阶段性改进模型性能</td></tr></tbody></table><h2 id="过拟合缓解措施"><a href="#过拟合缓解措施" class="headerlink" title="过拟合缓解措施"></a>过拟合缓解措施</h2><table><thead><tr><th><strong>方法</strong></th><th><strong>原理</strong></th><th><strong>适用场景</strong></th><th><strong>优势</strong></th><th><strong>使用场景</strong></th></tr></thead><tbody><tr><td><strong>L2 正则化</strong></td><td>在损失函数中加入权重的平方和作为惩罚项，防止权重过大</td><td>大多数神经网络，尤其是复杂的深度模型</td><td>减少权重过大，提升模型的泛化能力</td><td>数据量大、模型复杂，可能出现过拟合的场景</td></tr><tr><td><strong>L1 正则化</strong></td><td>在损失函数中加入权重的绝对值和作为惩罚项，倾向于使部分权重趋近于零</td><td>稀疏模型、特征选择</td><td>实现特征选择，简化模型</td><td>需要稀疏性或特征选择的任务，如文本分类</td></tr><tr><td><strong>Dropout</strong></td><td>训练时随机丢弃部分神经元，减少神经元间共适应性</td><td>深度神经网络，尤其是全连接层较多的模型</td><td>提升泛化能力，减少共适应性</td><td>卷积神经网络（CNN）、循环神经网络（RNN）</td></tr><tr><td><strong>早停法（Early Stopping）</strong></td><td>监控验证集性能，当性能不再提升时停止训练</td><td>所有深度学习任务，特别是长时间训练的任务</td><td>节省训练时间，防止过拟合</td><td>长时间训练的任务，如大型神经网络、语言模型</td></tr><tr><td><strong>数据增强</strong></td><td>通过随机变换训练数据（如翻转、裁剪等）增加数据的多样性</td><td>图像分类、时间序列处理等</td><td>增强数据集多样性，提高模型泛化能力</td><td>图像分类（翻转、旋转）、语音处理（噪声增强）</td></tr><tr><td><strong>Batch Normalization</strong></td><td>对每层的激活值进行标准化处理，使输入具有稳定的分布</td><td>深层神经网络，如卷积神经网络和循环神经网络</td><td>加速收敛，防止过拟合，训练更稳定</td><td>深层模型（如ResNet、VGG等），用于加速训练和稳定</td></tr><tr><td><strong>减少模型复杂度</strong></td><td>减少模型的参数量（如降低网络层数、神经元数）</td><td>小数据集、简单任务</td><td>通过简化模型结构减少过拟合风险</td><td>数据较少、简单任务，如小型图像分类任务</td></tr><tr><td><strong>交叉验证</strong></td><td>将数据划分为多个子集，循环验证模型性能</td><td>小数据集、模型调参</td><td>多次训练提高模型评估的稳定性</td><td>小数据集，模型调优，避免单次训练评估误差的场景</td></tr><tr><td><strong>添加噪声</strong></td><td>在输入、隐藏层或输出层添加噪声，增加模型的训练难度</td><td>时间序列、音频处理任务</td><td>增强模型鲁棒性，防止过拟合</td><td>语音、时间序列等，模型需要适应噪声的场景</td></tr><tr><td><strong>调节批次大小</strong></td><td>使用较小的批次大小，增加训练中的随机性</td><td>深度学习模型，特别是CNN和RNN模型</td><td>小批次能有效提升模型的泛化能力</td><td>大规模数据处理，小批次可能提升泛化效果的场景</td></tr><tr><td><strong>正则化项</strong></td><td>在损失函数中添加特定任务的自定义正则化项</td><td>特定任务，如有特定约束的模型</td><td>更好地控制模型的复杂性</td><td>有明确的任务约束，如控制输出范围的场景</td></tr></tbody></table>]]></content>
    
    
    <categories>
      
      <category>技术分享</category>
      
    </categories>
    
    
    <tags>
      
      <tag>深度学习</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Incorporating Gradients to Rules_ Towards Lightweight, Adaptive Provenance-based Intrusion Detection</title>
    <link href="/2024/10/29/CAPTAIN%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"/>
    <url>/2024/10/29/CAPTAIN%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/</url>
    
    <content type="html"><![CDATA[<p>本文提出了一种名为CAPTAIN的基于规则的溯源入侵检测系统，该系统旨在解决现有PIDS面临的高误报率和难以适应不同环境等问题。</p><h2 id="motivation"><a href="#motivation" class="headerlink" title="motivation"></a>motivation</h2><h3 id="“Grey”-Nodes"><a href="#“Grey”-Nodes" class="headerlink" title="“Grey” Nodes"></a>“<strong>Grey” Nodes</strong></h3><p>随着云计算的普及，很多合法的网络连接和云服务（如AWS Lambda、Cloudflare Workers）被广泛使用，但攻击者也可以利用这些服务作为其命令与控制（C2）服务器的中介。这使得现有的基于规则的PIDS难以区分合法与恶意的外部IP连接。传统系统通常会根据简单的信任度规则对节点进行分类，但过于粗糙的规则往往会导致误报或漏报。</p><ul><li><strong>解决方案动机：</strong> CAPTAIN通过引入更细粒度的标签（如将节点信任度设置为0到1之间的浮点数），能够更灵活地反映不同程度的信任，从而避免误报或漏报。</li></ul><h3 id="依赖爆炸问题-Dependency-Explosion"><a href="#依赖爆炸问题-Dependency-Explosion" class="headerlink" title="依赖爆炸问题 (Dependency Explosion)"></a><strong>依赖爆炸问题 (Dependency Explosion)</strong></h3><p>依赖爆炸是指单个可疑事件可能导致大量系统实体被标记为可疑，尤其是在复杂的依赖链中。一个恶意事件可能引发整个依赖链上的实体被怀疑为恶意，而很多情况下这些实体其实是正常的。现有的解决方案大多采用简单的事件白名单或手动划分攻击阶段，但这些方法往往需要大量的应用程序&#x2F;操作系统的调试，无法在实际系统中大规模使用。</p><ul><li><strong>解决方案动机：</strong> CAPTAIN通过引入可调节的标签传播速率（Tag Propagation Rate），允许根据事件的类型和上下文来调整恶意标签的传播力度，从而防止不必要的传播引发依赖爆炸。</li></ul><h3 id="自定义警报触发问题-Customized-Alarm-Triggering"><a href="#自定义警报触发问题-Customized-Alarm-Triggering" class="headerlink" title="自定义警报触发问题 (Customized Alarm Triggering)"></a><strong>自定义警报触发问题 (Customized Alarm Triggering)</strong></h3><p>现有的基于规则的PIDS在触发警报时，通常对所有事件应用统一的规则和阈值。然而，在不同的情境下，同一种行为可能是正常的或恶意的。例如，<code>sshd</code>进程执行脚本是常见的行为，而<code>firefox</code>进程执行脚本则是异常的。传统的规则系统无法为不同的事件设定不同的阈值，从而容易导致漏报或误报。</p><ul><li><strong>解决方案动机：</strong> CAPTAIN引入了自适应警报触发机制，允许为不同的事件和进程设置特定的警报触发阈值，以区分正常行为和异常行为。通过这种自定义的阈值，CAPTAIN能够减少不必要的警报，并提高对异常行为的敏感性。</li></ul><h2 id="CAPTAIN-系统设计"><a href="#CAPTAIN-系统设计" class="headerlink" title="CAPTAIN 系统设计"></a>CAPTAIN 系统设计</h2><p><img src="https://cdn.nlark.com/yuque/0/2024/png/46744832/1728365003605-d50496fe-3e23-4efe-a5f2-69526c0e18a8.png"></p><p>CAPTAIN系统的设计主要分为两个部分：</p><ul><li><strong>检测模块（Detection Module）</strong>：负责处理审计日志，生成溯源图并进行实时入侵检测。</li><li><strong>学习模块（Learning Module）</strong>：在训练阶段对检测模块进行优化，通过梯度下降算法自动调整自适应参数，以减少误报并提高检测精度。</li></ul><h3 id="检测模块的设计"><a href="#检测模块的设计" class="headerlink" title="检测模块的设计"></a><strong>检测模块的设计</strong></h3><p>检测模块的核心功能是通过标签传播对系统实体（进程、文件、网络连接等）进行实时监控和检测。该模块分为以下三个主要组件：</p><h4 id="标签初始化（Tag-Initialization）"><a href="#标签初始化（Tag-Initialization）" class="headerlink" title="标签初始化（Tag Initialization）"></a><strong>标签初始化（Tag Initialization）</strong></h4><p>CAPTAIN为每个系统实体分配初始的安全标签。具体来说：</p><ul><li>**数据标签 (Data Tags)**：表示系统实体的机密性和完整性。</li><li>**代码标签 (Code Tags)**：仅用于进程，表示进程代码的可信度。</li></ul><p>系统实体首次出现在溯源图时，会根据其特征（如进程名、文件路径、IP地址等）分配初始标签。标签初始化的具体规则由自适应参数 <strong>A</strong> 决定，而该参数会在训练阶段根据反馈进行调整。</p><h4 id="标签传播（Tag-Propagation）"><a href="#标签传播（Tag-Propagation）" class="headerlink" title="标签传播（Tag Propagation）"></a><strong>标签传播（Tag Propagation）</strong></h4><p>当系统中发生事件时，CAPTAIN会根据预定义的规则在节点之间传播标签。传播的方式有两种：</p><ul><li><strong>数据流传播</strong>：数据从源节点传播到目标节点（如进程读取文件时，文件的标签会影响进程的标签）。</li><li><strong>控制流传播</strong>：进程间的交互也会传播标签（如进程执行另一个进程时，代码的可信度会传播）。</li></ul><p>标签传播的强度由 <strong>传播速率参数 (G)</strong> 控制。CAPTAIN可以为每条边设置不同的传播速率，以防止标签不必要地过度传播，特别是在应对“依赖爆炸”问题时，传播速率的自适应调整尤为关键。</p><h4 id="警报生成（Alarm-Generation）"><a href="#警报生成（Alarm-Generation）" class="headerlink" title="警报生成（Alarm Generation）"></a><strong>警报生成（Alarm Generation）</strong></h4><p>CAPTAIN系统会根据标签的变化触发安全警报。当标签传播到某个节点，并且该节点的标签值超过了设定的阈值时，就会触发相应的警报。警报触发规则由 <strong>阈值参数 (T)</strong> 控制，可以根据不同的事件类型和实体特征调整触发阈值。</p><p>例如：</p><ul><li>当进程试图执行低完整性的代码时，系统可能会触发代码完整性相关的警报。</li><li>当进程访问高机密性的数据时，系统会触发数据泄漏警报。</li></ul><p>CAPTAIN能够为不同类型的系统事件设置灵活的阈值，从而减少误报，同时确保检测到真正的威胁。</p><h3 id="学习模块的设计"><a href="#学习模块的设计" class="headerlink" title="学习模块的设计"></a><strong>学习模块的设计</strong></h3><p>CAPTAIN的学习模块负责在训练阶段优化标签传播和警报触发的参数。通过对误报数据进行分析，该模块使用<strong>梯度下降算法</strong>来调整自适应参数（A, G, T），从而改进检测模块的性能。学习模块的主要功能包括：</p><h4 id="损失函数的定义（Loss-Function）"><a href="#损失函数的定义（Loss-Function）" class="headerlink" title="损失函数的定义（Loss Function）"></a><strong>损失函数的定义（Loss Function）</strong></h4><p>学习模块使用一个损失函数来衡量系统的检测效果。损失函数由两部分组成：</p><ul><li><strong>误报项</strong>：用于惩罚错误触发的警报。如果某个事件不应触发警报但触发了，该项会增加损失值。</li><li><strong>正则化项</strong>：用于避免系统过度宽松，确保系统对恶意活动仍然保持敏感。通过将当前参数与默认初始值之间的差距最小化，CAPTAIN能够在减少误报的同时保持对攻击的敏感性。</li></ul><h4 id="梯度计算（Gradient-Calculation）"><a href="#梯度计算（Gradient-Calculation）" class="headerlink" title="梯度计算（Gradient Calculation）"></a><strong>梯度计算（Gradient Calculation）</strong></h4><p>CAPTAIN将检测过程建模为可微分的函数，以便在训练过程中计算自适应参数的梯度。通过这些梯度，系统能够使用梯度下降算法不断更新参数，从而优化标签传播和警报生成规则。</p><p>例如：</p><ul><li>对于节点的初始标签（A）的梯度，系统根据标签如何传播来调整初始值，以减少误报。</li><li>对于边的传播速率（G），系统通过传播链上各节点的行为来计算传播速率的梯度，从而控制信息在系统中的传播程度。</li><li>对于警报阈值（T），梯度用于调整系统对不同事件的敏感性，避免过多或过少的警报触发。</li></ul><h4 id="训练与测试流程"><a href="#训练与测试流程" class="headerlink" title="训练与测试流程"></a><strong>训练与测试流程</strong></h4><p>在训练阶段，CAPTAIN会基于良性数据进行训练。训练的结果是生成一个优化的自适应参数配置。在测试阶段，系统根据训练得出的最优参数对新的系统事件进行实时检测。</p><h3 id=""><a href="#" class="headerlink" title=""></a></h3>]]></content>
    
    
    <categories>
      
      <category>论文笔记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>安全</tag>
      
      <tag>入侵检测</tag>
      
      <tag>PIDS</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>AMCNet阅读笔记</title>
    <link href="/2024/08/15/AMCNet%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"/>
    <url>/2024/08/15/AMCNet%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/</url>
    
    <content type="html"><![CDATA[<h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>动态链接预测（在动态图中，预测两个点在时间t是否存在边）关注两个信息：结构信息和时间信息。现有工作要么只考虑其中一个因素，要么两个因素都单独考虑而没有将它们联系起来，忽略了两者之间的关联性。</p><p>因此本文提出了一种方法，<strong>多尺度注意力协同进化网络（Attentional Multi-scale Co-evolving Network）</strong>，使用多层次注意力机制的序列到序列的模型（<strong>sequence-to-sequence</strong>）来学习不同层次之间的动态变化的内在关系。</p><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p><img src="https://raw.githubusercontent.com/zy-Pioneer/BlogImage/main/img/2025/01/9a2f5847.png"></p><p>本文中将图中的结构分为三个层次：</p><ul><li>微观层次（Microscopic structure）：图中的节点和边</li><li>中观层次（Mesoscopic structure）：图中的子图或者社区</li><li>宏观层次（Macroscopic structure）：整张图</li></ul><p>本文认为网络是由个体及其相互联系构成的，因此宏观时间动态自然取决于每个个体如何选择与他人建立联系的微观时间动态。另一方面，研究表明，人类行为受到社会关系的动态影响，例如政治取向、音乐品味，甚至人们如何选择新朋友。（中观影响微观，微观影响中观和宏观）</p><h3 id="contribution"><a href="#contribution" class="headerlink" title="contribution"></a>contribution</h3><ul><li>设计了多层次表示学习模块（通过GNN学习到节点表示，再通过节点表示来设计pooling表示中观和宏观），为了表示中观，提出了一个<code>motifs</code>的概念</li><li>提出了一个多层次协同进化模型来学习每个层次的动态特征</li><li>为了了解不同结构尺度的时间动态之间的内在相关性，通过一种新颖的基于注意力的分层模型，利用较高尺度的表示来指导较低尺度表示的学习过程。</li></ul><blockquote><p>motifs简介</p><p>motifs是一种模式，如下图所示：</p><p><img src="https://raw.githubusercontent.com/zy-Pioneer/BlogImage/main/img/2025/01/d203283f.png"></p><p>它表示一种子图结构，如何去判定一个子图结构是否为motif呢？有两个指标：频率和重要性。</p><p>频率指的是它在图中出现的频率，重要性通过随机构造一张随机图，判断真实图种motif出现的频率和随机图出现的频率的差异来判断重要性，差异越大，越重要</p><p>这个motif的发现有现成的工作来做，本文中并没有涉及构造motif的代码，它直接用了</p></blockquote><h2 id="method"><a href="#method" class="headerlink" title="method"></a>method</h2><p><img src="https://raw.githubusercontent.com/zy-Pioneer/BlogImage/main/img/2025/01/f7a04ef9.png"></p><p>整个架构分为两部分：</p><ol><li><strong>multiscale representation learning module</strong></li><li><strong>multi-scale evolving module.</strong></li></ol><h3 id="Multi-scale-Representation-Learning"><a href="#Multi-scale-Representation-Learning" class="headerlink" title="Multi-scale Representation Learning"></a>Multi-scale Representation Learning</h3><h4 id="Microscopic-Representation"><a href="#Microscopic-Representation" class="headerlink" title="Microscopic Representation"></a>Microscopic Representation</h4><p>用GAT来生成节点表示（就是MAGIC的骨架网络）</p><h4 id="Mesoscopic-Representation"><a href="#Mesoscopic-Representation" class="headerlink" title="Mesoscopic Representation"></a>Mesoscopic Representation</h4><p>作者一开始尝试，通过对motifs中的节点做平均池化来获得中观表示，但是效果不好，因此不单纯的做平均，加上了一个可学习的参数矩阵来为每个motif作为注意力参数</p><p><img src="https://raw.githubusercontent.com/zy-Pioneer/BlogImage/main/img/2025/01/a089c176.png"></p><p><img src="https://raw.githubusercontent.com/zy-Pioneer/BlogImage/main/img/2025/01/faf0efb3.png"></p><p>但是很奇怪，根据公式三，这样得到的表示不就是一个值了吗，我以为是每个motif都计算一个值作为中观表示</p><h4 id="Macroscopic-Representation"><a href="#Macroscopic-Representation" class="headerlink" title="Macroscopic Representation"></a>Macroscopic Representation</h4><p>全局的宏观表示就是将所有节点的特征平均一下：</p><p><img src="https://raw.githubusercontent.com/zy-Pioneer/BlogImage/main/img/2025/01/7dd9d57b.png"></p><h3 id="Multi-scale-Co-evolving-module"><a href="#Multi-scale-Co-evolving-module" class="headerlink" title="Multi-scale Co-evolving module"></a>Multi-scale Co-evolving module</h3><p>本文提出了两个观点：</p><ol><li>首先，从信息论的角度来看，数据中的噪声量和信息聚合水平通常呈负相关。结构层次越高，信息越少，噪声也越小。因此，较高结构尺度的时间动态比较低结构尺度更可预测。因此，较高尺度的预测有助于纠正较低尺度预测的潜在系统偏差，这对学习模型施加了尺度不变的约束。</li><li>其次，不同结构尺度的信息捕获了图的不同特征，从而相互补充。对不同尺度的时间动态进行联合建模使模型能够利用来自不同上下文范围的信息来进行预测。</li></ol><h4 id="Impletation"><a href="#Impletation" class="headerlink" title="Impletation"></a>Impletation</h4><p><strong>Sequence to Sequence Backbone：</strong>使用序列模型来捕获每个层次的数据的内在结构，设计了三个：</p><ol><li><strong>seq-seq-node：</strong>Seq2Seq_Attention(enc, dec, dev)</li><li><strong>seq-seq-motif：</strong>Seq2Seq_Attention(enc, dec, dev)</li><li><strong>seq-seq-graph：</strong>Seq2Seq(enc, dec, dev)</li></ol><p>从graph层次开始，graph指导motif，motif指导node：</p><p><img src="https://raw.githubusercontent.com/zy-Pioneer/BlogImage/main/img/2025/01/b681fa65.png"></p><p>其中<strong>seq2seq:</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Seq2Seq</span>(torch.nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, encoder, decoder, device</span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        <span class="hljs-variable language_">self</span>.encoder = encoder<br>        <span class="hljs-variable language_">self</span>.decoder = decoder<br>        <span class="hljs-variable language_">self</span>.device = device<br>        <span class="hljs-keyword">assert</span> encoder.hidden_size == decoder.hidden_size, <span class="hljs-string">&quot;Hidden dimensions of encoder and decoder must be equal!&quot;</span><br>        <span class="hljs-keyword">assert</span> encoder.n_layers == decoder.n_layers,       <span class="hljs-string">&quot;Encoder and decoder must have equal number of layers!&quot;</span><br><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x, y, teacher_forcing_ratio = <span class="hljs-number">0.75</span></span>):<br></code></pre></td></tr></table></figure><p>其中<strong>Seq2Seq_Attention:</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Seq2Seq_Attention</span>(torch.nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, encoder, decoder, device</span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        <span class="hljs-variable language_">self</span>.encoder = encoder<br>        <span class="hljs-variable language_">self</span>.decoder = decoder<br>        <span class="hljs-variable language_">self</span>.device = device<br>        <span class="hljs-variable language_">self</span>.attention = nn.Linear(encoder.hidden_size*<span class="hljs-number">2</span>, encoder.hidden_size)<br>        <span class="hljs-variable language_">self</span>.softmax = nn.Softmax(dim=<span class="hljs-number">1</span>)<br><br>        <span class="hljs-keyword">assert</span> encoder.hidden_size == decoder.hidden_size, <span class="hljs-string">&quot;Hidden dimensions of encoder and decoder must be equal!&quot;</span><br>        <span class="hljs-keyword">assert</span> encoder.n_layers == decoder.n_layers,       <span class="hljs-string">&quot;Encoder and decoder must have equal number of layers!&quot;</span><br>        nn.init.xavier_normal_(<span class="hljs-variable language_">self</span>.attention.weight)<br>        nn.init.constant_(<span class="hljs-variable language_">self</span>.attention.bias, <span class="hljs-number">0.0</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x, y,hiddens, teacher_forcing_ratio = <span class="hljs-number">0.75</span></span>):<br></code></pre></td></tr></table></figure><p><strong>encoder（LSTM）：</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Encoder</span>(torch.nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self,</span><br><span class="hljs-params">                input_size = <span class="hljs-number">128</span>,</span><br><span class="hljs-params">                embedding_size = <span class="hljs-number">128</span>,</span><br><span class="hljs-params">                hidden_size = <span class="hljs-number">256</span>,</span><br><span class="hljs-params">                n_layers = <span class="hljs-number">2</span>,</span><br><span class="hljs-params">                dropout = <span class="hljs-number">0.5</span></span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        <span class="hljs-variable language_">self</span>.hidden_size = hidden_size<br>        <span class="hljs-variable language_">self</span>.n_layers = n_layers<br>        <span class="hljs-variable language_">self</span>.linear = nn.Linear(input_size, embedding_size)<br>        <span class="hljs-variable language_">self</span>.rnn = nn.LSTM(embedding_size, hidden_size, n_layers,<br>                        dropout = dropout)<br>        <span class="hljs-variable language_">self</span>.dropout = nn.Dropout(dropout)<br><br>        nn.init.xavier_normal_(<span class="hljs-variable language_">self</span>.linear.weight)<br>        nn.init.constant_(<span class="hljs-variable language_">self</span>.linear.bias, <span class="hljs-number">0.0</span>)<br></code></pre></td></tr></table></figure><p><strong>decoder（LSTM）：</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Decoder</span>(torch.nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self,</span><br><span class="hljs-params">                output_size = <span class="hljs-number">256</span>,</span><br><span class="hljs-params">                embedding_size = <span class="hljs-number">128</span>,</span><br><span class="hljs-params">                hidden_size = <span class="hljs-number">256</span>,</span><br><span class="hljs-params">                n_layers = <span class="hljs-number">4</span>,</span><br><span class="hljs-params">                dropout = <span class="hljs-number">0.5</span></span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        <span class="hljs-variable language_">self</span>.output_size = output_size<br>        <span class="hljs-variable language_">self</span>.hidden_size = hidden_size<br>        <span class="hljs-variable language_">self</span>.n_layers = n_layers<br><br>        <span class="hljs-variable language_">self</span>.embedding = nn.Linear(output_size, embedding_size)<br>        <span class="hljs-variable language_">self</span>.rnn = nn.LSTM(embedding_size, hidden_size, n_layers, dropout = dropout)<br>        <span class="hljs-variable language_">self</span>.linear = nn.Linear(hidden_size, output_size)<br>        <span class="hljs-variable language_">self</span>.dropout = nn.Dropout(dropout)<br><br>        nn.init.xavier_normal_(<span class="hljs-variable language_">self</span>.embedding.weight)<br>        nn.init.constant_(<span class="hljs-variable language_">self</span>.embedding.bias, <span class="hljs-number">0.0</span>)<br>        nn.init.xavier_normal_(<span class="hljs-variable language_">self</span>.linear.weight)<br>        nn.init.constant_(<span class="hljs-variable language_">self</span>.linear.bias, <span class="hljs-number">0.0</span>)<br></code></pre></td></tr></table></figure><p>由于是联合优化，因此总体Model如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Model</span>(torch.nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, seq2seq_node, seq2seq_motif,seq2seq_graph, device</span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        <span class="hljs-variable language_">self</span>.seq2seq_node = seq2seq_node<br>        <span class="hljs-variable language_">self</span>.seq2seq_motif = seq2seq_motif<br>        <span class="hljs-variable language_">self</span>.seq2seq_graph = seq2seq_graph<br>        <span class="hljs-variable language_">self</span>.device = device<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, node_x, motif_x,graph_x,node_y,motif_y,graph_y, teacher_forcing_ratio = <span class="hljs-number">0.75</span></span>):<br>        graph_emb,graph_hiddens=seq2seq_graph(graph_x,graph_y,teacher_forcing_ratio)<br>        motig_emb,motif_hiddens=seq2seq_motif(motif_x,motif_y,graph_hiddens,teacher_forcing_ratio)<br>        node_emb,_ =seq2seq_node(node_x,node_y,motif_hiddens,teacher_forcing_ratio)<br>        final_emb=torch.cat((node_emb,motig_emb,graph_emb),axis=<span class="hljs-number">2</span>)<br>        <span class="hljs-keyword">return</span> final_emb<br></code></pre></td></tr></table></figure><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>很有启发性的一篇工作，总体思路就是在AE的基础上，串联多层次AE，来融合不同层次的语义信息（通过在不同层次之间，将上层的输出来生成下层的注意力，进行语义融合）。</p><p>文章的writting和画图都很棒，很值得借鉴，就是开源的代码不完全，GAT部分没有给出，无法复现。</p>]]></content>
    
    
    <categories>
      
      <category>论文笔记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>动态图神经网络</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>AFGRL阅读笔记</title>
    <link href="/2024/08/02/AFGRL%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"/>
    <url>/2024/08/02/AFGRL%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/</url>
    
    <content type="html"><![CDATA[<h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>提出了一种新颖的无增强图自监督学习框架，节点粒度的工作（个人感觉已经不像是对比学习了，不需要负例，只需要最小化正例之间的距离）</p><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>在对比学习方法中，需要对数据进行增强来构造正负例，但是 image 和 graph 在数据特征上具有很大的不同：虽然增强在图像上得到了很好的定义，但它在图上的行为可能是任意的。例如，就图像而言，即使随机裁剪和旋转它们，或者扭曲它们的颜色，它们的底层语义也几乎没有改变。另一方面，当我们扰动（删除或添加）图的边&#x2F;节点及其特征时，我们无法确定增强图是否与原始图正相关，更糟糕的是，由于图很难可视化，因此我们也没办法直观的感受到增强的有效性。例如，在分子图中，从阿司匹林的苯环上去掉一个碳原子会破坏芳香系统并产生烯烃链。此外，扰乱阿司匹林的连接可能会引入一种性质完全不同的分子，即五元内酯，这些微小改动造成了巨大的变化。</p><p>然后作者还进行了实验对比，说明了先前的工作有效性与否，很大程度上取决于使用的数据增强方式</p><h2 id="contribution"><a href="#contribution" class="headerlink" title="contribution"></a>contribution</h2><p>不同于之前的对比学习方法，本文提出的方法<code>不构造</code>view，而是从图本身去找 view，那么如何去确保自己找的 view 是一个好的 view 呢，本文提出了考虑了两种找 view 的方式结合起来，这样找到的 view 就更可能是好 view。</p><h2 id="Impletation"><a href="#Impletation" class="headerlink" title="Impletation"></a>Impletation</h2><p><img src="https://raw.githubusercontent.com/zy-Pioneer/BlogImage/main/img/2025/01/0584cdf7.png"></p><p>如上图所示，首先对一张图输入到两个 GCN 中，分别得到两个节点的嵌入H<sup>ξ</sup> 和 H<sup>θ</sup> ，这两者可以分别看做是初步找到的 view 和原始 view（分别记作 VE1 和 VE），接下来我们是要针对这个初步找到的 view 进行优化，让它更好。</p><h3 id="KNN"><a href="#KNN" class="headerlink" title="KNN"></a>KNN</h3><p>第一步我们对 VE 中的每个节点，去计算 VE1 中每个节点和该节点的距离：</p><p><img src="https://raw.githubusercontent.com/zy-Pioneer/BlogImage/main/img/2025/01/b0ef9ecf.png"></p><p>然后找到 K 个最近的节点，作为第一步的结果（KNN，K nearest neighbor），假设对于节点 V<sub>i</sub> ，KNN 的结果为 B<sub>i</sub> </p><h3 id="Local-Structural-Information"><a href="#Local-Structural-Information" class="headerlink" title="Local Structural Information"></a>Local Structural Information</h3><p>首先作者做了实验拥挤，发现方法 1 的结果，随着 K 的增大，其中和目标节点共享同一标签的比率逐渐降低</p><p><img src="https://raw.githubusercontent.com/zy-Pioneer/BlogImage/main/img/2025/01/20f4f5b0.png"></p><p>说明 1 的方法得到的结果存在一定的误差，为了缓解这一误差。作者考虑到了这一假设：</p><blockquote><p>对于节点 vi，其相邻节点 Ni 倾向于与查询节点 vi 共享相同的标签，即平滑假设（Zhu、Ghahramani 和 Lafferty 2003）。</p></blockquote><p>作者结合了 Local Structural Information，也就是说将目标节点的V<sub>i</sub> 的邻居节点集合 N<sub>i</sub> 和上一步得到的B<sub>i</sub> 作交集</p><p><img src="https://raw.githubusercontent.com/zy-Pioneer/BlogImage/main/img/2025/01/a6f5721d.png"></p><h3 id="Global-Semantics"><a href="#Global-Semantics" class="headerlink" title="Global Semantics"></a>Global Semantics</h3><p>在之前的步骤中，我们的筛选找到了和目标节点相邻的、具有相似语义的节点，但是也存在这样一种情况，即和目标节点不相邻、具有语义相似的节点（在文中举例是，在引文网络中，两个学者的研究方向一致，但是两人的文章并没有引用关系）。</p><p>作者认为这种特征可以根据聚类来捕获。（这里是我的一个疑惑的地方，为什么聚类可以捕获这种特征）</p><p>具体做法是，针对之前得到的 H<sup>ξ</sup> 进行 Kmeans 聚类，得到很多个簇，假设我们的目标节点 <img src="https://raw.githubusercontent.com/zy-Pioneer/BlogImage/main/img/2025/01/d21e93a2.png">，那么和 v<sub>i </sub>属于同一个簇的所有节点我们记作 C<sub>i</sub> ，这里同样我们取交集</p><p><img src="https://raw.githubusercontent.com/zy-Pioneer/BlogImage/main/img/2025/01/fdab93fb.png"></p><p>最终，我们通过上述两部分，得到了筛选过后的 VE1:</p><p><img src="https://raw.githubusercontent.com/zy-Pioneer/BlogImage/main/img/2025/01/8b57fb69.png"></p><p>最终构造的正例：</p><p><img src="https://raw.githubusercontent.com/zy-Pioneer/BlogImage/main/img/2025/01/7b3d5c13.png"></p><h2 id="Overall-Loss-function"><a href="#Overall-Loss-function" class="headerlink" title="Overall Loss function"></a>Overall Loss function</h2><p><img src="https://raw.githubusercontent.com/zy-Pioneer/BlogImage/main/img/2025/01/43e0f731.png"></p><p>我们的目标函数旨在最小化查询节点 v<sub>i</sub> 与其正例 P<sub>i</sub> 之间的余弦距离，这里的 </p><p><img src="https://raw.githubusercontent.com/zy-Pioneer/BlogImage/main/img/2025/01/6f883bb9.png"></p>]]></content>
    
    
    <categories>
      
      <category>论文笔记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>图神经网络</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>PRES阅读笔记</title>
    <link href="/2024/07/24/PRES%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"/>
    <url>/2024/07/24/PRES%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/</url>
    
    <content type="html"><![CDATA[<h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>基于内存的动态图神经网络 (MDGNN)十分有效，但是存在一个比较致命的问题：</p><p><strong>在一个时间窗口内的事件，其中的时间依赖关系无法捕捉</strong></p><h2 id="背景知识（TGN的memory机制解释）"><a href="#背景知识（TGN的memory机制解释）" class="headerlink" title="背景知识（TGN的memory机制解释）"></a>背景知识（TGN的memory机制解释）</h2><p>之前实现的MAGIC，是在静态图上进行处理，一次性加载完所有的数据。而动态图的特点在于动态，图的信息是不断扩展动态变化的，图并不是一次全部加载完全，而是每次只加载一个时间窗口中的事件，也就是边。</p><p>那么如何去捕获每个窗口之间的信息呢，在TGN中，它通过在每个时间窗口中计算节点的状态（这个状态由当前窗口中的事件以及上一时刻的状态决定），这个状态就称作memory，这个memory就代表了这个节点的历史信息，这样就能够捕获每个节点从出生到当前状态的所有信息。</p><p>下面详细解释一下节点memory的更新过程：</p><p><img src="https://raw.githubusercontent.com/zy-Pioneer/BlogImage/main/img/2025/01/92c8f93e.png" alt="图1"></p><p><img src="https://raw.githubusercontent.com/zy-Pioneer/BlogImage/main/img/2025/01/2d88de91.png" alt="图2"></p><p>如图2所示，整个TGN的核心就在这个TGNMemory，它维护了三个结构，分别是memory、msg_s_store（源节点的msg存储）和msg_d_store（目标节点的msg存储）。先计算msg：对于batch中的src和dst分别计算一次msg（视为无向图），每次msg计算如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">raw_msg = torch.cat(raw_msg, dim=<span class="hljs-number">0</span>)<br>t_rel = t - <span class="hljs-variable language_">self</span>.last_update[src]<br>t_enc = <span class="hljs-variable language_">self</span>.time_enc(t_rel.to(raw_msg.dtype))<br><br>msg = msg_module(<span class="hljs-variable language_">self</span>.memory[src], <span class="hljs-variable language_">self</span>.memory[dst], raw_msg, t_enc)<br></code></pre></td></tr></table></figure><p>这里的raw_msg就是msg_s_store或msg_d_store，取决于是计算src的msg还是dst的msg</p><p>计算完msg之后，在当前时间窗口中，对每个节点聚合和它交互的边，这个聚合操作可以自定义，在TGN中它的实现是选择最新的那条边，其他边就扔掉了（这也就是PERS这篇论文中想解决的问题，处理一个时间窗口中的时间顺序关系），将选择的那条边对应的msg和当前状态的memory一起送进GRU（一种循环神经网络，可以捕获msg和memory的序列特征）中，来更新memory。</p><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><h3 id="现有工作存在的问题"><a href="#现有工作存在的问题" class="headerlink" title="现有工作存在的问题"></a>现有工作存在的问题</h3><ol><li>MDGNN无法维持同一批次（时间窗口）内的数据点之间的时间依赖性，因此常常选择较小的时间窗口。</li><li>较小的时间窗口无法有效利用计算资源，因此解决批量大小瓶颈对于计算资源的利用至关重要。</li></ol><p><img src="https://raw.githubusercontent.com/zy-Pioneer/BlogImage/main/img/2025/01/f616b3f1.png"></p><h3 id="本文完成的工作"><a href="#本文完成的工作" class="headerlink" title="本文完成的工作"></a>本文完成的工作</h3><ol><li>进行了数学分析，证明了大时间窗口比小时间窗口更好（全文基本上都是数学分析，公式占了一半的篇幅，实在是看不太明白）</li><li>设计了一种新颖的框架来改善小时间窗口的问题</li><li>进行了实验，证明了本文提出的工作效果好</li></ol><h2 id="PERS-METHOD"><a href="#PERS-METHOD" class="headerlink" title="PERS METHOD"></a>PERS METHOD</h2><h3 id="方法总览"><a href="#方法总览" class="headerlink" title="方法总览"></a>方法总览</h3><p><img src="https://raw.githubusercontent.com/zy-Pioneer/BlogImage/main/img/2025/01/02ce2897.png"></p><p><img src="https://raw.githubusercontent.com/zy-Pioneer/BlogImage/main/img/2025/01/4076c791.png"></p><p>整篇文章的目的是对上式的右半边进行优化，右半边的值越小越好，其中最具影响力的两个因素是μ和σ<sub>max</sub>，因此本文就是为了去增大μ并减小σ<sub>max</sub>，提出了两个方向的改进措施<sup></sup>。</p><ul><li>ITERATIVE PREDICTION-CORRECTION SCHEME（优化第二项）</li><li>MEMORY COHERENCE SMOOTHING（优化第一项）</li></ul><p>伪代码如下：</p><p><img src="https://raw.githubusercontent.com/zy-Pioneer/BlogImage/main/img/2025/01/bb9aa082.png"></p><h3 id="ITERATIVE-PREDICTION-CORRECTION-SCHEME（迭代预测校正）"><a href="#ITERATIVE-PREDICTION-CORRECTION-SCHEME（迭代预测校正）" class="headerlink" title="ITERATIVE PREDICTION-CORRECTION SCHEME（迭代预测校正）"></a>ITERATIVE PREDICTION-CORRECTION SCHEME（迭代预测校正）</h3><h4 id="概念定义：pending-events"><a href="#概念定义：pending-events" class="headerlink" title="概念定义：pending events"></a>概念定义：pending events</h4><p><img src="https://raw.githubusercontent.com/zy-Pioneer/BlogImage/main/img/2025/01/8ad26fbb.png"></p><h4 id="背景知识：Gaussian-Mixture-Model"><a href="#背景知识：Gaussian-Mixture-Model" class="headerlink" title="背景知识：Gaussian Mixture Model"></a>背景知识：Gaussian Mixture Model</h4><p> GMM 假设数据点由多个高斯分布混合生成。每个高斯分布称为一个成分（component）。GMM 的概率密度函数是这些成分的加权和：  </p><p><img src="https://raw.githubusercontent.com/zy-Pioneer/BlogImage/main/img/2025/01/20f8e7aa.png"></p><p>因此GMM的参数包括：</p><ul><li>每个成分的均值向量 μ<sub>i</sub> </li><li>每个成分的协方差矩阵 Σ<sub>i</sub> </li><li>每个成分的权重 π<sub>i</sub></li></ul><p>接着使用 期望最大化（EM）算法来更新参数，其主要包含两个主要步骤：</p><ul><li><strong>E 步（期望步）</strong>：计算每个数据点属于每个成分的概率，即责任度（responsibility）。</li><li><strong>M 步（最大化步）</strong>：根据 E 步计算的责任度，重新估计参数。</li></ul><p><img src="https://raw.githubusercontent.com/zy-Pioneer/BlogImage/main/img/2025/01/e8cddf5d.png"></p><h4 id="纠错机制"><a href="#纠错机制" class="headerlink" title="纠错机制"></a>纠错机制</h4><p>设置GMM的成分数为2，由于该论文中的场景是进行链接预测，因此它会进行正负采样，所以这里设置成分数为2，不太懂这个是怎么训练的，但是最终，这个GMM的作用是预测δ<sub>si</sub> 的分布，通过这个分布可以每次去生成一个预测的节点状态：</p><p><img src="https://raw.githubusercontent.com/zy-Pioneer/BlogImage/main/img/2025/01/774320c1.png"></p><p>之后为了拟合真实的考虑了时间的节点状态，作者使用参数γ去中和：</p><p><img src="https://raw.githubusercontent.com/zy-Pioneer/BlogImage/main/img/2025/01/e30f87e2.png"></p><p>这时得到的值就是进行纠错之后的节点状态，那么为什么是上面两个公式这样的形式呢，作者在附录中进行了推导（作者说明了这里的符号和论文其他部分不一致），证明了：</p><p><img src="https://raw.githubusercontent.com/zy-Pioneer/BlogImage/main/img/2025/01/6eeb6afa.png"></p><p><img src="https://raw.githubusercontent.com/zy-Pioneer/BlogImage/main/img/2025/01/3f208881.png"></p><p>也就是表明本文方法计算出的状态相对于未改进之前，更接近真实值，优化了方差的大小（不懂那个方差是啥，但它说是就是吧）</p><h3 id="MEMORY-COHERENCE-SMOOTHING"><a href="#MEMORY-COHERENCE-SMOOTHING" class="headerlink" title="MEMORY COHERENCE SMOOTHING"></a>MEMORY COHERENCE SMOOTHING</h3><p><img src="https://raw.githubusercontent.com/zy-Pioneer/BlogImage/main/img/2025/01/14c6d51b.png"></p><p>这个内存一致性怎么计算的看不懂，也不太能看懂是个啥，看它的描述，上半部分应该是考虑了pending events时（考虑了时间依赖性）去更新节点状态计算的梯度和未考虑pending events去更新节点状态计算的梯度进行点积。也就是说，这个一致性在直观上来讲，它度量了理想的梯度下降方向和实际的梯度下降方向的一致程度。当它是正值的时候，表示方向一致（可能参数都是增加或者较小？），负值就表示方向相反。</p>]]></content>
    
    
    <categories>
      
      <category>论文笔记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>图神经网络</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
