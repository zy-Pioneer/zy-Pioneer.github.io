<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>AMCNet阅读笔记</title>
    <link href="/2025/01/16/AMCNet%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"/>
    <url>/2025/01/16/AMCNet%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/</url>
    
    <content type="html"><![CDATA[<h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>动态链接预测（在动态图中，预测两个点在时间t是否存在边）关注两个信息：结构信息和时间信息。现有工作要么只考虑其中一个因素，要么两个因素都单独考虑而没有将它们联系起来，忽略了两者之间的关联性。</p><p>因此本文提出了一种方法，<strong>多尺度注意力协同进化网络（Attentional Multi-scale Co-evolving Network）</strong>，使用多层次注意力机制的序列到序列的模型（<strong>sequence-to-sequence</strong>）来学习不同层次之间的动态变化的内在关系。</p><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p><img src="https://raw.githubusercontent.com/zy-Pioneer/BlogImage/main/img/2025/01/9a2f5847.png"></p><p>本文中将图中的结构分为三个层次：</p><ul><li>微观层次（Microscopic structure）：图中的节点和边</li><li>中观层次（Mesoscopic structure）：图中的子图或者社区</li><li>宏观层次（Macroscopic structure）：整张图</li></ul><p>本文认为网络是由个体及其相互联系构成的，因此宏观时间动态自然取决于每个个体如何选择与他人建立联系的微观时间动态。另一方面，研究表明，人类行为受到社会关系的动态影响，例如政治取向、音乐品味，甚至人们如何选择新朋友。（中观影响微观，微观影响中观和宏观）</p><h3 id="contribution"><a href="#contribution" class="headerlink" title="contribution"></a>contribution</h3><ul><li>设计了多层次表示学习模块（通过GNN学习到节点表示，再通过节点表示来设计pooling表示中观和宏观），为了表示中观，提出了一个<code>motifs</code>的概念</li><li>提出了一个多层次协同进化模型来学习每个层次的动态特征</li><li>为了了解不同结构尺度的时间动态之间的内在相关性，通过一种新颖的基于注意力的分层模型，利用较高尺度的表示来指导较低尺度表示的学习过程。</li></ul><blockquote><p>motifs简介</p><p>motifs是一种模式，如下图所示：</p><p><img src="https://raw.githubusercontent.com/zy-Pioneer/BlogImage/main/img/2025/01/d203283f.png"></p><p>它表示一种子图结构，如何去判定一个子图结构是否为motif呢？有两个指标：频率和重要性。</p><p>频率指的是它在图中出现的频率，重要性通过随机构造一张随机图，判断真实图种motif出现的频率和随机图出现的频率的差异来判断重要性，差异越大，越重要</p><p>这个motif的发现有现成的工作来做，本文中并没有涉及构造motif的代码，它直接用了</p></blockquote><h2 id="method"><a href="#method" class="headerlink" title="method"></a>method</h2><p><img src="https://raw.githubusercontent.com/zy-Pioneer/BlogImage/main/img/2025/01/f7a04ef9.png"></p><p>整个架构分为两部分：</p><ol><li><strong>multiscale representation learning module</strong></li><li><strong>multi-scale evolving module.</strong></li></ol><h3 id="Multi-scale-Representation-Learning"><a href="#Multi-scale-Representation-Learning" class="headerlink" title="Multi-scale Representation Learning"></a>Multi-scale Representation Learning</h3><h4 id="Microscopic-Representation"><a href="#Microscopic-Representation" class="headerlink" title="Microscopic Representation"></a>Microscopic Representation</h4><p>用GAT来生成节点表示（就是MAGIC的骨架网络）</p><h4 id="Mesoscopic-Representation"><a href="#Mesoscopic-Representation" class="headerlink" title="Mesoscopic Representation"></a>Mesoscopic Representation</h4><p>作者一开始尝试，通过对motifs中的节点做平均池化来获得中观表示，但是效果不好，因此不单纯的做平均，加上了一个可学习的参数矩阵来为每个motif作为注意力参数</p><p><img src="https://raw.githubusercontent.com/zy-Pioneer/BlogImage/main/img/2025/01/a089c176.png"></p><p><img src="https://raw.githubusercontent.com/zy-Pioneer/BlogImage/main/img/2025/01/faf0efb3.png"></p><p>但是很奇怪，根据公式三，这样得到的表示不就是一个值了吗，我以为是每个motif都计算一个值作为中观表示</p><h4 id="Macroscopic-Representation"><a href="#Macroscopic-Representation" class="headerlink" title="Macroscopic Representation"></a>Macroscopic Representation</h4><p>全局的宏观表示就是将所有节点的特征平均一下：</p><p><img src="https://raw.githubusercontent.com/zy-Pioneer/BlogImage/main/img/2025/01/7dd9d57b.png"></p><h3 id="Multi-scale-Co-evolving-module"><a href="#Multi-scale-Co-evolving-module" class="headerlink" title="Multi-scale Co-evolving module"></a>Multi-scale Co-evolving module</h3><p>本文提出了两个观点：</p><ol><li>首先，从信息论的角度来看，数据中的噪声量和信息聚合水平通常呈负相关。结构层次越高，信息越少，噪声也越小。因此，较高结构尺度的时间动态比较低结构尺度更可预测。因此，较高尺度的预测有助于纠正较低尺度预测的潜在系统偏差，这对学习模型施加了尺度不变的约束。</li><li>其次，不同结构尺度的信息捕获了图的不同特征，从而相互补充。对不同尺度的时间动态进行联合建模使模型能够利用来自不同上下文范围的信息来进行预测。</li></ol><h4 id="Impletation"><a href="#Impletation" class="headerlink" title="Impletation"></a>Impletation</h4><p><strong>Sequence to Sequence Backbone：</strong>使用序列模型来捕获每个层次的数据的内在结构，设计了三个：</p><ol><li><strong>seq-seq-node：</strong>Seq2Seq_Attention(enc, dec, dev)</li><li><strong>seq-seq-motif：</strong>Seq2Seq_Attention(enc, dec, dev)</li><li><strong>seq-seq-graph：</strong>Seq2Seq(enc, dec, dev)</li></ol><p>从graph层次开始，graph指导motif，motif指导node：</p><p><img src="https://raw.githubusercontent.com/zy-Pioneer/BlogImage/main/img/2025/01/b681fa65.png"></p><p>其中<strong>seq2seq:</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Seq2Seq</span>(torch.nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, encoder, decoder, device</span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        <span class="hljs-variable language_">self</span>.encoder = encoder<br>        <span class="hljs-variable language_">self</span>.decoder = decoder<br>        <span class="hljs-variable language_">self</span>.device = device<br>        <span class="hljs-keyword">assert</span> encoder.hidden_size == decoder.hidden_size, <span class="hljs-string">&quot;Hidden dimensions of encoder and decoder must be equal!&quot;</span><br>        <span class="hljs-keyword">assert</span> encoder.n_layers == decoder.n_layers,       <span class="hljs-string">&quot;Encoder and decoder must have equal number of layers!&quot;</span><br><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x, y, teacher_forcing_ratio = <span class="hljs-number">0.75</span></span>):<br></code></pre></td></tr></table></figure><p>其中<strong>Seq2Seq_Attention:</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Seq2Seq_Attention</span>(torch.nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, encoder, decoder, device</span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        <span class="hljs-variable language_">self</span>.encoder = encoder<br>        <span class="hljs-variable language_">self</span>.decoder = decoder<br>        <span class="hljs-variable language_">self</span>.device = device<br>        <span class="hljs-variable language_">self</span>.attention = nn.Linear(encoder.hidden_size*<span class="hljs-number">2</span>, encoder.hidden_size)<br>        <span class="hljs-variable language_">self</span>.softmax = nn.Softmax(dim=<span class="hljs-number">1</span>)<br><br>        <span class="hljs-keyword">assert</span> encoder.hidden_size == decoder.hidden_size, <span class="hljs-string">&quot;Hidden dimensions of encoder and decoder must be equal!&quot;</span><br>        <span class="hljs-keyword">assert</span> encoder.n_layers == decoder.n_layers,       <span class="hljs-string">&quot;Encoder and decoder must have equal number of layers!&quot;</span><br>        nn.init.xavier_normal_(<span class="hljs-variable language_">self</span>.attention.weight)<br>        nn.init.constant_(<span class="hljs-variable language_">self</span>.attention.bias, <span class="hljs-number">0.0</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x, y,hiddens, teacher_forcing_ratio = <span class="hljs-number">0.75</span></span>):<br></code></pre></td></tr></table></figure><p><strong>encoder（LSTM）：</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Encoder</span>(torch.nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self,</span><br><span class="hljs-params">                input_size = <span class="hljs-number">128</span>,</span><br><span class="hljs-params">                embedding_size = <span class="hljs-number">128</span>,</span><br><span class="hljs-params">                hidden_size = <span class="hljs-number">256</span>,</span><br><span class="hljs-params">                n_layers = <span class="hljs-number">2</span>,</span><br><span class="hljs-params">                dropout = <span class="hljs-number">0.5</span></span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        <span class="hljs-variable language_">self</span>.hidden_size = hidden_size<br>        <span class="hljs-variable language_">self</span>.n_layers = n_layers<br>        <span class="hljs-variable language_">self</span>.linear = nn.Linear(input_size, embedding_size)<br>        <span class="hljs-variable language_">self</span>.rnn = nn.LSTM(embedding_size, hidden_size, n_layers,<br>                        dropout = dropout)<br>        <span class="hljs-variable language_">self</span>.dropout = nn.Dropout(dropout)<br><br>        nn.init.xavier_normal_(<span class="hljs-variable language_">self</span>.linear.weight)<br>        nn.init.constant_(<span class="hljs-variable language_">self</span>.linear.bias, <span class="hljs-number">0.0</span>)<br></code></pre></td></tr></table></figure><p><strong>decoder（LSTM）：</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Decoder</span>(torch.nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self,</span><br><span class="hljs-params">                output_size = <span class="hljs-number">256</span>,</span><br><span class="hljs-params">                embedding_size = <span class="hljs-number">128</span>,</span><br><span class="hljs-params">                hidden_size = <span class="hljs-number">256</span>,</span><br><span class="hljs-params">                n_layers = <span class="hljs-number">4</span>,</span><br><span class="hljs-params">                dropout = <span class="hljs-number">0.5</span></span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        <span class="hljs-variable language_">self</span>.output_size = output_size<br>        <span class="hljs-variable language_">self</span>.hidden_size = hidden_size<br>        <span class="hljs-variable language_">self</span>.n_layers = n_layers<br><br>        <span class="hljs-variable language_">self</span>.embedding = nn.Linear(output_size, embedding_size)<br>        <span class="hljs-variable language_">self</span>.rnn = nn.LSTM(embedding_size, hidden_size, n_layers, dropout = dropout)<br>        <span class="hljs-variable language_">self</span>.linear = nn.Linear(hidden_size, output_size)<br>        <span class="hljs-variable language_">self</span>.dropout = nn.Dropout(dropout)<br><br>        nn.init.xavier_normal_(<span class="hljs-variable language_">self</span>.embedding.weight)<br>        nn.init.constant_(<span class="hljs-variable language_">self</span>.embedding.bias, <span class="hljs-number">0.0</span>)<br>        nn.init.xavier_normal_(<span class="hljs-variable language_">self</span>.linear.weight)<br>        nn.init.constant_(<span class="hljs-variable language_">self</span>.linear.bias, <span class="hljs-number">0.0</span>)<br></code></pre></td></tr></table></figure><p>由于是联合优化，因此总体Model如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Model</span>(torch.nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, seq2seq_node, seq2seq_motif,seq2seq_graph, device</span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        <span class="hljs-variable language_">self</span>.seq2seq_node = seq2seq_node<br>        <span class="hljs-variable language_">self</span>.seq2seq_motif = seq2seq_motif<br>        <span class="hljs-variable language_">self</span>.seq2seq_graph = seq2seq_graph<br>        <span class="hljs-variable language_">self</span>.device = device<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, node_x, motif_x,graph_x,node_y,motif_y,graph_y, teacher_forcing_ratio = <span class="hljs-number">0.75</span></span>):<br>        graph_emb,graph_hiddens=seq2seq_graph(graph_x,graph_y,teacher_forcing_ratio)<br>        motig_emb,motif_hiddens=seq2seq_motif(motif_x,motif_y,graph_hiddens,teacher_forcing_ratio)<br>        node_emb,_ =seq2seq_node(node_x,node_y,motif_hiddens,teacher_forcing_ratio)<br>        final_emb=torch.cat((node_emb,motig_emb,graph_emb),axis=<span class="hljs-number">2</span>)<br>        <span class="hljs-keyword">return</span> final_emb<br></code></pre></td></tr></table></figure><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>很有启发性的一篇工作，总体思路就是在AE的基础上，串联多层次AE，来融合不同层次的语义信息（通过在不同层次之间，将上层的输出来生成下层的注意力，进行语义融合）。</p><p>文章的writting和画图都很棒，很值得借鉴，就是开源的代码不完全，GAT部分没有给出，无法复现。</p>]]></content>
    
    
    <categories>
      
      <category>论文笔记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>动态图神经网络</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title></title>
    <link href="/2025/01/15/PROVNINJA%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"/>
    <url>/2025/01/15/PROVNINJA%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/</url>
    
    <content type="html"><![CDATA[<h4 id="d66ad31e"></h4>该论文提出了一个名为 **PROVNINJA** 的框架，用来设计和生成对抗性攻击，目的是规避基于系统溯源**数据的机器学习检测器。系统溯源用于追踪系统中进程、文件、网络套接字等资源之间的操作和依赖关系，这些信息通过**溯源图来表示。PROVNINJA的主要目标是伪装恶意行为，使它们看起来像正常系统操作，从而规避检测。<p><img src="https://cdn.nlark.com/yuque/0/2024/png/46744832/1728363715637-8e45fd21-7754-4328-ba74-b799609e6ec1.png"></p><h2 id="XliVX"> Introduction</h2>基于溯源的ML检测器分析系统中详细的运行时数据，通过检测异常行为来防御潜在的 APT 和无文件恶意软件等复杂攻击。然而，现有的基于溯源的ML检测器并未完全抵御攻击者可能使用的对抗性技术，攻击者可以设计看似正常的系统操作来绕过检测。这种情况下需要一个系统化的方法来生成对抗性攻击，使其既能够完成恶意目标，又能尽量不被检测器发现。<h2 id="I4E44">PROVNINJA的核心框架</h2>PROVNINJA通过三个关键阶段实现对抗性攻击的生成与实施：<h3 id="Gkur5"> 识别显眼事件</h3>显眼事件是指那些容易引起ML检测器注意的系统事件。这些事件可能具有以下特点：<ul><li>在系统中出现频率较低（稀有性高）。</li><li>对ML检测器的预测结果影响大。</li></ul><h4 id="ASPp1"> 频率分析</h4>PROVNINJA通过计算系统事件的**规则性评分（Regularity Score）**来判断事件的稀有程度。规则性评分的公式如下：<p><img src="https://cdn.nlark.com/yuque/0/2024/png/46744832/1728356583881-5460842d-8454-4719-9fcf-005055bd14aa.png"></p><p>通过计算每个事件的规则性评分，PROVNINJA可以识别出那些在系统活动中不常见的显眼事件，这些事件很容易引发检测器的警报。</p><h4 id="cvvfp">图结构分析</h4>1. 事件的传递性影响<p>在系统中，某些事件可能会通过一条长路径传播影响。一个显眼事件往往是那些能引发后续多个操作的事件。例如：</p><ul><li>如果进程A创建了进程B，而进程B执行了网络连接或修改了系统文件，那么进程A的行为会在之后通过进程B的操作对系统产生重大影响。</li><li>如果某个事件（如进程创建、文件读写）位于路径的关键位置，它不仅影响直接相连的节点，还可能通过多个中介节点传递影响到系统的其他部分。</li></ul><p>因此，具有<strong>广泛传递性</strong>的事件通常是显眼事件。攻击者可能希望通过替换这些事件来隐蔽攻击路径。</p><hr><ol start="2"><li>事件在路径中的位置</li></ol><p>在因果路径中，事件的相对位置非常重要。通常，<strong>位于因果路径关键位置</strong>的事件（例如路径的起点或中间位置）具有更高的显眼性，因为这些位置的事件可能直接影响后续事件的执行：</p><ul><li>如果某个事件发生在路径的起点，它通常是整个攻击链的触发点，且对于后续的攻击操作至关重要。</li><li>中间节点的事件（例如创建关键进程或修改重要文件）也可能是显眼的，因为它们连接了路径的不同阶段，起到了承前启后的作用。</li></ul><p>这些位置上的事件如果表现异常，就更容易被ML检测器捕捉到。</p><ol start="3"><li>路径的长度和复杂度</li></ol><p><strong>路径的长度和复杂度</strong>也是判断事件显眼性的一个重要指标。通常，越长的路径包含的操作和依赖关系越多，检测器可能会更加关注这类复杂路径中的关键节点和事件：</p><ul><li>如果某个事件位于一条长路径的中间，它的异常行为可能会被放大，因为它可能影响到路径的多个下游节点。</li><li>同样，如果一个路径包含多个高度依赖的节点或资源，这些资源之间的依赖关系越紧密，路径中的异常事件就越容易引起检测器的警觉。</li></ul><ol start="4"><li>节点和边的重要性（图结构分析）</li></ol><p>在因果路径分析中，除了事件本身的位置和传递性，还可以通过图的结构特性来分析事件的重要性。通过分析图中的<strong>节点和边的中心性</strong>，可以判断某个节点（事件）是否在整个系统图中起到关键作用。例如：</p><ul><li><strong>介数中心性（Betweenness Centrality）</strong>：介数中心性衡量一个节点在多条最短路径中的重要性。如果一个节点具有较高的介数中心性，说明该节点位于系统中多条重要路径的中间，连接着大量其他节点。这样的节点通常是显眼事件，因为它们控制着多个系统资源之间的交互。</li><li><strong>度数中心性（Degree Centrality）</strong>：一个节点的度数表示它与其他节点相连的边数。如果一个节点的度数很高（即它连接了许多其他节点），那么该节点可能是一个系统中高度活跃的资源。如果该节点的行为在系统中不常见，它可能成为显眼事件，因为它与系统中的多个资源有关联，且容易影响其他节点的行为。</li></ul><p>这些图结构分析可以帮助确定哪些事件在系统行为中起到至关重要的作用，从而可能引起检测器的重点关注。</p><h3 id="gL0XC">特征空间规避</h3>在特征空间规避中，PROVNINJA利用所谓的“**Gadget链**”来替换显眼事件。Gadget链是由一系列规则性较高的系统事件构成的，它们在系统中更加常见，因此替换后不会显得异常。<p>Gadget链的生成过程包括以下步骤：</p><ol><li><strong>寻找显眼事件的替代事件</strong>：PROVNINJA从“替代库”中寻找能够替代显眼事件的其他系统操作。替代事件必须符合两个条件：<ul><li>保持攻击者的目标不变。例如，如果攻击者需要创建一个恶意进程，替代事件也应能实现相似的操作。</li><li>替代事件应尽可能模仿正常的系统行为，避免引起检测器的警觉。</li></ul></li><li><strong>生成Gadget链</strong>：有时，单个替代事件不足以完成复杂的攻击任务。PROVNINJA可以通过多个Gadget链的组合来替换显眼事件，这些链条连接了一系列常见的系统操作，从而有效地掩盖了恶意行为。</li><li><strong>优化攻击路径</strong>：通过将显眼事件替换为更常见的事件，攻击路径在ML检测器看来更加像正常的系统活动。这样可以显著降低检测器对攻击的检测概率。</li></ol><p>在进行替换时，攻击者通过将显眼事件替换、攻击路径分散和路径加长（广度和深度）这些手段来混淆检测模型。</p><h3 id="hCY3Z">问题空间实现</h3>这是将特征空间中的规避策略转换为实际系统行为的过程，即将Gadget链应用于真实系统。在这个阶段，PROVNINJA的主要挑战是如何将理论上的规避方法应用到现实的复杂系统环境中。<p><strong>问题空间的实现面临以下几大挑战</strong>：</p><ol><li><strong>保持攻击语义</strong>：在进行攻击时，替代事件必须能够实现与原始显眼事件相同的恶意目标。例如，如果原本的恶意事件需要创建某个进程或修改某个文件，替代事件也必须具备类似功能，否则攻击目标将无法达成。</li><li><strong>处理系统环境差异</strong>：不同系统之间的配置和依赖关系可能会影响攻击实施。例如，一个系统在某个时间点的状态可能与在其他时间点有所不同，或系统运行的环境与攻击者的测试环境不一致，这些都可能影响攻击的实施。</li><li><strong>事件的可实现性</strong>：某些替代事件或Gadget链在攻击者的测试环境中可能可行，但在目标系统中却可能因为权限不足、系统配置差异等问题而无法实际实现。因此，PROVNINJA需要通过实际的系统环境进行校验，确保攻击路径的可执行性。</li></ol><h2 id="vRqkN">威胁模型</h2>PROVNINJA框架被设计用于不同类型的威胁模型，其中主要包括三种类型：<ul><li><strong>黑箱模型</strong>：攻击者无法直接访问或查询ML检测器的内部结构，但可以通过一些外部查询（如查询公开的程序执行频率）来推断系统行为。PROVNINJA在黑箱模型下主要依赖于从公开数据集中收集的行为数据，生成规避攻击。</li><li><strong>白箱模型</strong>：攻击者对ML检测器的内部工作机制有完全了解，包括模型的架构和参数。在这种情况下，PROVNINJA可以通过工具（如GNNExplainer）来识别哪些事件对ML检测器的决策贡献最大，从而设计更有针对性的攻击路径。</li><li><strong>盲箱模型</strong>：攻击者无法查询检测器，也无法获得系统的行为数据，只能基于公共数据集或对系统行为的推断来设计攻击。这是最为困难的模型。</li></ul>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>Incorporating Gradients to Rules_ Towards Lightweight, Adaptive Provenance-based Intrusion Detection</title>
    <link href="/2025/01/14/CAPTAIN%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"/>
    <url>/2025/01/14/CAPTAIN%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/</url>
    
    <content type="html"><![CDATA[<p>本文提出了一种名为CAPTAIN的基于规则的溯源入侵检测系统，该系统旨在解决现有PIDS面临的高误报率和难以适应不同环境等问题。</p><h2 id="motivation"><a href="#motivation" class="headerlink" title="motivation"></a>motivation</h2><h3 id="“Grey”-Nodes"><a href="#“Grey”-Nodes" class="headerlink" title="“Grey” Nodes"></a>“<strong>Grey” Nodes</strong></h3><p>随着云计算的普及，很多合法的网络连接和云服务（如AWS Lambda、Cloudflare Workers）被广泛使用，但攻击者也可以利用这些服务作为其命令与控制（C2）服务器的中介。这使得现有的基于规则的PIDS难以区分合法与恶意的外部IP连接。传统系统通常会根据简单的信任度规则对节点进行分类，但过于粗糙的规则往往会导致误报或漏报。</p><ul><li><strong>解决方案动机：</strong> CAPTAIN通过引入更细粒度的标签（如将节点信任度设置为0到1之间的浮点数），能够更灵活地反映不同程度的信任，从而避免误报或漏报。</li></ul><h3 id="依赖爆炸问题-Dependency-Explosion"><a href="#依赖爆炸问题-Dependency-Explosion" class="headerlink" title="依赖爆炸问题 (Dependency Explosion)"></a><strong>依赖爆炸问题 (Dependency Explosion)</strong></h3><p>依赖爆炸是指单个可疑事件可能导致大量系统实体被标记为可疑，尤其是在复杂的依赖链中。一个恶意事件可能引发整个依赖链上的实体被怀疑为恶意，而很多情况下这些实体其实是正常的。现有的解决方案大多采用简单的事件白名单或手动划分攻击阶段，但这些方法往往需要大量的应用程序&#x2F;操作系统的调试，无法在实际系统中大规模使用。</p><ul><li><strong>解决方案动机：</strong> CAPTAIN通过引入可调节的标签传播速率（Tag Propagation Rate），允许根据事件的类型和上下文来调整恶意标签的传播力度，从而防止不必要的传播引发依赖爆炸。</li></ul><h3 id="自定义警报触发问题-Customized-Alarm-Triggering"><a href="#自定义警报触发问题-Customized-Alarm-Triggering" class="headerlink" title="自定义警报触发问题 (Customized Alarm Triggering)"></a><strong>自定义警报触发问题 (Customized Alarm Triggering)</strong></h3><p>现有的基于规则的PIDS在触发警报时，通常对所有事件应用统一的规则和阈值。然而，在不同的情境下，同一种行为可能是正常的或恶意的。例如，<code>sshd</code>进程执行脚本是常见的行为，而<code>firefox</code>进程执行脚本则是异常的。传统的规则系统无法为不同的事件设定不同的阈值，从而容易导致漏报或误报。</p><ul><li><strong>解决方案动机：</strong> CAPTAIN引入了自适应警报触发机制，允许为不同的事件和进程设置特定的警报触发阈值，以区分正常行为和异常行为。通过这种自定义的阈值，CAPTAIN能够减少不必要的警报，并提高对异常行为的敏感性。</li></ul><h2 id="CAPTAIN-系统设计"><a href="#CAPTAIN-系统设计" class="headerlink" title="CAPTAIN 系统设计"></a>CAPTAIN 系统设计</h2><p><img src="https://cdn.nlark.com/yuque/0/2024/png/46744832/1728365003605-d50496fe-3e23-4efe-a5f2-69526c0e18a8.png"></p><p>CAPTAIN系统的设计主要分为两个部分：</p><ul><li><strong>检测模块（Detection Module）</strong>：负责处理审计日志，生成溯源图并进行实时入侵检测。</li><li><strong>学习模块（Learning Module）</strong>：在训练阶段对检测模块进行优化，通过梯度下降算法自动调整自适应参数，以减少误报并提高检测精度。</li></ul><h3 id="检测模块的设计"><a href="#检测模块的设计" class="headerlink" title="检测模块的设计"></a><strong>检测模块的设计</strong></h3><p>检测模块的核心功能是通过标签传播对系统实体（进程、文件、网络连接等）进行实时监控和检测。该模块分为以下三个主要组件：</p><h4 id="标签初始化（Tag-Initialization）"><a href="#标签初始化（Tag-Initialization）" class="headerlink" title="标签初始化（Tag Initialization）"></a><strong>标签初始化（Tag Initialization）</strong></h4><p>CAPTAIN为每个系统实体分配初始的安全标签。具体来说：</p><ul><li>**数据标签 (Data Tags)**：表示系统实体的机密性和完整性。</li><li>**代码标签 (Code Tags)**：仅用于进程，表示进程代码的可信度。</li></ul><p>系统实体首次出现在溯源图时，会根据其特征（如进程名、文件路径、IP地址等）分配初始标签。标签初始化的具体规则由自适应参数 <strong>A</strong> 决定，而该参数会在训练阶段根据反馈进行调整。</p><h4 id="标签传播（Tag-Propagation）"><a href="#标签传播（Tag-Propagation）" class="headerlink" title="标签传播（Tag Propagation）"></a><strong>标签传播（Tag Propagation）</strong></h4><p>当系统中发生事件时，CAPTAIN会根据预定义的规则在节点之间传播标签。传播的方式有两种：</p><ul><li><strong>数据流传播</strong>：数据从源节点传播到目标节点（如进程读取文件时，文件的标签会影响进程的标签）。</li><li><strong>控制流传播</strong>：进程间的交互也会传播标签（如进程执行另一个进程时，代码的可信度会传播）。</li></ul><p>标签传播的强度由 <strong>传播速率参数 (G)</strong> 控制。CAPTAIN可以为每条边设置不同的传播速率，以防止标签不必要地过度传播，特别是在应对“依赖爆炸”问题时，传播速率的自适应调整尤为关键。</p><h4 id="警报生成（Alarm-Generation）"><a href="#警报生成（Alarm-Generation）" class="headerlink" title="警报生成（Alarm Generation）"></a><strong>警报生成（Alarm Generation）</strong></h4><p>CAPTAIN系统会根据标签的变化触发安全警报。当标签传播到某个节点，并且该节点的标签值超过了设定的阈值时，就会触发相应的警报。警报触发规则由 <strong>阈值参数 (T)</strong> 控制，可以根据不同的事件类型和实体特征调整触发阈值。</p><p>例如：</p><ul><li>当进程试图执行低完整性的代码时，系统可能会触发代码完整性相关的警报。</li><li>当进程访问高机密性的数据时，系统会触发数据泄漏警报。</li></ul><p>CAPTAIN能够为不同类型的系统事件设置灵活的阈值，从而减少误报，同时确保检测到真正的威胁。</p><h3 id="学习模块的设计"><a href="#学习模块的设计" class="headerlink" title="学习模块的设计"></a><strong>学习模块的设计</strong></h3><p>CAPTAIN的学习模块负责在训练阶段优化标签传播和警报触发的参数。通过对误报数据进行分析，该模块使用<strong>梯度下降算法</strong>来调整自适应参数（A, G, T），从而改进检测模块的性能。学习模块的主要功能包括：</p><h4 id="损失函数的定义（Loss-Function）"><a href="#损失函数的定义（Loss-Function）" class="headerlink" title="损失函数的定义（Loss Function）"></a><strong>损失函数的定义（Loss Function）</strong></h4><p>学习模块使用一个损失函数来衡量系统的检测效果。损失函数由两部分组成：</p><ul><li><strong>误报项</strong>：用于惩罚错误触发的警报。如果某个事件不应触发警报但触发了，该项会增加损失值。</li><li><strong>正则化项</strong>：用于避免系统过度宽松，确保系统对恶意活动仍然保持敏感。通过将当前参数与默认初始值之间的差距最小化，CAPTAIN能够在减少误报的同时保持对攻击的敏感性。</li></ul><h4 id="梯度计算（Gradient-Calculation）"><a href="#梯度计算（Gradient-Calculation）" class="headerlink" title="梯度计算（Gradient Calculation）"></a><strong>梯度计算（Gradient Calculation）</strong></h4><p>CAPTAIN将检测过程建模为可微分的函数，以便在训练过程中计算自适应参数的梯度。通过这些梯度，系统能够使用梯度下降算法不断更新参数，从而优化标签传播和警报生成规则。</p><p>例如：</p><ul><li>对于节点的初始标签（A）的梯度，系统根据标签如何传播来调整初始值，以减少误报。</li><li>对于边的传播速率（G），系统通过传播链上各节点的行为来计算传播速率的梯度，从而控制信息在系统中的传播程度。</li><li>对于警报阈值（T），梯度用于调整系统对不同事件的敏感性，避免过多或过少的警报触发。</li></ul><h4 id="训练与测试流程"><a href="#训练与测试流程" class="headerlink" title="训练与测试流程"></a><strong>训练与测试流程</strong></h4><p>在训练阶段，CAPTAIN会基于良性数据进行训练。训练的结果是生成一个优化的自适应参数配置。在测试阶段，系统根据训练得出的最优参数对新的系统事件进行实时检测。</p><h3 id=""><a href="#" class="headerlink" title=""></a></h3>]]></content>
    
    
    <categories>
      
      <category>论文笔记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>安全</tag>
      
      <tag>入侵检测</tag>
      
      <tag>PIDS</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>神经网络调参技巧</title>
    <link href="/2024/11/14/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%B0%83%E5%8F%82%E6%96%B9%E6%B3%95/"/>
    <url>/2024/11/14/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%B0%83%E5%8F%82%E6%96%B9%E6%B3%95/</url>
    
    <content type="html"><![CDATA[<h2 id="调参顺序"><a href="#调参顺序" class="headerlink" title="调参顺序"></a>调参顺序</h2><p>第一个要进行调整的参数就是学习率，需要设置一个好的初始学习率，它可以决定损失函数的降低速度以及损失函数的最低位置。通常从 0.01 开始，**范围从 [1e-6,1e-1]**，通常只选择 1e<sup>n</sup> 。</p><p>学习率优化器是针对每个参数进行调整的，学习率调度器是对全局的学习率进行调整的。</p><table><thead><tr><th><strong>学习率调度器</strong></th><th><strong>学习率优化器</strong></th><th><strong>组合优势</strong></th><th><strong>适用场景</strong></th></tr></thead><tbody><tr><td><strong>StepLR</strong></td><td>SGD, Adam</td><td>定期减小学习率，简单高效，防止过拟合</td><td>大多数监督学习任务，如分类、回归任务</td></tr><tr><td><strong>ReduceLROnPlateau</strong></td><td>SGD, Adam</td><td>自适应调节学习率，基于验证损失自动减少，避免学习率过小</td><td>验证集性能停滞的任务，如回归、复杂的模型训练</td></tr><tr><td><strong>ExponentialLR</strong></td><td>SGD, Adam, RMSprop</td><td>指数衰减学习率，快速收敛，减少训练时间</td><td>快速收敛场景，适合较大规模数据集</td></tr><tr><td><strong>CosineAnnealingLR</strong></td><td>SGD, Adam</td><td>平滑衰减学习率，避免震荡，适合长时间训练</td><td>长期训练的大型深度神经网络，如卷积神经网络</td></tr><tr><td><strong>CyclicLR</strong></td><td>Adam, RMSprop</td><td>周期性调整学习率，跳出局部最优，稳定优化</td><td>复杂优化任务，如生成对抗网络（GAN）、深度强化学习</td></tr><tr><td><strong>OneCycleLR</strong></td><td>Adam, SGD</td><td>先增大学习率，后逐渐减小，快速找到最优解</td><td>快速训练大规模神经网络，如图像分类、NLP大模型</td></tr><tr><td><strong>LambdaLR</strong></td><td>任意优化器</td><td>完全自定义学习率变化策略，灵活可控</td><td>特定需求场景，无法用其他调度器满足的情况</td></tr><tr><td><strong>MultiStepLR</strong></td><td>SGD, Adam</td><td>在特定里程碑时减少学习率，适合多阶段训练</td><td>长期训练的任务，如卷积神经网络、阶段性改进模型性能</td></tr></tbody></table><h2 id="过拟合缓解措施"><a href="#过拟合缓解措施" class="headerlink" title="过拟合缓解措施"></a>过拟合缓解措施</h2><table><thead><tr><th><strong>方法</strong></th><th><strong>原理</strong></th><th><strong>适用场景</strong></th><th><strong>优势</strong></th><th><strong>使用场景</strong></th></tr></thead><tbody><tr><td><strong>L2 正则化</strong></td><td>在损失函数中加入权重的平方和作为惩罚项，防止权重过大</td><td>大多数神经网络，尤其是复杂的深度模型</td><td>减少权重过大，提升模型的泛化能力</td><td>数据量大、模型复杂，可能出现过拟合的场景</td></tr><tr><td><strong>L1 正则化</strong></td><td>在损失函数中加入权重的绝对值和作为惩罚项，倾向于使部分权重趋近于零</td><td>稀疏模型、特征选择</td><td>实现特征选择，简化模型</td><td>需要稀疏性或特征选择的任务，如文本分类</td></tr><tr><td><strong>Dropout</strong></td><td>训练时随机丢弃部分神经元，减少神经元间共适应性</td><td>深度神经网络，尤其是全连接层较多的模型</td><td>提升泛化能力，减少共适应性</td><td>卷积神经网络（CNN）、循环神经网络（RNN）</td></tr><tr><td><strong>早停法（Early Stopping）</strong></td><td>监控验证集性能，当性能不再提升时停止训练</td><td>所有深度学习任务，特别是长时间训练的任务</td><td>节省训练时间，防止过拟合</td><td>长时间训练的任务，如大型神经网络、语言模型</td></tr><tr><td><strong>数据增强</strong></td><td>通过随机变换训练数据（如翻转、裁剪等）增加数据的多样性</td><td>图像分类、时间序列处理等</td><td>增强数据集多样性，提高模型泛化能力</td><td>图像分类（翻转、旋转）、语音处理（噪声增强）</td></tr><tr><td><strong>Batch Normalization</strong></td><td>对每层的激活值进行标准化处理，使输入具有稳定的分布</td><td>深层神经网络，如卷积神经网络和循环神经网络</td><td>加速收敛，防止过拟合，训练更稳定</td><td>深层模型（如ResNet、VGG等），用于加速训练和稳定</td></tr><tr><td><strong>减少模型复杂度</strong></td><td>减少模型的参数量（如降低网络层数、神经元数）</td><td>小数据集、简单任务</td><td>通过简化模型结构减少过拟合风险</td><td>数据较少、简单任务，如小型图像分类任务</td></tr><tr><td><strong>交叉验证</strong></td><td>将数据划分为多个子集，循环验证模型性能</td><td>小数据集、模型调参</td><td>多次训练提高模型评估的稳定性</td><td>小数据集，模型调优，避免单次训练评估误差的场景</td></tr><tr><td><strong>添加噪声</strong></td><td>在输入、隐藏层或输出层添加噪声，增加模型的训练难度</td><td>时间序列、音频处理任务</td><td>增强模型鲁棒性，防止过拟合</td><td>语音、时间序列等，模型需要适应噪声的场景</td></tr><tr><td><strong>调节批次大小</strong></td><td>使用较小的批次大小，增加训练中的随机性</td><td>深度学习模型，特别是CNN和RNN模型</td><td>小批次能有效提升模型的泛化能力</td><td>大规模数据处理，小批次可能提升泛化效果的场景</td></tr><tr><td><strong>正则化项</strong></td><td>在损失函数中添加特定任务的自定义正则化项</td><td>特定任务，如有特定约束的模型</td><td>更好地控制模型的复杂性</td><td>有明确的任务约束，如控制输出范围的场景</td></tr></tbody></table>]]></content>
    
    
    
    <tags>
      
      <tag>深度学习</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
